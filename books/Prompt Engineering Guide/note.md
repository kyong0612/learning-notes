# Prompt Engineering Guide

ref: <https://www.promptingguide.ai/jp>

指定されたウェブサイトの内容を確認するため、まずサイトをスクレイピングします。

ウェブサイトからスクレイピングした「LLMの設定」の内容を以下にまとめます：

## LLMの設定

プロンプトを使用してLLMと対話する際、いくつかのパラメータ設定によって異なる結果を得ることができます。主な設定パラメータは以下の通りです：

### Temperature（温度）

- 値が低いほど結果は決定論的になり、最も確率の高い回答が選ばれる
- 値が高いほどランダム性が増し、多様で創造的なアウトプットが可能になる
- 事実に基づくQ&Aには低い値が適切
- 詩の生成などの創造的タスクには高い値が効果的

### Top_p（核サンプリング）

- モデルが応答生成時の決定性をコントロールする手法
- 正確で事実に基づいた回答には低い値が適切
- 多様な回答を求める場合は高い値が適切
- 一般的には、TemperatureとTop_pは両方ではなくどちらか一方を調整することが推奨

### Max Length（最大長）

- モデルが生成するトークン数を管理
- 長すぎる・関連性のない回答を防止し、コストを管理できる

### Stop Sequences（停止シーケンス）

- モデルがトークン生成を停止する文字列を指定
- 回答の長さや構造を制御する方法
- 例：「11」を停止シーケンスに指定すると、10項目以上のリスト生成を防止できる

### Frequency Penalty（頻度ペナルティ）

- トークンが既に回答やプロンプトに出現した回数に比例してペナルティを適用
- 値が高いほど単語の繰り返しが少なくなる
- 頻出トークンに高いペナルティを与え、繰り返しを減らす

### Presence Penalty（存在ペナルティ）

- 繰り返されるトークンに対して同一のペナルティを適用
- 出現回数に関わらず（2回でも10回でも）同じペナルティが課される
- 多様性や創造性を求める場合は高く設定
- 特定フレーズへの集中が許容される場合は低く設定
- 一般的には、Frequency PenaltyとPresence Penaltyは両方ではなくどちらか一方を調整することが推奨

なお、使用するLLMのバージョンによって結果が異なる可能性があります。
