# Pre-Training GPT-4.5

ref: <https://www.youtube.com/watch?v=6nJZopACRuQ>

## GPT-4.5のプリトレーニング：OpenAIの大規模言語モデル開発の舞台裏

### 1. プロジェクト概要

- GPT-4.5の開発は約2年前から始まり、「GPT-4の10倍賢いモデル」を目標として設定
- OpenAIのほぼ全リソースを投入した大規模プロジェクト
- 予想以上にユーザーから高評価を獲得
- 現在は経験を積んだため、GPT-4レベルのモデルであれば5〜10人程度のチームで再訓練可能

### 2. 大規模モデル訓練の課題

#### 2.1 システムインフラの課題

- 大規模クラスタ（多数のGPU）での訓練は新たな問題を顕在化させる
- 小規模では稀だった障害が大規模では致命的な頻度で発生
- ハードウェア、ネットワークファブリック、個々のアクセラレータなど様々な障害源
- 特に訓練の初期段階では障害率が高く、原因を特定して解決するにつれて改善

#### 2.2 バグ対応の実例

- PyTorchのsum関数のバグが多くの問題の原因となった具体例
- 症状が異なる複数の問題が実は単一のバグだった
- データ分布に依存して非常に稀に発生する不具合
- 開発者たちは最初、自分たちの複雑なカーネルにバグがあると疑ったが、実際はPyTorchの基本機能にバグがあった

### 3. データ効率とアルゴリズム

- GPT-4.5から「計算制約の時代」から「データ制約の時代」へ移行
- 人間と比較すると、現在のモデルのデータ効率は天文学的に低い（100,000倍以上の差）
- 小さな効率改善（10%、20%など）が積み重なる可能性に期待
- 脳とはアルゴリズム的に全く異なる原理で動作しているため、人間レベルのデータ効率への道のりは不明確

### 4. チーム間の協力とコデザイン

- システムチームとMLチームの緊密な協力が不可欠
- GPT-4.5では、モデル仕様に基づいてシステムスタック自体を変更する必要があった
- マルチクラスター訓練、状態管理の新アプローチなど多くの変更が必要
- 「コデザイン」：MLアルゴリズムとシステムインフラストラクチャの共同設計
- 訓練中もMLコードの改善を継続し、実行時間を短縮

### 5. 将来の方向性と制約

- スケーリングはまだ限界に達していない
- 現在の知識とシステムで「GPT-5.5」までは到達可能と予想
- 将来的に1000万GPU以上の訓練実行が可能になる可能性
- 完全に同期的ではなく「半同期的」な大規模訓練へ
- 耐障害性がさらなるスケーリングの鍵

### 6. モデル評価とスケーリング法則

- パープレキシティ（perplexity）という指標でモデルを評価
- 単なる記憶力ではなく一般化能力を測定することの重要性
- 訓練データに含まれていない内部コードベース（monorepo）でのテスト
- スケーリング法則の哲学的根拠：圧縮と知能の関係
- 世界のデータにおいて関連概念がスパース（疎）である特性
- パワー法則：重要度が下がるにつれて出現頻度が下がる現象

### 7. 重要な結論と発見

- 大規模言語モデルの訓練には綿密な計画と準備が必要（実行の1年前から準備）
- 小規模から大規模へのスケーリング検証の重要性
- チーム境界を超えた協力精神の価値
- スケーリング法則は実際に機能し、モデルサイズと計算リソースの増加が知能の向上につながることを再確認
- データ効率の改善が今後の主要な研究分野となる可能性
