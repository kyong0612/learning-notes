# Notion が 2000 億件のノートを (クラッシュせずに) 処理する方法

ref: <https://www.youtube.com/watch?v=NwZ26lxl8wU>

## データレイクに関する詳細情報

### データレイク導入の背景と課題

- Notionは当初、ユーザー向けオンラインサービスと分析・ML処理に**同じPostgresインフラ**を使用していた
- これにより、分析処理がユーザーエクスペリエンスに影響を与える可能性があった
- Notionのデータモデルは「ブロック」が基本となり、**更新頻度が非常に高い**特性を持つ
  - 通常のブログシステムなどでは1つの更新に対して1つのデータベース行が変更される
  - Notionでは1回の編集で最大200以上のブロック（データベース行）が同時にリアルタイム更新される
  - この「高頻度更新」特性が独自のデータレイク構築を必要とする主要因になった

### 初期データレイク実装：Snowflakeの採用

- 解決策として最初に**Snowflakeデータレイク**を導入
- プロセスフロー：
  1. Postgresシャードからデータ抽出
  2. **Fivetran**を使用して抽出したデータをSnowflakeに生データとして読み込み
  3. データを変換して分析用の単一テーブルに統合（ELT = Extract, Load, Transform方式）
- Snowflakeの課題：
  - **新規データ挿入**には効率的だが、Notionの頻繁な**更新処理には最適ではなかった**
  - データモデルの特性上、計算処理が高コストになる傾向があった
  - ユーザー数が6〜12ヶ月ごとに倍増する状況に対応する拡張性に懸念があった

### Notion専用データレイクの構築

- データレイク開発の主要目標：
  1. **生データと処理済みデータの両方**を効率的に保存できるシステム
  2. Notionの**更新頻度の高いブロックデータ**に最適化された高速処理
  3. AI、検索など**非構造化データを必要とする最新機能**のサポート

### 最終的なデータレイクアーキテクチャ

- **Amazon S3**を中央リポジトリとして採用
  - 既存のAWSインフラとの統合性
  - コスト効率の高いストレージソリューション
  - Elasticsearch、ベクトルデータベース、KVストアなど他のサービスとの互換性確保
- データ処理パイプライン：
  1. **変更データキャプチャ（CDC）**: Postgresデータベースの増分変更を検出
  2. **Apache Kafka**: 変更データをPostgresからデータレイクへ一貫して大量送信するメッセージングシステム
  3. **Apache Spark**: ELTプロセスのトランスフォーム処理を担当
     - 複数コンピュータクラスタ間で大規模データセットをインメモリ処理
     - SQL以外の複雑なクエリ計算にも対応
  4. **Apache Hoodie**: S3へのデータ格納前に実装
     - データレイク上のデータパイプライン構築・管理を簡素化
     - 更新処理に最適化された機能を提供

### データレイク導入の効果

- オープンソースソフトウェアを活用することで**数百万ドルのコスト削減**を実現
- オンラインユーザー向けサービスと分析処理の負荷分離によるパフォーマンス向上
- 6〜12ヶ月ごとの**ユーザー数倍増**に対応できる拡張性の確保
- AIや高度な検索機能など新機能開発のための基盤整備
- 特に**更新が頻繁なNotionの独自データモデル**に最適化されたシステム構築

Notionのケースは、急成長するプロダクトが直面するデータ管理の課題と、オープンソースを活用した効率的なソリューション構築の好例です。一般的なデータレイクソリューションではなく、自社の特殊なデータパターンに合わせてカスタマイズしたアーキテクチャを選択したことが成功の鍵となりました。
