---
title: "Leading AI Language Models & Solutions"
source: "https://deepseek.ai/blog/deepseek-ocr-context-compression"
author:
  - "[[DeepSeek AI]]"
published: 2025-10-21
created: 2025-10-23
description: "DeepSeek AIによる先進的なAI言語モデルとエンタープライズソリューション。光学的2Dマッピングによる長文コンテキスト圧縮の新しいパラダイムを提示するDeepSeek-OCRについての詳細。"
tags:
  - "clippings"
  - "DeepSeek"
  - "OCR"
  - "コンテキスト圧縮"
  - "ビジョン言語モデル"
---

## 概要：コンテキスト圧縮の新パラダイム

- DeepSeek AIが**DeepSeek-OCR**を発表
  - 光学的2Dマッピングによる長文コンテキスト圧縮の画期的なアプローチ
  - テキストヘビーなドキュメント処理において、ビジョンベースの圧縮が驚異的な効率性を実現
  - 大規模言語モデル（LLM）の膨大なテキスト情報処理方法を革新する可能性

- システム構成
  - **DeepEncoder**（エンコーダー）
  - **DeepSeek3B-MoE-A570M**（デコーダー）
  - 10倍未満の圧縮率（10テキストトークンを1ビジョントークンに圧縮）で**97%のOCR精度**を達成
  - 20倍の高圧縮率でも約60%の精度を維持

## DeepSeek-OCRが革新的な理由

### 1. 高精度を維持した卓越した圧縮率

- テキスト情報を劇的に圧縮しながら高精度を維持する能力が核心的イノベーション
  - **96%以上のOCR精度**：9-10倍の圧縮率
  - **約90%の精度**：10-12倍の圧縮率
  - **約60%の精度**：20倍の圧縮率

- コンパクトな言語モデルが圧縮された視覚表現を効果的にデコード可能であることを実証
- より大規模なLLMも適切なプリトレーニング設計により同様の能力を容易に獲得できることを示唆

### 2. DeepEncoder：低アクティベーション、高効率

- 新規アーキテクチャの特徴
  - 高解像度入力でも低アクティベーションメモリと最小限のビジョントークンを維持
  
- 主要機能
  - ウィンドウアテンションとグローバルアテンションエンコーダーコンポーネントの直列接続
  - 16倍の畳み込み圧縮器
    - 密なグローバルアテンションに入る前にビジョントークンを削減
  - GPUメモリオーバーフローなしで大画像を処理する能力
  - 最適なパフォーマンスのための効果的なメモリとトークン圧縮

### 3. 最小限のトークンで最先端のパフォーマンス

- **OmniDocBench**ベンチマークでの驚異的な効率性
  - **GOT-OCR2.0**（ページあたり256トークン使用）を**わずか100ビジョントークン**で上回る
  - **MinerU2.0**（ページあたり平均6000以上のトークン）を**800未満のビジョントークン**で凌駕
  - エンドツーエンドモデルの中で最少のビジョントークン使用で最先端のパフォーマンスを達成

### 4. 大規模な本番スケーラビリティ

- 実世界での卓越したパフォーマンス
  - LLMとVLM向けのトレーニングデータを前例のない規模で生成可能
  
- 処理能力
  - **単一A100-40G GPU**で**1日あたり20万ページ以上**
  - **20ノード（160 A100-40G GPU）**で**1日あたり3,300万ページ**
  - 大規模ドキュメント処理タスクへの実用的な展開

## DeepSeek-OCRの技術アーキテクチャ

### ビジョンエンコーダーの比較

- 現在のオープンソースビジョン言語モデル（VLM）が採用する3つの主要なビジョンエンコーダータイプ
  
  1. **デュアルタワーアーキテクチャ**（例：Vary）
     - 利点：制御可能なパラメータ
     - 制限：複雑なデュアル画像前処理が必要
  
  2. **タイルベース手法**（例：InternVL2.0）
     - 利点：アクティベーションメモリの削減
     - 制限：過度な断片化と多数のビジョントークンが生じる可能性
  
  3. **適応解像度エンコーディング**（例：Qwen2-VL）
     - 利点：多様な解像度を柔軟に処理
     - 制限：膨大なアクティベーションメモリ消費の課題

- DeepEncoderの優位性
  - 各アプローチの最良の側面を組み合わせつつ、欠点を最小化
  - メモリ効率、トークン数、処理能力のバランスを達成

### マルチ解像度サポート

- DeepEncoderの設計特性
  - 複数の解像度を効率的にサポート
  - さまざまなサイズと複雑性のドキュメントを処理
  - パフォーマンスを犠牲にせず、過度な計算リソースを必要としない

### MoEデコーダーアーキテクチャ

- デコーダーコンポーネントの特徴
  - **DeepSeek3B-MoE-A570M**を利用
  - Mixture-of-Experts（MoE）アーキテクチャ
  - 高精度を維持しながら効率的な推論を提供
  
- 設計の利点
  - モデルがOCRタスクのさまざまな側面に特化可能
  - エキスパート間で知識を共有

## 実用的なアプリケーションとユースケース

### 歴史的文書の圧縮

- DeepSeek-OCRの応用可能性
  - 歴史的長文コンテキスト圧縮などの研究分野で大きな可能性
  - アーカイブ資料の効率的なデジタル化と処理が可能
  - 膨大なストレージや計算リソースを必要としない

### LLMにおけるメモリメカニズム

- ビジョン-テキスト圧縮パラダイムの新しい可能性
  - LLMにおけるメモリ忘却メカニズムの実装
  - 計算制約を管理しながら履歴コンテキストを効率的に保存・取得
  - モデルが効率的に履歴コンテキストを管理可能

### 拡張ドキュメント解析

- 標準OCRを超える機能
  - 高精度でのチャートとグラフの解析
  - 化学式と科学表記の解析
  - シンプルな幾何学図形と図表の解析
  - テキストが埋め込まれた自然画像の解析
  - さまざまな言語にわたる多言語ドキュメントの解析

### トレーニングデータ生成

- 大規模データ生成への活用
  - 単一GPUで1日あたり20万ページ以上を処理する能力
  - 次世代LLMとVLM向けの高品質トレーニングデータを大規模に生成するための理想的なツール

## 新しいパラダイム：「百聞は一見に如かず」

### 基本的な研究課題への取り組み

- DeepSeek-OCRが取り組む重要な研究課題
  - 「1000語を含むドキュメントをデコードするために、最低限必要なビジョントークン数は？」
  - 現在のモデルが十分に探求していない問題

### パラダイムシフトの意義

- 「百聞は一見に如かず」の原則に対する深い影響
  - ドキュメントテキストを含む単一画像が、同等のデジタルテキストよりも大幅に少ないトークンで豊富な情報を表現可能
  - ビジョントークンを通じた光学的圧縮が、従来のテキストエンコーディングよりもはるかに高い圧縮率を達成できることを示唆

- VLMの再考察
  - LLM中心の視点からビジョン言語モデル（VLM）を再検討
  - ビジョンエンコーダーがLLMのテキスト情報処理効率をどのように向上させるかに焦点
  - 視覚的質問応答（VQA）タスクのみに焦点を当てるのではない新しいアプローチ

## データエンジンとトレーニングパイプライン

### 包括的なデータ収集

- DeepSeek-OCRデータエンジンが組み込む複数のデータソース
  - **OCR 1.0データ**：ベースライントレーニング用の従来のOCRデータセット
  - **OCR 2.0データ**：高度な合成および実世界のドキュメントデータ
  - **一般ビジョンデータ**：より広範な視覚理解のための多様な画像データセット
  - **テキストのみのデータ**：デコーダー能力を強化する純粋な言語データ

### 2段階トレーニングプロセス

- 体系的なアプローチに従うトレーニングパイプライン
  1. **DeepEncoderのトレーニング**
     - 第1段階：効率的な圧縮のためのビジョンエンコーダーの最適化に焦点
  
  2. **DeepSeek-OCRのトレーニング**
     - 第2段階：エンコーダーとデコーダーを統合し、完全なシステムのファインチューニング

## オープンソース提供

### 公開されているリソース

- DeepSeek AIのオープンリサーチへのコミットメント
  - コードとモデルウェイトの両方が公開アクセス可能
  - 公開先：[github.com/deepseek-ai/DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR)

### オープンソースリリースのメリット

- 世界中の研究者と開発者が可能になること
  - 研究結果の再現と検証
  - カスタムアプリケーション向けのDeepSeek-OCRアーキテクチャの構築
  - コミュニティへの改善と拡張の貢献
  - 本番ユースケースへのシステム展開

## 結論：より効率的なLLMへ向けて

### 重要な前進

- DeepSeek-OCRが表すもの
  - 現代AIにおける最も差し迫った課題の1つへの重要な前進
  - 課題：長いテキストコンテキストの効率的な処理
  
- 視覚モダリティを圧縮媒体として活用
  - 高精度を維持しながら、異なるコンテキスト段階で大幅なトークン削減（7-20倍）が達成可能であることを実証

### 実用的な貢献

- DeepSeek-OCRによる定量的分析が提供するもの
  - VLMトークン配分を最適化するための実証的ガイドライン
  
- DeepEncoderアーキテクチャの実現性
  - 実世界での展開能力を持つ実用的な実現可能性を示す
  
- 新しい可能性の開拓
  - OCRを概念実証として焦点を当てているものの、このパラダイムは新しい可能性を開く
  - ビジョンとランゲージのモダリティを相乗的に組み合わせる方法の再考
  - 大規模テキスト処理とエージェントシステムにおける計算効率の向上

### 将来への展望

- LLMの継続的な成長
  - サイズと能力において成長し続けるLLM
  - DeepSeek-OCRのようなイノベーションが重要になる理由
    - これらの強力なモデルをよりアクセスしやすく、効率的に、実用的にするため
  
- AIの未来
  - コンテキスト管理と計算効率の基本的な課題に対する創造的なアプローチに依存する可能性
  - このような革新的なアプローチがAIの未来を形作る
