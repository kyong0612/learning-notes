# エージェント

著者: Julia Wiesinger、Patrick Marlow、Vladimir Vuskovic

2024年9月

## 謝辞

### レビュアーおよび貢献者

- Evan Huang
- Emily Xue
- Olcan Sercinoglu
- Sebastian Riedel
- Satinder Baveja
- Antonio Gulli
- Anant Nawalgaria

### キュレーターおよび編集者

- Antonio Gulli
- Anant Nawalgaria
- Grace Mollison

### テクニカルライター

- Joey Haymaker

### デザイナー

- Michael Lanning

## 目次

- [エージェント](#エージェント)
  - [謝辞](#謝辞)
    - [レビュアーおよび貢献者](#レビュアーおよび貢献者)
    - [キュレーターおよび編集者](#キュレーターおよび編集者)
    - [テクニカルライター](#テクニカルライター)
    - [デザイナー](#デザイナー)
  - [目次](#目次)
  - [はじめに](#はじめに)
  - [エージェントとは何か](#エージェントとは何か)
    - [モデル](#モデル)
    - [ツール](#ツール)
    - [オーケストレーションレイヤー](#オーケストレーションレイヤー)
    - [エージェントとモデルの比較](#エージェントとモデルの比較)
    - [認知アーキテクチャ：エージェントの動作原理](#認知アーキテクチャエージェントの動作原理)
  - [ツール：外部世界への鍵](#ツール外部世界への鍵)
    - [エクステンション](#エクステンション)
      - [サンプルエクステンション](#サンプルエクステンション)
    - [ファンクション](#ファンクション)
      - [ユースケース](#ユースケース)
      - [ファンクションのサンプルコード](#ファンクションのサンプルコード)
    - [データストア](#データストア)
      - [実装と応用](#実装と応用)
    - [ツールの要約](#ツールの要約)
  - [対象を絞った学習によるモデルパフォーマンスの向上](#対象を絞った学習によるモデルパフォーマンスの向上)
  - [LangChainによるエージェントクイックスタート](#langchainによるエージェントクイックスタート)
  - [Vertex AIエージェントでの本番アプリケーション](#vertex-aiエージェントでの本番アプリケーション)
  - [まとめ](#まとめ)
    - [モデル](#モデル-1)
    - [ツール](#ツール-1)
    - [オーケストレーションレイヤー](#オーケストレーションレイヤー-1)
    - [エージェントとモデルの比較](#エージェントとモデルの比較-1)
    - [認知アーキテクチャ：エージェントの動作原理](#認知アーキテクチャエージェントの動作原理-1)
  - [ツール：外部世界への鍵](#ツール外部世界への鍵-1)
    - [エクステンション](#エクステンション-1)
      - [サンプルエクステンション](#サンプルエクステンション-1)
    - [ファンクション](#ファンクション-1)

## はじめに

人間は複雑なパターン認識タスクを得意としています。しかし、結論に達する前に、書籍、Google検索、電卓などのツールを利用して既存の知識を補完することがよくあります。人間と同様に、生成AIモデルもツールを使用してリアルタイム情報にアクセスしたり、実世界のアクションを提案したりするように訓練できます。例えば、モデルはデータベース取得ツールを活用して顧客の購入履歴などの特定情報にアクセスし、パーソナライズされたショッピング推奨を生成できます。あるいは、ユーザーのクエリに基づいて、モデルは同僚にメール返信を送信したり、ユーザーに代わって金融取引を完了したりするために様々なAPI呼び出しを行うこともできます。

これを実現するためには、モデルが外部ツールのセットにアクセスできるだけでなく、自己主導的な方法であらゆるタスクを計画し実行する能力も必要です。推論、論理、外部情報へのアクセスがすべて生成AIモデルに接続されているこの組み合わせは、エージェント、つまり生成AIモデル単体の能力を超えて拡張するプログラムという概念を呼び起こします。このホワイトペーパーでは、これらすべての側面とそれに関連する側面について詳しく掘り下げていきます。

> 推論、論理、外部情報へのアクセスがすべて生成AIモデルに接続されているこの組み合わせは、エージェントという概念を呼び起こします。

## エージェントとは何か

最も基本的な形では、生成AIエージェントは、世界を観察し、利用可能なツールを使用して行動することにより、目標を達成しようとするアプリケーションとして定義できます。エージェントは自律的であり、特に達成すべき適切な目標や目的が提供されている場合、人間の介入なしに独立して行動できます。エージェントは目標達成へのアプローチにおいて積極的でもあります。人間からの明示的な指示セットがなくても、エージェントは最終目標を達成するために次に何をすべきかを推論できます。AIにおけるエージェントの概念は非常に一般的で強力ですが、このホワイトペーパーでは、本稿執筆時点で生成AIモデルが構築可能な特定タイプのエージェントに焦点を当てています。

エージェントの内部動作を理解するために、まずエージェントの行動、アクション、意思決定を駆動する基本的なコンポーネントを紹介しましょう。これらのコンポーネントの組み合わせは認知アーキテクチャと呼ばれ、これらのコンポーネントを組み合わせることで多くの認知アーキテクチャを実現できます。コア機能に焦点を当てると、図1に示すように、エージェントの認知アーキテクチャには3つの本質的なコンポーネントがあります。

![図1：一般的なエージェントアーキテクチャとコンポーネント]

### モデル

エージェントの範囲内では、モデルとはエージェントプロセスの中央意思決定者として使用される言語モデル（LM）を指します。エージェントによって使用されるモデルは、ReAct、Chain-of-Thought、Tree-of-Thoughtsなどの指示ベースの推論と論理フレームワークに従うことができる任意のサイズ（小/大）の1つまたは複数のLMとなります。モデルは、特定のエージェントアーキテクチャのニーズに基づいて、汎用、マルチモーダル、または微調整されたものとなります。最良の本番結果を得るためには、目的のエンドアプリケーションに最適なモデルを活用し、理想的には認知アーキテクチャで使用予定のツールに関連するデータシグネチャで訓練されたモデルを使用するべきです。

重要なことに、モデルは通常、エージェントの特定の構成設定（ツールの選択、オーケストレーション/推論のセットアップなど）で訓練されていません。ただし、特定のツールや様々なコンテキストでの推論ステップを使用するエージェントのインスタンスなど、エージェントの機能を示す例をモデルに提供することで、エージェントのタスクに対するモデルをさらに洗練させることも可能です。

### ツール

基盤モデルは、テキストや画像の生成において印象的ですが、外部世界とのインタラクション能力がないという制約があります。ツールはこのギャップを埋め、エージェントが外部データやサービスとやり取りし、基礎となるモデル単体を超えた幅広いアクションを可能にします。ツールは様々な形式を取り、複雑さの程度も異なりますが、通常はGET、POST、PATCH、DELETEなどの一般的なウェブAPIメソッドに準拠しています。

例えば、ツールはデータベース内の顧客情報を更新したり、エージェントがユーザーに提供する旅行推奨に影響を与える天気データを取得したりできます。ツールを使用することで、エージェントは実世界の情報にアクセスして処理できます。これにより、検索拡張生成（RAG）のような、より専門化されたシステムをサポートすることが可能になり、基盤モデル単体で達成できる範囲を大幅に拡張します。ツールについては後で詳しく説明しますが、最も重要なことは、ツールがエージェントの内部能力と外部世界の間のギャップを埋め、より広範な可能性を解き放つことです。

### オーケストレーションレイヤー

オーケストレーションレイヤーは、エージェントが情報を取り込み、内部推論を実行し、その推論を使用して次のアクションや決定に影響を与える循環プロセスを表します。一般的に、このループはエージェントが目標または停止点に達するまで継続します。オーケストレーションレイヤーの複雑さは、エージェントとそれが実行するタスクによって大きく異なります。一部のループは簡単な計算と決定ルールに基づくものですが、他のループは連鎖論理を含んだり、追加の機械学習アルゴリズムを含んだり、あるいは他の確率的推論技術を実装したりします。エージェントオーケストレーションレイヤーの詳細な実装については、認知アーキテクチャのセクションで詳しく説明します。

### エージェントとモデルの比較

エージェントとモデルの違いをより明確に理解するために、次の表を参考にしてください：

| モデル | エージェント |
|-------|-------------|
| 知識は訓練データで利用可能なものに限定される | ツールを介した外部システムとの接続により知識が拡張される |
| ユーザークエリに基づく単一の推論/予測。モデルに明示的に実装されていない限り、セッション履歴や継続的なコンテキスト（チャット履歴など）の管理はない | ユーザークエリやオーケストレーションレイヤーでの決定に基づくマルチターン推論/予測を可能にするセッション履歴（チャット履歴など）の管理。ここでの「ターン」は、相互作用システムとエージェント間のインタラクションとして定義される（1つの受信イベント/クエリと1つのエージェント応答） |
| ネイティブなツール実装はない | ツールはエージェントアーキテクチャにネイティブに実装されている |
| ネイティブな論理レイヤーの実装はない。ユーザーは単純な質問として、または推論フレームワーク（CoT、ReActなど）を使用して複雑なプロンプトを作成し、予測のモデルを導くことができる | CoT、ReAct、またはLangChainのような他の既成のエージェントフレームワークのような推論フレームワークを使用するネイティブな認知アーキテクチャ |

### 認知アーキテクチャ：エージェントの動作原理

忙しいキッチンでシェフを想像してみてください。彼らの目標はレストランの客のために美味しい料理を作ることで、これには計画、実行、調整のサイクルが含まれます。

- 彼らは客の注文や、パントリーや冷蔵庫にある食材など、情報を収集します。
- 彼らは集めた情報に基づいて、どのような料理やフレーバープロファイルを作れるかについて内部推論を行います。
- 彼らは野菜を切る、香辛料を混ぜる、肉を焼くなど、料理を作るための行動を取ります。

プロセスの各段階で、シェフは必要に応じて調整を行い、材料が減ったり客からフィードバックを受けたりするにつれて計画を洗練し、一連の以前の結果を使用して次のアクションプランを決定します。情報摂取、計画、実行、調整のこのサイクルは、シェフが目標を達成するために採用する独自の認知アーキテクチャを表しています。

シェフと同様に、エージェントは認知アーキテクチャを使用して、情報を反復的に処理し、情報に基づいた決定を行い、前の出力に基づいて次のアクションを洗練させることで目標を達成できます。エージェント認知アーキテクチャの中核にはオーケストレーションレイヤーがあり、メモリ、状態、推論、計画を維持する責任があります。それは急速に進化するプロンプトエンジニアリングの分野と関連するフレームワークを使用して推論と計画を導き、エージェントがより効果的に環境と対話しタスクを完了できるようにします。

言語モデルのプロンプトエンジニアリングフレームワークとタスク計画の研究分野は急速に進化しており、様々な有望なアプローチを生み出しています。網羅的なリストではありませんが、本稿執筆時点で利用可能な最も一般的なフレームワークと推論手法のいくつかを紹介します：

- ReAct：言語モデルにユーザークエリについて推論し行動するための思考プロセス戦略を提供するプロンプトエンジニアリングフレームワークで、コンテキスト内の例が有る場合と無い場合があります。ReActプロンプティングは、いくつかの最先端のベースラインを上回り、LLMの人間との相互運用性と信頼性を向上させることが示されています。

- Chain-of-Thought（CoT）：中間ステップを通じて推論能力を可能にするプロンプトエンジニアリングフレームワークです。CoTには、自己一貫性、アクティブプロンプト、マルチモーダルCoTなど、特定のアプリケーションに応じて強みと弱みを持つさまざまなサブ技術があります。

- Tree-of-Thoughts（ToT）：探索や戦略的先読みタスクに適したプロンプトエンジニアリングフレームワークです。思考の連鎖プロンプティングを一般化し、言語モデルによる一般的な問題解決のための中間ステップとして機能する様々な思考の連鎖を探索できるようにします。

エージェントは上記の推論技術の1つ、または他の多くの技術を利用して、ユーザーリクエストに対する次の最適なアクションを選択できます。例えば、ReActフレームワークを使用してユーザークエリに対する正しいアクションとツールを選択するようにプログラムされたエージェントを考えてみましょう。イベントの順序は次のようになります：

1. ユーザーがエージェントにクエリを送信
2. エージェントがReActシーケンスを開始
3. エージェントはモデルにプロンプトを提供し、次のReActステップとそれに対応する出力を生成するよう依頼します：
   a. 質問：プロンプトと共に提供されるユーザークエリからの入力質問
   b. 思考：次に何をすべきかについてのモデルの考え
   c. アクション：次に取るべきアクションに関するモデルの決定
      i. ここでツール選択が発生する可能性がある
      ii. 例えば、アクションは[Flights, Search, Code, None]のいずれかとなり、最初の3つはモデルが選択できる既知のツールを表し、最後は「ツール選択なし」を表す
   d. アクション入力：ツールに提供する入力（もしあれば）に関するモデルの決定
   e. 観察：アクション/アクション入力シーケンスの結果
      i. この思考/アクション/アクション入力/観察は必要に応じてN回繰り返される可能性がある
   f. 最終回答：元のユーザークエリに対して提供するモデルの最終回答
4. ReActループが終了し、最終回答がユーザーに返される

![図2：オーケストレーションレイヤーでReAct推論を使用したエージェントの例]

図2に示すように、モデル、ツール、エージェント構成が連携して、ユーザーの元のクエリに基づいた根拠のある簡潔な回答をユーザーに提供します。モデルは事前知識に基づいて回答を推測（幻覚）することもできましたが、代わりにツール（Flights）を使用してリアルタイムの外部情報を検索しました。この追加情報がモデルに提供され、モデルは実際の事実データに基づいてより情報に基づいた決定を下し、この情報をユーザーに要約することができました。

要約すると、エージェント応答の品質は、モデルが適切なツールを選択する能力を含む、これらの様々なタスクについて推論し行動する能力と、そのツールがどの程度うまく定義されているかに直接関連します。新鮮な食材と顧客からのフィードバックに注意深いシェフが料理を作るように、エージェントは最適な結果を提供するために健全な推論と信頼性の高い情報に依存しています。次のセクションでは、エージェントが新鮮なデータと接続するさまざまな方法について詳しく説明します。

## ツール：外部世界への鍵

言語モデルは情報処理に優れていますが、実世界を直接認識し影響を与える能力が欠けています。これにより、外部システムやデータとの対話が必要な状況での有用性が制限されます。つまり、ある意味では、言語モデルはその訓練データから学んだことに限られています。しかし、どれだけ多くのデータをモデルに投入しても、モデルには外部世界とやり取りする基本的な能力が欠けています。では、モデルにリアルタイムで文脈に応じた外部システムとの対話能力を与えるにはどうすればよいでしょうか？ファンクション、エクステンション、データストア、プラグインはすべて、モデルにこの重要な機能を提供する方法です。

様々な名前で呼ばれていますが、ツールは基盤モデルと外部世界との間のリンクを作成するものです。外部システムやデータへのこのリンクにより、エージェントはより幅広いタスクを実行し、より正確で信頼性の高い方法で行うことができます。例えば、ツールはエージェントがスマートホーム設定の調整、カレンダーの更新、データベースからのユーザー情報の取得、特定の指示セットに基づくメールの送信などを可能にします。

本稿執筆時点では、Googleモデルが対話できる主要なツールタイプは3つあります：エクステンション、ファンクション、データストアです。エージェントにツールを装備することで、世界を理解するだけでなく、それに対して行動する膨大な可能性を解き放ち、新しいアプリケーションや可能性の扉を開きます。

### エクステンション

エクステンションを理解する最も簡単な方法は、APIとエージェントの間のギャップを標準化された方法で埋めるものと考えることです。これにより、エージェントは基礎となる実装に関係なく、APIをシームレスに実行できます。ユーザーが航空券を予約するのを手助けするという目標でエージェントを構築したとしましょう。Google Flights APIを使用して航空便情報を取得したいことは分かっていますが、エージェントにこのAPIエンドポイントへの呼び出しをどのように行わせるか確信が持てません。

![図3：エージェントは外部APIとどのように対話するか？]

一つのアプローチは、受信ユーザークエリを取得し、関連情報を解析してからAPIコールを行うカスタムコードを実装することです。例えば、航空券予約のユースケースでは、ユーザーが「オースティンからチューリッヒへの便を予約したい」と述べるかもしれません。このシナリオでは、カスタムコードソリューションはAPIコールを試みる前に、ユーザークエリから「オースティン」と「チューリッヒ」を関連エンティティとして抽出する必要があります。しかし、ユーザーが「チューリッヒへの便を予約したい」と言って出発都市を提供しなかった場合はどうなるでしょう？必要なデータがないとAPIコールは失敗し、このようなエッジケースやコーナーケースに対応するためにさらに多くのコードを実装する必要が出てきます。このアプローチは拡張性がなく、実装されたカスタムコードの範囲外のシナリオで簡単に破綻する可能性があります。

より堅牢なアプローチはエクステンションを使用することです。エクステンションはエージェントとAPIの間のギャップを埋めることで：

1. 例を使ってAPIエンドポイントの使用方法をエージェントに教えます。
2. APIエンドポイントを正常に呼び出すために必要な引数やパラメータをエージェントに教えます。

![図4：エクステンションはエージェントを外部APIに接続する]

エクステンションはエージェントとは独立して作成できますが、エージェントの設定の一部として提供する必要があります。エージェントは実行時にモデルと例を使用して、どのエクステンション（もしあれば）がユーザーのクエリを解決するのに適しているかを決定します。これはエクステンションの主要な強みである組み込み例タイプを強調しており、エージェントがタスクに最も適切なエクステンションを動的に選択できるようにします。

![図5：エージェント、エクステンション、APIの間の1対多の関係]

これはソフトウェア開発者がユーザーの問題を解決する際にどのAPIエンドポイントを使用するかを決定するのと同じように考えてください。ユーザーが航空券を予約したい場合、開発者はGoogle Flights APIを使用するかもしれません。ユーザーが自分の位置に対して最寄りのコーヒーショップを知りたい場合、開発者はGoogle Maps APIを使用するかもしれません。同じように、エージェント/モデルスタックは既知のエクステンションのセットを使用して、ユーザーのクエリに最適なものを決定します。

エクステンションの実際の動きを見たい場合は、設定 > エクステンションに移動し、テストしたいエクステンションを有効にすることで、Geminiアプリケーションで試すことができます。例えば、Google Flightsエクステンションを有効にしてから、「オースティンからチューリッヒへの来週金曜日出発の便を表示して」とGeminiに尋ねることができます。

#### サンプルエクステンション

エクステンションの使用を簡素化するために、Googleはプロジェクトに迅速にインポートして最小限の設定で使用できるいくつかのすぐに使えるエクステンションを提供しています。例えば、スニペット1のコードインタプリタエクステンションは、自然言語記述からPythonコードを生成して実行することができます。

```python
import vertexai
import pprint
PROJECT_ID = "YOUR_PROJECT_ID"
REGION = "us-central1"
vertexai.init(project=PROJECT_ID, location=REGION)
from vertexai.preview.extensions import Extension
extension_code_interpreter = Extension.from_hub("code_interpreter")
CODE_QUERY = """Write a python method to invert a binary tree in O(n) time."""
response = extension_code_interpreter.execute(
  operation_id = "generate_and_execute",
  operation_params = {"query": CODE_QUERY}
  )
print("Generated Code:")
pprint.pprint({response['generated_code']})
# 上記のスニペットは以下のコードを生成します。
```

```
生成されたコード：
class TreeNode:
  def __init__(self, val=0, left=None, right=None):
    self.val = val
    self.left = left
    self.right = right

def invert_binary_tree(root):
    """
    二分木を反転させます。
    引数：
        root: 二分木のルート
    戻り値：
        反転した二分木のルート
    """
    if not root:
        return None
    # 左右の子を再帰的に入れ替える
    root.left, root.right = 
invert_binary_tree(root.right), invert_binary_tree(root.left)
    return root
# 使用例：
# サンプル二分木を構築
root = TreeNode(4)
root.left = TreeNode(2)
root.right = TreeNode(7)
root.left.left = TreeNode(1)
root.left.right = TreeNode(3)
root.right.left = TreeNode(6)
root.right.right = TreeNode(9)
# 二分木を反転
inverted_root = invert_binary_tree(root)
```

スニペット1. コードインタプリタエクステンションはPythonコードを生成して実行できます

要約すると、エクステンションはエージェントが外部世界を様々な方法で認識し、対話し、影響を与える方法を提供します。これらのエクステンションの選択と呼び出しは、エクステンション設定の一部として定義された例の使用によって導かれます。

### ファンクション

ソフトウェアエンジニアリングの世界では、ファンクションは特定のタスクを達成し、必要に応じて再利用できる自己完結型のコードモジュールとして定義されています。ソフトウェア開発者がプログラムを作成する際、様々なタスクを実行するために多くのファンクションを作成することがよくあります。また、function_aとfunction_bのどちらを呼び出すかの論理や、期待される入力と出力も定義します。

ファンクションはエージェントの世界でも非常に似たように機能しますが、ソフトウェア開発者の代わりにモデルを使うことができます。モデルは既知のファンクションのセットを取り、その仕様に基づいて各ファンクションをいつ使用するか、そしてそのファンクションにはどのような引数が必要かを決定できます。ファンクションはエクステンションといくつかの点で異なります。最も顕著な違いは：

1. モデルはファンクションとその引数を出力しますが、実際のAPIコールは行いません。
2. ファンクションはクライアント側で実行され、エクステンションはエージェント側で実行されます。

再びGoogle Flightsの例を使うと、ファンクションのシンプルなセットアップは図7のようになるでしょう。

![図7：ファンクションは外部APIとどのように対話するか？]

ここでの主な違いは、ファンクションもエージェントもGoogle Flights APIと直接対話しないということです。では、APIコールは実際にどのように行われるのでしょうか？

ファンクションでは、実際のAPIエンドポイントを呼び出す論理と実行は、エージェントから離れ、図8と図9に示すようにクライアント側アプリケーションに戻されます。これにより、開発者はアプリケーションのデータフローをより細かく制御できます。開発者がエクステンションよりもファンクションを選択する理由はたくさんありますが、いくつかの一般的なユースケースは次のとおりです：

- APIコールが直接エージェントアーキテクチャフロー外のアプリケーションスタックの別のレイヤー（ミドルウェアシステム、フロントエンドフレームワークなど）で行われる必要がある場合
- エージェントがAPIを直接呼び出すことを妨げるセキュリティまたは認証の制限がある場合（例：APIがインターネットに公開されていない、またはエージェントインフラストラクチャでアクセスできない）
- エージェントがリアルタイムでAPIコールを行うことを妨げるタイミングや操作順序の制約がある場合（バッチ操作、人間介在のレビューなど）
- エージェントが実行できない追加のデータ変換ロジックをAPI応答に適用する必要がある場合。例えば、返される結果の数を制限するためのフィルタリングメカニズムを提供しないAPIエンドポイントを考えてみてください。クライアント側でファンクションを使用することで、開発者はこれらの変換を行うための追加の機会が得られます。
- 開発者がAPIエンドポイント用の追加インフラストラクチャをデプロイせずにエージェント開発を反復したい場合（つまり、ファンクションコーリングはAPIの「スタブ」のように機能できる）

図8に示すように、二つのアプローチ間の内部アーキテクチャの違いは微妙ですが、追加の制御と外部インフラストラクチャからの切り離された依存関係により、ファンクションコーリングは開発者にとって魅力的な選択肢となります。

![図8：エクステンションとファンクションコーリングのクライアント対エージェント側の制御の区別]

#### ユースケース

モデルを使用してファンクションを呼び出し、エンドユーザーの複雑なクライアント側実行フローを処理することができます。この場合、エージェント開発者はAPIの実行を言語モデルに管理させたくない（エクステンションの場合のように）かもしれません。休暇旅行を予約したいユーザーと対話するための旅行コンシェルジュとしてエージェントが訓練されている次の例を考えてみましょう。目標は、ミドルウェアアプリケーションでユーザーの旅行計画のために画像、データなどをダウンロードするために使用できる都市のリストをエージェントに生成させることです。ユーザーは次のように言うかもしれません：

「家族でスキー旅行に行きたいのですが、どこに行けばいいかわかりません。」

モデルへの典型的なプロンプトでは、出力は次のようになるかもしれません：

ここに家族でのスキー旅行を検討できる都市のリストがあります：

- クレステッドビュート、コロラド州、米国
- ウィスラー、ブリティッシュコロンビア州、カナダ
- ツェルマット、スイス

上記の出力には必要なデータ（都市名）が含まれていますが、解析するには理想的な形式ではありません。ファンクションコーリングを使用すると、モデルに出力を構造化されたスタイル（JSONなど）で形式化することを教えることができ、別のシステムが解析するのに便利です。ユーザーからの同じ入力プロンプトを与えられた場合、ファンクションからのJSONサンプル出力はスニペット5のようになるでしょう。

```
function_call {
  name: "display_cities"
  args: {
    "cities": ["Crested Butte", "Whistler", "Zermatt"],
    "preferences": "skiing"
    }
}
```

スニペット5. 都市リストとユーザー設定を表示するためのサンプルファンクションコールペイロード

このJSONペイロードはモデルによって生成され、クライアント側サーバーに送信されて、私たちが望むことを実行します。この特定のケースでは、Google Places APIを呼び出して、モデルによって提供された都市を取得し画像を検索し、それらを書式設定されたリッチコンテンツとしてユーザーに提供します。図9の上記の対話を段階的に示すシーケンス図を考えてみてください。

![図9：ファンクションコールのライフサイクルを示すシーケンス図]

図9の例の結果は、モデルがGoogle Places APIを呼び出すためにクライアント側UIに必要なパラメータを「穴埋め」するために活用されることです。クライアント側UIは、モデルが返したファンクションで提供されたパラメータを使用して、実際のAPI呼び出しを管理します。これはファンクションコーリングの一つのユースケースに過ぎませんが、他にも考慮すべきシナリオがあります：

- コードで使用できるファンクションを言語モデルに提案させたいが、認証情報をコードに含めたくない場合。ファンクションコーリングはファンクションを実行しないため、ファンクション情報と共に認証情報をコードに含める必要はありません。
- 数秒以上かかる可能性のある非同期操作を実行している場合。これらのシナリオはファンクションコーリングとうまく機能します。なぜなら、それは非同期操作だからです。
- ファンクションコールとその引数を生成するシステムとは異なるデバイスでファンクションを実行したい場合。

ファンクションについて覚えておくべき重要なことは、APIコールの実行だけでなく、アプリケーション全体のデータフローも開発者により多くの制御を提供することを目的としているということです。図9の例では、開発者はエージェントが将来取るかもしれないアクションには関係ないため、APIの情報をエージェントに返さないことを選択しました。しかし、アプリケーションのアーキテクチャに基づいて、将来の推論、論理、およびアクション選択に影響を与えるために外部APIコールデータをエージェントに返すことは理にかなっているかもしれません。最終的には、特定のアプリケーションに適したものを選択するのはアプリケーション開発者次第です。

#### ファンクションのサンプルコード

スキー休暇シナリオの上記の出力を実現するために、gemini-1.5-flash-001モデルでこれが機能するように各コンポーネントを構築しましょう。

まず、display_citiesファンクションを単純なPythonメソッドとして定義します。

```python
def display_cities(cities: list[str], preferences: Optional[str] = None):
 """ユーザーの検索クエリと好みに基づいて都市のリストを提供します。
   引数:
    preferences (str): 検索のためのユーザーの好み（スキー、ビーチ、レストラン、BBQなど）。
    cities (list[str]): ユーザーに推奨される都市のリスト。
   戻り値:
    list[str]: ユーザーに推奨される都市のリスト。
   """
   return cities
```

スニペット6. 都市のリストを表示するファンクションのサンプルPythonメソッド。

次に、モデルをインスタンス化し、ツールを構築し、ユーザーのクエリとツールをモデルに渡します。以下のコードを実行すると、コードスニペットの下部に示すような出力が得られます。

```python
from vertexai.generative_models import GenerativeModel, Tool, FunctionDeclaration
model = GenerativeModel("gemini-1.5-flash-001")
display_cities_function = FunctionDeclaration.from_func(display_cities)
tool = Tool(function_declarations=[display_cities_function])
message = "家族でスキー旅行に行きたいのですが、どこに行けばいいかわかりません。"
res = model.generate_content(message, tools=[tool])
print(f"ファンクション名: {res.candidates[0].content.parts[0].function_call.name}")
print(f"ファンクション引数: {res.candidates[0].content.parts[0].function_call.args}")
> ファンクション名: display_cities
> ファンクション引数: {'preferences': 'skiing', 'cities': ['Aspen', 'Vail', 'Park City']}
```

スニペット7. ツールを構築し、ユーザークエリと共にモデルに送信し、ファンクションコールを実行できるようにする

要約すると、ファンクションはアプリケーション開発者にデータフローとシステム実行に対する細かい制御を提供する枠組みを提供し、重要な入力生成のためにエージェント/モデルを効果的に活用します。開発者は特定のアプリケーションアーキテクチャの要件に基づいて、外部データを返すことでエージェントを「ループ内に保つ」か、あるいは省略するかを選択的に選ぶことができます。

### データストア

言語モデルを訓練データを含む膨大な書籍の図書館と想像してみてください。しかし、継続的に新しい本を取得する図書館とは異なり、この図書館は静的であり、最初に訓練されたナレッジのみを保持しています。これは課題を提示します。なぜなら、実世界の知識は常に進化しているからです。データストアはより動的で最新の情報へのアクセスを提供することで、この制限に対処し、モデルの応答が事実性と関連性を維持することを保証します。

開発者がスプレッドシートやPDFなどの形で少量の追加データをモデルに提供する必要があるという一般的なシナリオを考えてみましょう。

![図10：エージェントは構造化データと非構造化データとどのように対話できるか？]

データストアを使用すると、開発者は時間のかかるデータ変換、モデルの再訓練、または微調整の必要なしに、元の形式で追加データをエージェントに提供できます。データストアは入力文書をエージェントが次のアクションやユーザーへの応答を補完するために必要な情報を抽出するために使用できるベクトルデータベース埋め込みのセットに変換します。

![図11：データストアはエージェントを様々なタイプの新しいリアルタイムデータソースに接続する]

#### 実装と応用

生成AIエージェントのコンテキストでは、データストアは通常、開発者がランタイムでエージェントにアクセスさせたいベクトルデータベースとして実装されます。ここではベクトルデータベースについて詳しく取り上げませんが、理解すべき重要なポイントは、これらが提供されたデータのベクトル埋め込み、つまり高次元ベクトルまたは数学的表現の形式でデータを格納するということです。近年、言語モデルとデータストアの最も広く使用されている例の一つは、検索拡張生成（RAG）ベースのアプリケーションの実装です。これらのアプリケーションは、モデルに以下のような様々な形式のデータへのアクセスを提供することで、モデルの知識の幅と深さを基盤訓練データを超えて拡張しようとしています：

- ウェブサイトコンテンツ
- PDF、Wordドキュメント、CSV、スプレッドシートなどの形式の構造化データ
- HTML、PDF、TXTなどの形式の非構造化データ

![図12：エージェントとデータストアの間の1対多の関係。データストアは様々なタイプの事前インデックス化されたデータを表す]

各ユーザーリクエストとエージェント応答ループの基本的なプロセスは、一般的に図13のようにモデル化されています。

1. ユーザークエリが埋め込みモデルに送信され、クエリの埋め込みが生成される
2. クエリの埋め込みはSCaNNなどのマッチングアルゴリズムを使用してベクトルデータベースの内容と照合される
3. 一致したコンテンツがテキスト形式でベクトルデータベースから取得され、エージェントに送り返される
4. エージェントはユーザークエリと取得されたコンテンツの両方を受け取り、応答またはアクションを策定する
5. 最終的な応答がユーザーに送信される

![図13：RAGベースのアプリケーションにおけるユーザーリクエストとエージェント応答のライフサイクル]

最終的な結果は、エージェントがベクトル検索を通じてユーザーのクエリを既知のデータストアと照合し、元のコンテンツを取得し、さらに処理するためにオーケストレーションレイヤーとモデルに提供することができるアプリケーションです。次のアクションはユーザーに最終的な回答を提供するか、あるいは結果をさらに絞り込むために追加のベクトル検索を実行することかもしれません。

ReAct推論/計画を持つRAGを実装するエージェントとの対話例は図14で見ることができます。

![図14：ReAct推論/計画によるRAGベースのアプリケーションの例]

### ツールの要約

要約すると、エクステンション、ファンクション、データストアはランタイムでエージェントが使用できるいくつかの異なるツールタイプを構成しています。それぞれに独自の目的があり、エージェント開発者の裁量に応じて一緒に使用することも独立して使用することもできます。

| エクステンション | ファンクションコーリング | データストア |
|----------------|------------------------|-------------|
| **実行** | エージェント側実行 | クライアント側実行 | エージェント側実行 |
| **ユースケース** | • 開発者がAPIエンドポイントとの対話をエージェントに制御させたい<br>• ネイティブの既製エクステンション（Vertex Search、Code Interpreterなど）を活用する場合に有用<br>• マルチホップ計画とAPI呼び出し（次のエージェントアクションが前のアクション/API呼び出しの出力に依存する） | • セキュリティまたは認証の制限によりエージェントがAPIを直接呼び出せない<br>• エージェントがリアルタイムでAPIコールを行うことを妨げるタイミングや操作順序の制約（バッチ操作、人間介在のレビューなど）<br>• インターネットに公開されていない、またはGoogleシステムでアクセスできないAPI | 開発者が次のようなデータタイプで検索拡張生成（RAG）を実装したい：<br>• 事前インデックス化されたドメインとURLからのウェブサイトコンテンツ<br>• PDF、Wordドキュメント、CSV、スプレッドシートなどの形式の構造化データ<br>• リレーショナル/非リレーショナルデータベース<br>• HTML、PDF、TXTなどの形式の非構造化データ |

## 対象を絞った学習によるモデルパフォーマンスの向上

モデルを効果的に使用する上で重要な側面は、特に本番環境でツールを大規模に使用する際に、出力を生成する際に適切なツールを選択する能力です。一般的な訓練はモデルがこのスキルを開発するのに役立ちますが、実世界のシナリオでは訓練データを超えた知識が必要になることがよくあります。これは、基本的な料理スキルと特定の料理のマスターの違いのようなものです。どちらも基本的な料理の知識が必要ですが、後者はより微妙な結果を得るためのターゲットを絞った学習が必要です。

モデルがこのタイプの特定の知識にアクセスできるよう支援するために、いくつかのアプローチが存在します：

- コンテキスト内学習：この方法は、汎用モデルに推論時にプロンプト、ツール、および少数のショット例を提供し、特定のタスクに対してどのようにそしていつそれらのツールを使用すべきか「その場で」学習できるようにします。ReActフレームワークは自然言語でのこのアプローチの例です。

- 検索ベースのコンテキスト内学習：この技術は、外部メモリから最も関連する情報、ツール、および関連する例を取得することで、モデルプロンプトを動的に埋めます。これの例としては、Vertex AIエクステンションの「Example Store」や、前述のデータストアRAGベースのアーキテクチャがあります。

- 微調整ベースの学習：この方法は、推論前に特定の例の大きなデータセットを使用してモデルをトレーニングすることを含みます。これにより、モデルはユーザークエリを受信する前に特定のツールをいつどのように適用するかを理解するのに役立ちます。

各ターゲットを絞った学習アプローチに関する追加の洞察を提供するために、料理のアナロジーに戻りましょう。

- シェフが特定のレシピ（プロンプト）、いくつかの主要な材料（関連ツール）、および顧客からのいくつかの料理例（少数のショット例）を受け取ったと想像してください。この限られた情報とシェフの一般的な料理知識に基づいて、彼らはレシピと顧客の好みに最も近い料理を「その場で」作る方法を理解する必要があります。これがコンテキスト内学習です。

- 今度は様々な材料や料理本（例とツール）でいっぱいの食材棚（外部データストア）を持つキッチンにいるシェフを想像してみましょう。シェフは食材棚から材料と料理本を動的に選び、顧客のレシピと好みにより適合できるようになりました。これにより、シェフは既存の知識と新しい知識の両方を活用して、より情報に基づいた洗練された料理を作ることができます。これが検索ベースのコンテキスト内学習です。

- 最後に、シェフを新しい料理または料理のセット（特定の例の大きなデータセットでの事前トレーニング）を学ぶために学校に送り返したとします。これにより、シェフは将来の未見の顧客レシピをより深い理解でアプローチできます。このアプローチは、シェフが特定の料理（知識ドメイン）で優れたいと望む場合に最適です。これが微調整ベースの学習です。

これらのアプローチはそれぞれ、速度、コスト、およびレイテンシーの点で独自の利点と欠点を提供します。しかし、エージェントフレームワークでこれらの技術を組み合わせることにより、様々な強みを活用し弱点を最小化し、より堅牢で適応性のあるソリューションを実現できます。

## LangChainによるエージェントクイックスタート

実際の実行可能な例としてエージェントを示すために、LangChainとLangGraphライブラリを使用した簡単なプロトタイプを構築しましょう。これらの人気のあるオープンソースライブラリを使用すると、ユーザーは論理、推論、およびツール呼び出しのシーケンスを「チェーン」してユーザーのクエリに答えるカスタムエージェントを構築できます。スニペット8に示すように、gemini-1.5-flash-001モデルといくつかの単純なツールを使用して、ユーザーからのマルチステージクエリに答えましょう。

使用するツールはSerpAPI（Google検索用）とGoogle Places APIです。スニペット8のプログラムを実行すると、スニペット9にサンプル出力が表示されます。

```python
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from langchain_community.utilities import SerpAPIWrapper
from langchain_community.tools import GooglePlacesTool
os.environ["SERPAPI_API_KEY"] = "XXXXX"
os.environ["GPLACES_API_KEY"] = "XXXXX"
@tool
def search(query: str):
   """SerpAPIを使ってGoogle検索を実行します。"""
   search = SerpAPIWrapper()
   return search.run(query)
@tool
def places(query: str):
   """Google Places APIを使ってGoogle Placesクエリを実行します。"""
   places = GooglePlacesTool()
   return places.run(query)
model = ChatVertexAI(model="gemini-1.5-flash-001")
tools = [search, places]
query = "テキサス・ロングホーンズは先週フットボールで誰と試合しましたか？相手チームのスタジアムの住所は何ですか？"
agent = create_react_agent(model, tools)
input = {"messages": [("human", query)]}
for s in agent.stream(input, stream_mode="values"):
   message = s["messages"][-1]
   if isinstance(message, tuple):
      print(message)
   else:
      message.pretty_print()
```

スニペット8. ツールを持つLangChainとLangGraphベースのエージェントのサンプル

```
=============================== Human Message ================================
テキサス・ロングホーンズは先週フットボールで誰と試合しましたか？相手チームのスタジアムの住所は何ですか？
================================= Ai Message =================================
Tool Calls: search
Args:
   query: Texas Longhorns football schedule
================================ Tool Message ================================
Name: search
{...Results: "NCAA Division I Football, Georgia, Date..."}
================================= Ai Message =================================
テキサス・ロングホーンズは先週ジョージア・ブルドッグスと試合しました。
Tool Calls: places
Args:
   query: Georgia Bulldogs stadium
================================ Tool Message ================================
Name: places
{...Sanford Stadium Address: 100 Sanford...}
================================= Ai Message =================================
ジョージア・ブルドッグスのスタジアムの住所は100 Sanford Dr, Athens, GA 30602, USAです。
```

スニペット9. スニペット8のプログラムの出力

これはかなり単純なエージェントの例ですが、特定の目標を達成するために協力して機能するモデル、オーケストレーション、およびツールの基本的なコンポーネントを示しています。最後のセクションでは、これらのコンポーネントがVertex AIエージェントやGenerative PlaybooksなどのGoogle規模の管理製品でどのように組み合わされるかを探ります。

## Vertex AIエージェントでの本番アプリケーション

このホワイトペーパーではエージェントの中核コンポーネントを探求しましたが、本番グレードのアプリケーションを構築するには、ユーザーインターフェース、評価フレームワーク、継続的改善メカニズムなどの追加ツールとそれらを統合する必要があります。GoogleのVertex AIプラットフォームは、前述した基本的な要素をすべて備えた完全に管理されたソリューションを提供しています。

Vertex AIエージェントは、生成AIエージェントを構築、デプロイ、管理するための統合プラットフォームです。これは以下のコンポーネントで構成されています：

1. Geminiモデル - ユーザーリクエストを処理し、適切な応答を生成する
2. ツール（データストア、エクステンション、ファンクション）- エージェントが外部データやサービスと統合するために必要
3. オーケストレーションレイヤー - 認知アーキテクチャ（ReAct、Chain of Thought）を実装
4. デプロイメントインフラストラクチャ - スケーラブルでセキュアな環境

Vertex AIエージェントは、テキスト入力とテキスト応答をサポートし、データストアの統合、アシスタントAPIとの統合、継続的なセッション管理などの機能も提供します。このプラットフォームにより、企業や開発者は堅牢で信頼性の高いエージェントを迅速に構築し、デプロイすることができます。

## まとめ

エージェントは、単なる大規模言語モデルを超えた可能性を提供します。ツール、データストア、認知アーキテクチャを統合することで、エージェントは実世界の問題に対処し、ユーザーのために複雑なタスクを実行できます。この技術の発展に伴い、エージェントはより洗練され、より自律的になり、より幅広いアプリケーションで活用されるようになるでしょう。

Google Cloudのエージェントテクノロジーを探索して、組織がどのようにエージェントを活用して新しい可能性を開拓できるかを確認することをお勧めします。Vertex AIは、エージェントテクノロジーを民主化し、世界中の開発者がこれらの強力なツールを活用できるようにすることを目指しています。

最も基本的な形では、生成AIエージェントは、世界を観察し、利用可能なツールを使用して行動することにより、目標を達成しようとするアプリケーションとして定義できます。エージェントは自律的であり、特に達成すべき適切な目標や目的が提供されている場合、人間の介入なしに独立して行動できます。エージェントは目標達成へのアプローチにおいて積極的でもあります。人間からの明示的な指示セットがなくても、エージェントは最終目標を達成するために次に何をすべきかを推論できます。AIにおけるエージェントの概念は非常に一般的で強力ですが、このホワイトペーパーでは、本稿執筆時点で生成AIモデルが構築可能な特定タイプのエージェントに焦点を当てています。

エージェントの内部動作を理解するために、まずエージェントの行動、アクション、意思決定を駆動する基本的なコンポーネントを紹介しましょう。これらのコンポーネントの組み合わせは認知アーキテクチャと呼ばれ、これらのコンポーネントを組み合わせることで多くの認知アーキテクチャを実現できます。コア機能に焦点を当てると、図1に示すように、エージェントの認知アーキテクチャには3つの本質的なコンポーネントがあります。

![図1：一般的なエージェントアーキテクチャとコンポーネント]

### モデル

エージェントの範囲内では、モデルとはエージェントプロセスの中央意思決定者として使用される言語モデル（LM）を指します。エージェントによって使用されるモデルは、ReAct、Chain-of-Thought、Tree-of-Thoughtsなどの指示ベースの推論と論理フレームワークに従うことができる任意のサイズ（小/大）の1つまたは複数のLMとなります。モデルは、特定のエージェントアーキテクチャのニーズに基づいて、汎用、マルチモーダル、または微調整されたものとなります。最良の本番結果を得るためには、目的のエンドアプリケーションに最適なモデルを活用し、理想的には認知アーキテクチャで使用予定のツールに関連するデータシグネチャで訓練されたモデルを使用するべきです。

重要なことに、モデルは通常、エージェントの特定の構成設定（ツールの選択、オーケストレーション/推論のセットアップなど）で訓練されていません。ただし、特定のツールや様々なコンテキストでの推論ステップを使用するエージェントのインスタンスなど、エージェントの機能を示す例をモデルに提供することで、エージェントのタスクに対するモデルをさらに洗練させることも可能です。

### ツール

基盤モデルは、テキストや画像の生成において印象的ですが、外部世界とのインタラクション能力がないという制約があります。ツールはこのギャップを埋め、エージェントが外部データやサービスとやり取りし、基礎となるモデル単体を超えた幅広いアクションを可能にします。ツールは様々な形式を取り、複雑さの程度も異なりますが、通常はGET、POST、PATCH、DELETEなどの一般的なウェブAPIメソッドに準拠しています。

例えば、ツールはデータベース内の顧客情報を更新したり、エージェントがユーザーに提供する旅行推奨に影響を与える天気データを取得したりできます。ツールを使用することで、エージェントは実世界の情報にアクセスして処理できます。これにより、検索拡張生成（RAG）のような、より専門化されたシステムをサポートすることが可能になり、基盤モデル単体で達成できる範囲を大幅に拡張します。ツールについては後で詳しく説明しますが、最も重要なことは、ツールがエージェントの内部能力と外部世界の間のギャップを埋め、より広範な可能性を解き放つことです。

### オーケストレーションレイヤー

オーケストレーションレイヤーは、エージェントが情報を取り込み、内部推論を実行し、その推論を使用して次のアクションや決定に影響を与える循環プロセスを表します。一般的に、このループはエージェントが目標または停止点に達するまで継続します。オーケストレーションレイヤーの複雑さは、エージェントとそれが実行するタスクによって大きく異なります。一部のループは簡単な計算と決定ルールに基づくものですが、他のループは連鎖論理を含んだり、追加の機械学習アルゴリズムを含んだり、あるいは他の確率的推論技術を実装したりします。エージェントオーケストレーションレイヤーの詳細な実装については、認知アーキテクチャのセクションで詳しく説明します。

### エージェントとモデルの比較

エージェントとモデルの違いをより明確に理解するために、次の表を参考にしてください：

| モデル | エージェント |
|-------|-------------|
| 知識は訓練データで利用可能なものに限定される | ツールを介した外部システムとの接続により知識が拡張される |
| ユーザークエリに基づく単一の推論/予測。モデルに明示的に実装されていない限り、セッション履歴や継続的なコンテキスト（チャット履歴など）の管理はない | ユーザークエリやオーケストレーションレイヤーでの決定に基づくマルチターン推論/予測を可能にするセッション履歴（チャット履歴など）の管理。ここでの「ターン」は、相互作用システムとエージェント間のインタラクションとして定義される（1つの受信イベント/クエリと1つのエージェント応答） |
| ネイティブなツール実装はない | ツールはエージェントアーキテクチャにネイティブに実装されている |
| ネイティブな論理レイヤーの実装はない。ユーザーは単純な質問として、または推論フレームワーク（CoT、ReActなど）を使用して複雑なプロンプトを作成し、予測のモデルを導くことができる | CoT、ReAct、またはLangChainのような他の既成のエージェントフレームワークのような推論フレームワークを使用するネイティブな認知アーキテクチャ |

### 認知アーキテクチャ：エージェントの動作原理

忙しいキッチンでシェフを想像してみてください。彼らの目標はレストランの客のために美味しい料理を作ることで、これには計画、実行、調整のサイクルが含まれます。

- 彼らは客の注文や、パントリーや冷蔵庫にある食材など、情報を収集します。
- 彼らは集めた情報に基づいて、どのような料理やフレーバープロファイルを作れるかについて内部推論を行います。
- 彼らは野菜を切る、香辛料を混ぜる、肉を焼くなど、料理を作るための行動を取ります。

プロセスの各段階で、シェフは必要に応じて調整を行い、材料が減ったり客からフィードバックを受けたりするにつれて計画を洗練し、一連の以前の結果を使用して次のアクションプランを決定します。情報摂取、計画、実行、調整のこのサイクルは、シェフが目標を達成するために採用する独自の認知アーキテクチャを表しています。

シェフと同様に、エージェントは認知アーキテクチャを使用して、情報を反復的に処理し、情報に基づいた決定を行い、前の出力に基づいて次のアクションを洗練させることで目標を達成できます。エージェント認知アーキテクチャの中核にはオーケストレーションレイヤーがあり、メモリ、状態、推論、計画を維持する責任があります。それは急速に進化するプロンプトエンジニアリングの分野と関連するフレームワークを使用して推論と計画を導き、エージェントがより効果的に環境と対話しタスクを完了できるようにします。

言語モデルのプロンプトエンジニアリングフレームワークとタスク計画の研究分野は急速に進化しており、様々な有望なアプローチを生み出しています。網羅的なリストではありませんが、本稿執筆時点で利用可能な最も一般的なフレームワークと推論手法のいくつかを紹介します：

- ReAct：言語モデルにユーザークエリについて推論し行動するための思考プロセス戦略を提供するプロンプトエンジニアリングフレームワークで、コンテキスト内の例が有る場合と無い場合があります。ReActプロンプティングは、いくつかの最先端のベースラインを上回り、LLMの人間との相互運用性と信頼性を向上させることが示されています。

- Chain-of-Thought（CoT）：中間ステップを通じて推論能力を可能にするプロンプトエンジニアリングフレームワークです。CoTには、自己一貫性、アクティブプロンプト、マルチモーダルCoTなど、特定のアプリケーションに応じて強みと弱みを持つさまざまなサブ技術があります。

- Tree-of-Thoughts（ToT）：探索や戦略的先読みタスクに適したプロンプトエンジニアリングフレームワークです。思考の連鎖プロンプティングを一般化し、言語モデルによる一般的な問題解決のための中間ステップとして機能する様々な思考の連鎖を探索できるようにします。

エージェントは上記の推論技術の1つ、または他の多くの技術を利用して、ユーザーリクエストに対する次の最適なアクションを選択できます。例えば、ReActフレームワークを使用してユーザークエリに対する正しいアクションとツールを選択するようにプログラムされたエージェントを考えてみましょう。イベントの順序は次のようになります：

1. ユーザーがエージェントにクエリを送信
2. エージェントがReActシーケンスを開始
3. エージェントはモデルにプロンプトを提供し、次のReActステップとそれに対応する出力を生成するよう依頼します：
   a. 質問：プロンプトと共に提供されるユーザークエリからの入力質問
   b. 思考：次に何をすべきかについてのモデルの考え
   c. アクション：次に取るべきアクションに関するモデルの決定
      i. ここでツール選択が発生する可能性がある
      ii. 例えば、アクションは[Flights, Search, Code, None]のいずれかとなり、最初の3つはモデルが選択できる既知のツールを表し、最後は「ツール選択なし」を表す
   d. アクション入力：ツールに提供する入力（もしあれば）に関するモデルの決定
   e. 観察：アクション/アクション入力シーケンスの結果
      i. この思考/アクション/アクション入力/観察は必要に応じてN回繰り返される可能性がある
   f. 最終回答：元のユーザークエリに対して提供するモデルの最終回答
4. ReActループが終了し、最終回答がユーザーに返される

![図2：オーケストレーションレイヤーでReAct推論を使用したエージェントの例]

図2に示すように、モデル、ツール、エージェント構成が連携して、ユーザーの元のクエリに基づいた根拠のある簡潔な回答をユーザーに提供します。モデルは事前知識に基づいて回答を推測（幻覚）することもできましたが、代わりにツール（Flights）を使用してリアルタイムの外部情報を検索しました。この追加情報がモデルに提供され、モデルは実際の事実データに基づいてより情報に基づいた決定を下し、この情報をユーザーに要約することができました。

要約すると、エージェント応答の品質は、モデルが適切なツールを選択する能力を含む、これらの様々なタスクについて推論し行動する能力と、そのツールがどの程度うまく定義されているかに直接関連します。新鮮な食材と顧客からのフィードバックに注意深いシェフが料理を作るように、エージェントは最適な結果を提供するために健全な推論と信頼性の高い情報に依存しています。次のセクションでは、エージェントが新鮮なデータと接続するさまざまな方法について詳しく説明します。

## ツール：外部世界への鍵

言語モデルは情報処理に優れていますが、実世界を直接認識し影響を与える能力が欠けています。これにより、外部システムやデータとの対話が必要な状況での有用性が制限されます。つまり、ある意味では、言語モデルはその訓練データから学んだことに限られています。しかし、どれだけ多くのデータをモデルに投入しても、モデルには外部世界とやり取りする基本的な能力が欠けています。では、モデルにリアルタイムで文脈に応じた外部システムとの対話能力を与えるにはどうすればよいでしょうか？ファンクション、エクステンション、データストア、プラグインはすべて、モデルにこの重要な機能を提供する方法です。

様々な名前で呼ばれていますが、ツールは基盤モデルと外部世界との間のリンクを作成するものです。外部システムやデータへのこのリンクにより、エージェントはより幅広いタスクを実行し、より正確で信頼性の高い方法で行うことができます。例えば、ツールはエージェントがスマートホーム設定の調整、カレンダーの更新、データベースからのユーザー情報の取得、特定の指示セットに基づくメールの送信などを可能にします。

本稿執筆時点では、Googleモデルが対話できる主要なツールタイプは3つあります：エクステンション、ファンクション、データストアです。エージェントにツールを装備することで、世界を理解するだけでなく、それに対して行動する膨大な可能性を解き放ち、新しいアプリケーションや可能性の扉を開きます。

### エクステンション

エクステンションを理解する最も簡単な方法は、APIとエージェントの間のギャップを標準化された方法で埋めるものと考えることです。これにより、エージェントは基礎となる実装に関係なく、APIをシームレスに実行できます。ユーザーが航空券を予約するのを手助けするという目標でエージェントを構築したとしましょう。Google Flights APIを使用して航空便情報を取得したいことは分かっていますが、エージェントにこのAPIエンドポイントへの呼び出しをどのように行わせるか確信が持てません。

![図3：エージェントは外部APIとどのように対話するか？]

一つのアプローチは、受信ユーザークエリを取得し、関連情報を解析してからAPIコールを行うカスタムコードを実装することです。例えば、航空券予約のユースケースでは、ユーザーが「オースティンからチューリッヒへの便を予約したい」と述べるかもしれません。このシナリオでは、カスタムコードソリューションはAPIコールを試みる前に、ユーザークエリから「オースティン」と「チューリッヒ」を関連エンティティとして抽出する必要があります。しかし、ユーザーが「チューリッヒへの便を予約したい」と言って出発都市を提供しなかった場合はどうなるでしょう？必要なデータがないとAPIコールは失敗し、このようなエッジケースやコーナーケースに対応するためにさらに多くのコードを実装する必要が出てきます。このアプローチは拡張性がなく、実装されたカスタムコードの範囲外のシナリオで簡単に破綻する可能性があります。

より堅牢なアプローチはエクステンションを使用することです。エクステンションはエージェントとAPIの間のギャップを埋めることで：

1. 例を使ってAPIエンドポイントの使用方法をエージェントに教えます。
2. APIエンドポイントを正常に呼び出すために必要な引数やパラメータをエージェントに教えます。

![図4：エクステンションはエージェントを外部APIに接続する]

エクステンションはエージェントとは独立して作成できますが、エージェントの設定の一部として提供する必要があります。エージェントは実行時にモデルと例を使用して、どのエクステンション（もしあれば）がユーザーのクエリを解決するのに適しているかを決定します。これはエクステンションの主要な強みである組み込み例タイプを強調しており、エージェントがタスクに最も適切なエクステンションを動的に選択できるようにします。

![図5：エージェント、エクステンション、APIの間の1対多の関係]

これはソフトウェア開発者がユーザーの問題を解決する際にどのAPIエンドポイントを使用するかを決定するのと同じように考えてください。ユーザーが航空券を予約したい場合、開発者はGoogle Flights APIを使用するかもしれません。ユーザーが自分の位置に対して最寄りのコーヒーショップを知りたい場合、開発者はGoogle Maps APIを使用するかもしれません。同じように、エージェント/モデルスタックは既知のエクステンションのセットを使用して、ユーザーのクエリに最適なものを決定します。

エクステンションの実際の動きを見たい場合は、設定 > エクステンションに移動し、テストしたいエクステンションを有効にすることで、Geminiアプリケーションで試すことができます。例えば、Google Flightsエクステンションを有効にしてから、「オースティンからチューリッヒへの来週金曜日出発の便を表示して」とGeminiに尋ねることができます。

#### サンプルエクステンション

エクステンションの使用を簡素化するために、Googleはプロジェクトに迅速にインポートして最小限の設定で使用できるいくつかのすぐに使えるエクステンションを提供しています。例えば、スニペット1のコードインタプリタエクステンションは、自然言語記述からPythonコードを生成して実行することができます。

```python
import vertexai
import pprint
PROJECT_ID = "YOUR_PROJECT_ID"
REGION = "us-central1"
vertexai.init(project=PROJECT_ID, location=REGION)
from vertexai.preview.extensions import Extension
extension_code_interpreter = Extension.from_hub("code_interpreter")
CODE_QUERY = """Write a python method to invert a binary tree in O(n) time."""
response = extension_code_interpreter.execute(
  operation_id = "generate_and_execute",
  operation_params = {"query": CODE_QUERY}
  )
print("Generated Code:")
pprint.pprint({response['generated_code']})
# 上記のスニペットは以下のコードを生成します。
```

```
生成されたコード：
class TreeNode:
  def __init__(self, val=0, left=None, right=None):
    self.val = val
    self.left = left
    self.right = right

def invert_binary_tree(root):
    """
    二分木を反転させます。
    引数：
        root: 二分木のルート
    戻り値：
        反転した二分木のルート
    """
    if not root:
        return None
    # 左右の子を再帰的に入れ替える
    root.left, root.right = 
invert_binary_tree(root.right), invert_binary_tree(root.left)
    return root
# 使用例：
# サンプル二分木を構築
root = TreeNode(4)
root.left = TreeNode(2)
root.right = TreeNode(7)
root.left.left = TreeNode(1)
root.left.right = TreeNode(3)
root.right.left = TreeNode(6)
root.right.right = TreeNode(9)
# 二分木を反転
inverted_root = invert_binary_tree(root)
```

スニペット1. コードインタプリタエクステンションはPythonコードを生成して実行できます

要約すると、エクステンションはエージェントが外部世界を様々な方法で認識し、対話し、影響を与える方法を提供します。これらのエクステンションの選択と呼び出しは、エクステンション設定の一部として定義された例の使用によって導かれます。

### ファンクション

ソフトウェアエンジニアリングの世界では、ファンクションは特定のタスクを達成し、必要に応じて再利用できる自己完結型のコードモジュールとして定義されています。ソフトウェア開発者がプログラムを作成する際、様々なタスクを実行するために多くのファンクションを作成することがよくあります。また、function_aとfunction_bのどちらを呼び出すかの論理や、期待される入力と出力も定義します。

ファンクションはエージェントの世界でも非常に似たように機能しますが、ソフトウェア開発者の代わりにモデルを使用します。モデルは既知のファンクションのセットから、仕様に基づいて適切なファンクションをいつ使用するか、そしてどのような引数が必要かを決定します。このようにして、AIエージェントは外部システムやデータと効果的に対話し、よりインテリジェントで適応性の高いソリューションを提供することができます。

エージェント技術は急速に進化しており、より高度なモデル、豊富なツールセット、さらに洗練されたオーケストレーション技術によって、さらに強力になっていくでしょう。私たちは今、AIエージェントの可能性が広がる新しい時代の始まりを目の当たりにしています。
