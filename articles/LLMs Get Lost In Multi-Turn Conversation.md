---
title: "LLMs Get Lost In Multi-Turn Conversation"
source: "https://arxiv.org/html/2505.06120v1"
author: Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jennifer Neville
published: 2025-05-09
created: 2025-07-16
description: 大規模言語モデル（LLM）が複数ターンの会話において著しい性能低下を示すことを実証した研究。15の主要なLLMを6つの生成タスクでテストし、シングルターンと比較してマルチターン会話で平均39%の性能低下を確認。LLMが会話の初期段階で誤った仮定を立て、早期に最終解を生成しようとする傾向があることを発見。
tags:
  - "clippings"
  - "LLM"
  - "multi-turn conversation"
  - "conversational AI"
  - "model reliability"
  - "underspecified instructions"
---

## 研究概要

本研究は、Microsoft Research、Salesforce Research、および共同研究者によって実施された、大規模言語モデル（LLM）の複数ターン会話における性能低下現象「Lost in Conversation」を体系的に実証した画期的な研究です。

## 主要な発見

### 1. 性能低下の規模

- **15の主要LLM**（GPT-4、Claude 3、Gemini 2.5、Llama、Phi-4など）を検証
- **6つの生成タスク**で評価：コード生成、データベースクエリ、API呼び出し、数学問題、データテキスト変換、要約
- **平均39%の性能低下**：シングルターン（90%）からマルチターン（65%）への移行時

### 2. 「Lost in Conversation」現象の特徴

- **信頼性の劇的な低下**：マルチターン設定での信頼性が112%低下（2倍以上悪化）
- **能力（Aptitude）の維持**：能力低下は16%程度で比較的軽微
- **モデルサイズに関係なく発生**：小規模モデル（8B）から大規模モデル（300B+）まで一様に影響

## 実験手法：シャーディング（Sharding）

### シャーディングプロセス

1. **完全指定型の指示**を**シャード（断片）**に分解
2. 各シャードは元の指示の一部分を含む
3. 会話の各ターンで1つずつシャードを開示

例：

- 元の指示：「JayがSisterとの雪合戦のために雪玉を作っています。1時間に20個作れますが、15分ごとに2個溶けます。60個になるまでどのくらいかかりますか？」
- シャード化：
  - シャード1：「Jayが雪合戦の準備にどのくらい時間がかかりますか？」
  - シャード2：「妹との雪合戦の準備をしています」
  - シャード3：「1時間に20個の雪玉を作れます」
  - シャード4：「合計60個を目指しています」
  - シャード5：「問題は15分ごとに2個溶けることです」

## 問題の根本原因

### 1. 早期の仮定と結論

- LLMは情報が不完全な段階で最終的な解答を生成しようとする
- 誤った仮定に基づいて解答を構築し、後の修正が困難

### 2. 過去の誤答への過度な依存

- 以前の誤った回答に固執し、「答えの肥大化」が発生
- 新しい情報を適切に統合できない

### 3. 会話の中間部分の情報喪失

- 最初と最後のターンに過度に注目
- 中間のターンで提供された重要な情報を見落とす

### 4. 冗長な応答

- 過度に詳細な説明により、ユーザーの実際の要求から逸脱
- 不必要な仮定の導入

## 緩和策の効果

### 1. エージェント的介入

- **Recap（要約）**：最後に全情報を再提示 → 部分的改善
- **Snowball（雪だるま式）**：各ターンで過去の情報を累積的に再提示 → 15-20%の改善

### 2. 温度パラメータの調整

- シングルターン：温度低下で信頼性が50-80%向上
- マルチターン：温度を0.0にしても信頼性改善は限定的（約30%の不確実性が残存）

### 3. 推論モデルの限界

- o3、Deepseek-R1などの推論モデルも同様に性能低下
- 追加の計算時間は問題解決に寄与せず

## 実用的な示唆

### システム開発者向け

- ネイティブなマルチターンサポートが必要
- エージェントフレームワークだけでは不十分

### LLM開発者向け

- 能力（Aptitude）と信頼性（Reliability）の両立が必要
- 目標：マルチターン設定でU₁₀⁹⁰<15、T=1.0での安定動作

### ユーザー向け推奨事項

1. **再試行戦略**：会話が行き詰まったら新しい会話を開始
2. **情報統合**：分散した情報を一つの指示にまとめてから再度質問

## 研究の限界と今後の課題

1. **シミュレーション環境**：実際の人間との会話より単純化
2. **タスクの範囲**：分析的タスクに限定、創造的タスクは未検証
3. **言語とモダリティ**：英語のテキストのみ、多言語・マルチモーダルは未検証

## 結論

本研究は、LLMが複数ターンの会話において「迷子になる」現象を初めて体系的に実証しました。この発見は、現在のLLMの実用性に重大な制限があることを示しており、今後のモデル開発において信頼性の向上が急務であることを明らかにしています。
