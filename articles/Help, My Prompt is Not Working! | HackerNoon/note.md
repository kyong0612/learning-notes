---
title: "Help, My Prompt is Not Working! | HackerNoon"
source: "https://hackernoon.com/help-my-prompt-is-not-working"
author:
  - "Andrew Prosikhin"
published: "2025-05-12"
created: "2025-05-20"
description: |
  When your AI prompt fails, follow a step-by-step escalation: start by refining instructions, adding examples, or explanation fields. If that fails, try a different model, break prompts into parts, or as a last resort, fine-tune the model. Use this approach to save time and debug efficiently.
tags:
  - "machine-learning"
  - "ai"
  - "generative-ai"
  - "prompt-engineering"
  - "ai-prompt-debugging"
  - "llms"
  - "fine-tuning-llms"
  - "ai-prompts"
---

## AIプロンプトが機能しない場合の対処法

Andrew Prosikhin 氏による2025年5月12日の記事より。

![](https://hackernoon.imgix.net/images/Y1R5QnwdHha1bpbTUnCTTnw8G0r2-va0382w.jpeg?auto=format&fit=max&w=1024)

LLM（大規模言語モデル）が期待通りに動作しない場合、プロンプトの編集、モデルの変更、ファインチューニングなど、試すべき修正方法がいくつかあります。この記事では、それらの修正を試す順序について説明します。

### 原則V：プロンプト修正のエスカレーションラダーに従う

プロンプトが期待通りに機能しない場合、著者は以下の修正を優先順位に従って試します。

1. **指示の拡大と再表現**: 指示を明確にし、言い換え、またはプロンプト内で移動させます。重要な指示はプロンプトの最初か最後に配置すると効果的です。
2. **例の追加**: LLMは文脈内学習（入力と出力の例）によく反応します。特に小規模なモデルでは、多くのガイダンスが必要なため重要です。
3. **説明フィールドの追加**: LLMに出力JSONに「説明」フィールドを追加させると、思考プロセスを説明することになり、出力が改善される傾向があります。これにより、モデルが特定の決定を下す理由を特定し、指示や例を調整するのに役立ちます。内部ドキュメントを使用する場合は、回答の構築に使用したドキュメントのセクションを出力させることで、ハルシネーションを減らすことができます。思考連鎖（Chain-of-Thought）プロンプトも試す価値がありますが、出力の抽出が課題となることがあります。
4. **異なるモデルの使用**: モデルによって得意なタスクが異なります。AIエンジニアの仕事の一部は、利用可能なモデルの長所と短所を把握し続けることです。同じタスクに対して頻繁に異なるモデルを試すことが推奨され、自動テストとメトリクスがあると、この実験がより速く安全に行えます。
5. **単一プロンプトの複数プロンプトへの分割**: 1つのプロンプトでうまくいかない場合、2つ以上のプロンプトのシステムを試すことができます。一般的なアプローチは、責任範囲による分割と、前のプロンプトの出力をレビューするガードレールとしての新しいプロンプトの使用です。
6. **モデルのファインチューニング**: これは最後の手段として考えられます。ファインチューニングは機械学習のアプローチであり、大量のデータ収集とMLツールセットが必要になるため、小〜中規模プロジェクトでは管理のオーバーヘッドが大きくなります。また、説明可能性やロジック編集の容易さといったAIの主要な利点も減少します。
    ファインチューニングを検討するケース：
    * 他の手法で目的を達成できなかった場合。
    * 問題が非常に複雑で専門的であり、デフォルトのLLMの知識では不十分な場合。
    * 大量のユースケースがあり、低価格モデルを使用してコストを節約したい場合。
    * 低レイテンシが必要で、複数のプロンプトを連続して実行できない場合。
7. **（最終手段として）ラップトップを窓から投げる**: これは冗談ですが、フラストレーションの大きさを示唆しています。

これらのアプローチは厳密なはしごではなく、前進し続けるためのガイドロープとして意図されています。最初の3つはプロンプトエンジニアリングの範疇に入り、マルチプロンプトとファインチューニングのアプローチはそれぞれ専用の章で詳しく説明される予定です。

### 軽量アプローチ

#### 指示の追加

LLMに対してプロンプトの指示を通じて何をすべきかを再説明します。より明確な指示を追加したり、言い回しを変えたり、指示を移動させたりします。重要な指示は、プロンプトの最初か最後に配置すると効果的です。

#### 例の追加

LLMは文脈内学習（入力と出力の例）に非常によく反応します。特に小規模なモデルでは、多くのガイダンスが必要なので重要です。

```
Detect the language of the text and output it in the JSON format: {“language”: “name_of_language”}. If you don’t know the language, output “unknown” in the language field.

Example I:

Input: Hello

Output: {“language”: “English”}

Example II:

Input: EjnWcn

Output: {“language”: “Unknown”}

Text: {{text}}
```

通常1〜3つの例を使用しますが、より多くの例でパフォーマンスが向上するという証拠もあります。ただし、メンテナンスと実行コストも増加します。

#### 説明フィールドの追加

LLMは、人間と同様に、思考を説明することで恩恵を受けます。出力JSONに「explanation」フィールドを追加すると、通常、出力が向上します。これにより、モデルが特定の決定を下している理由を特定し、指示や例を調整するのにも役立ちます。
プロンプトが内部ドキュメントを使用する場合、LLMに回答の構築に使用したドキュメントのセクションを出力させるように依頼します。これにより、ハルシネーションが減少します。
[思考連鎖（Chain-of-Thought）プロンプト](https://www.promptingguide.ai/techniques/cot?ref=hackernoon.com)の使用も試すことができます。ここでの課題は、出力を適切に抽出することです。CoT推論を含む応答を処理するには、2番目のプロンプトまたは追加のコードが必要になる場合があります。

#### モデルの変更

異なるモデルは、異なるタイプのタスクで優れています。例えば、OpenAIのo3モデルはコード分析に優れていますが、安価な4oモデルの方が優れた文章を生成する傾向があります。AIエンジニアの仕事の一部は、リリースおよび更新される利用可能なモデルの長所と短所を把握し続けることです。
同じタスクに対して頻繁に異なるモデルを試してみてください。この実験は、各モデルのタスクへの「適合性」を測定するための自動テストとメトリクスがある場合に、はるかに迅速かつ安全に機能します。

### 重量アプローチ

これまでのすべてのアプローチは、試すコストが比較的低いものでした。ここからは、重量級の修正に入ります。

#### プロンプトの分割

1つのプロンプトでジョブを完了できない場合は、2つ以上のプロンプトのシステムを試してみてはどうでしょうか。これは、場合によっては効果的に機能します。一般的な2つのアプローチは次のとおりです。

* 責任範囲ごとにプロンプトを分割する。
* 前のプロンプトの出力をレビューするガードレールとして新しいプロンプトを使用する。

#### ファインチューニング

ファインチューニングは、複数のプロンプトを使用するよりもさらに重量級のアプローチです。ほとんどの問題では、最後の手段として使用されます。
ファインチューニングがほとんどの場合に推奨されない理由：ファインチューニングは基本的に、[Generative AIに適用される](https://hackernoon.com/treating-your-llm-prompts-like-code-can-save-your-ai-project?ref=hackernoon.com)機械学習アプローチです。そのため、大量のデータ収集と、Generative AIツールに加えてMLツール一式が必要であり、これは中小規模のプロジェクトでは管理するための大きなオーバーヘッドとなります。また、説明可能性やロジック編集の容易さといったAIの主要な利点も損なわれます。

ファインチューニングを検討する場合：

* 他の手法で目的を達成できなかった場合。
* 問題が非常に複雑で専門的であり、デフォルトのLLMの知識では不十分な場合。
* 大量のユースケースがあり、低価格モデルを使用してコストを節約したい場合。
* 低レイテンシが必要で、複数のプロンプトをシーケンシャルに実行できない場合。

### 結論

この記事が、プロンプトが意図したとおりに機能しない場合に実行すべき手順の順序を明確にすることを願っています。まず、通常はプロンプトエンジニアリングアプローチを試します。それが機能しない場合は、モデルを切り替えてみて、それが役立つかどうかを確認します。次のステップは、複数の相互作用するプロンプトを利用することです。最後に、他のすべての方法が失敗した場合は、ファインチューニングを検討します。

If you've enjoyed this post - subscribe for more.

#### THIS ARTICLE WAS FEATURED IN...[Terminal](https://terminal.hackernoon.com/help-my-prompt-is-not-working?ref=hackernoon)

[

Lite

](<https://hackernoon.com/lite/help-my-prompt-is-not-working?ref=hackernoon)[>

Hackernoon

](<https://hackernoon.com/archives/2025/5/12>)
