---
title: "AI時代のアーキテクトは「文脈」を設計せよ ― 非決定的なAIを制御するコンテキストモデリング"
source: "https://zenn.dev/loglass/articles/31ff1820fec6e0"
author:
  - "knih"
published: 2025-12-01
created: 2025-12-02
description: |
  生成AIをシステムに組み込んだ際の「任せきれなさ」は、プロンプトやRAGのチューニングだけでなく、AIに渡す文脈の設計不足から来ている。本稿では「コンテキストモデリング」を、焦点・境界・粒度の3軸で「AIに渡す世界」を設計することとして定義し、非決定的なAIを制御するための実践的な手法を提示する。これにより、AIに任せる範囲と人間が責任を持つ範囲の線引きが明確になる。
tags:
  - "DDD"
  - "architecture"
  - "モデリング"
  - "AIエージェント"
  - "コンテキストモデリング"
  - "プロンプトエンジニアリング"
---

## AI時代のアーキテクトは「文脈」を設計せよ ― 非決定的なAIを制御するコンテキストモデリング

### TL;DR（要約）

- 「AI任せにできない感覚」の多くはモデルではなく文脈の設計の不足から来ている

- 文脈は「焦点・境界・粒度」の3軸で分解できる

- 「コンテキストモデリング」= この3軸で「AIに渡す世界」を設計すること

- それによって、AIに任せる範囲と人間が責任を持つ範囲の線引きができる

## 1. なぜ任せきれないのか

多くの現場で以下のような状態になっている：

- 社内の資料を全部ベクトルDBに入れる

- 関連しそうなテキストを引っ張ってくる

- AIに「いい感じにまとめて」とお願いする

これでも意味はあるが、「渡し方（How）」の工夫に偏っていて、「渡すもの（What）」の設計が不十分という状態。

### 問題の本質：決定論的 vs 非決定的

従来の業務システムは「同じ入力なら同じ出力になる」という**決定論的（deterministic）**なモデルで設計されてきた。一方、LLMや強化学習エージェントは**確率モデル**として実装され、同じ入力でも毎回わずかに結果が揺らぐ**非決定的（non-deterministic）**な振る舞いを示す。

このゆらぐ層の「前後」に、設計されていない空白があることが問題の本質。この空白を埋めるのが「コンテキストモデリング」である。

## 2. 「コンテキストモデリング」とは何か

### プロンプト/コンテキストエンジニアリングとの違い

| 層 | 役割（Role） | 対象（Target） | 担当者 |
|---|---|---|---|
| **プロンプトエンジニアリング** | How to Ask（どう聞くか） | 自然言語の指示（役割・制約） | 全ユーザー |
| **コンテキストエンジニアリング** | How to Implement（どう実装するか） | 技術パラメータ（ベクトル・チャンク・検索精度） | データ／MLエンジニア |
| **コンテキストモデリング** | What to Structure（何を構造化するか） | 意味の境界（焦点・境界・粒度） | アーキテクト／PdM |

**コンテキストモデリング**とは、ひと言でいうと：

- **焦点・境界・粒度の3軸で「AIに渡す世界」を設計すること**

もう少し分解すると：

1. **焦点（Focus）** - どんな問いに答えさせたいのか

2. **境界（Boundary）** - どこまでを同じ世界として扱うか

3. **粒度（Granularity）** - 世界をどの大きさのかたまりで切るか

### Before / After で見る効果イメージ

**Before（文脈を設計しない場合）：**

- ユーザー：「ログインできません」

- → 全マニュアルを検索

- → AI：「パスワードリセット、SSOエラー、ネットワーク問題の可能性があります...（長文）」

**After（文脈を設計した場合）：**

- 【文脈】
  - 焦点: トラブルシュート（エラーコードの原因切り分け）
  - 境界: EnterpriseプランかつSSO利用が前提（ローカルログインは対象外）
  - 粒度: 「ログインできない」という問い合わせ1件（チケット単位）

- → AI：「SSO設定を以下3点で確認してください：1. IDプロバイダーの証明書期限 2. リダイレクトURLの設定 3. ユーザー属性のマッピング」

## 3. コンテキストモデリングの3つの設計軸

### 3-1. なぜ設計軸が必要なのか

AIに任せられるかどうかは、「どんなコンテキストで、どこまでをAIに渡すか」でかなり決まる。そのコンテキストを考えるときに、毎回一から考えるのは大変なので、**思考のための軸**を用意する。

### 軸の依存関係：焦点 → 境界 → 粒度

3つの軸は並列ではなく、決める順序がある：

1. **焦点が最初** - 「何を答えたいか」が決まらないと、境界も粒度も「何のために？」が宙に浮く

2. **境界が次** - 焦点が決まれば、「その問いに答えるのに必要な世界の範囲」が見えてくる

3. **粒度が最後** - 境界の中で「何を1単位とみなすか」は、境界が決まってから初めて意味を持つ

### 3-2. 焦点（Focus）：このやり取りは、どんな問いに答えようとしているのか

焦点は、「この文脈で答えたい問いの種類」を決める軸。

同じデータを見ていても、問いが違えば、欲しい答えも違う：

- 同じ売上データでも、「原因を特定したい」のか、「今後のシナリオを比べたい」のか

- 同じサポート問い合わせでも、「今すぐの対処方法」を知りたいのか、「根本原因と再発防止策」を知りたいのか

問いが混ざると、AIは全部に"そこそこ"答えようとし、結果として長くて器用だけれど、「結局何の話だったっけ？」となる。

**焦点を設計する** = 「いまは何について答えるターンなのか」を明示する

- この呼び出しはトラブルシュートのため

- この呼び出しは契約条件の説明のため

- この呼び出しは意思決定のための論点整理のため

技術的には「インテント分類」と似ているが、コンテキストモデリングではそれをもう少し広く、「問いごとにコンテキストをスイッチする仕組み」として扱う。

### 3-3. 境界（Boundary）：どこまでを同じ世界として扱うか

境界は、「どの範囲を、この文脈の"有効な世界"と見なすか」の軸。

プロダクト全体を思い浮かべるとき、頭の中には全プラン・全機能・全オプション・全リージョンがそろった理論上の世界が広がっている。でも、現実には、ひとりのユーザーやひとつの案件にとっての「世界」は、そのごく一部：

- いま契約しているプラン

- 実際に有効化されている機能

- 合意しているサポート範囲やリードタイム

境界が曖昧なままAIに情報を渡すと、そのユーザーには関係ない機能の話、契約上はサポート外の前提、将来の可能性としてしか存在しないオプションまで、一律に同じ文脈として扱ってしまう。

**境界を設計する** = 「この文脈では、どこまでを同じ世界として良しとするか」を決める

#### 境界設計は認可（Authorization）設計の前提になる

「境界」をどう引くかによって、RAGにおける「認可制御」に大きく影響する。マルチテナントのサポートシステムで境界設計が甘いと、A社の担当者がB社の問い合わせ履歴を参照できてしまうといった事故が起こりえる。

境界が明確であれば、そのままデータガバナンスのルールとしてコードにしやすくなる。セキュリティ設計とコンテキスト設計は、「あとから別チームが付け足す」ものではなく、同じモデルの上で一緒に議論すべきテーマ。

### 3-4. 粒度（Granularity）：何を1単位の状況とみなすか

粒度は、「世界をどの大きさのかたまりで切るか」の軸。

- 売上を「1取引」単位で見るのか、「1顧客」単位で見るのか、「1四半期」単位で見るのか

- インシデントを「1回の障害」なのか、「根本原因ごとのまとまり」なのか

- 会話を「1メッセージ」なのか、「1往復」なのか、「解決までのスレッド」なのか

粒度の取り方がバラバラだと、AIに渡す情報もバラバラになる。1回の問いに対して、過剰に大きいかたまり（全部入りのログ）を渡してしまったり、逆に細切れすぎて本質が見えなかったりする。

**粒度を設計する** = 「このユースケースでは、何を1まとまりの状況とみなすか」を先に決める

この「1まとまり」が決まっていると、どの単位の履歴をAIに渡すべきか、どの単位で類似ケースを探すべきか、「この回答は何に基づいているか」をあとから説明するときの単位がそろってくる。

### 3-5. （例）CS（カスタマーサポート）自動回答に3つの設計軸を当てはめると

**焦点：** 問い合わせを「トラブルシュート」「機能の使い方」「契約相談」などに分類し、カテゴリごとに参照するケースやテンプレートを切り替える

**境界：** ユーザーの契約プランや有効なオプションをもとに、「このユーザーにとっての世界」を決め、その境界の内側の情報だけをAIに渡す

**粒度：** 「1件の問い合わせ〜クローズまで」を1ケースとみなし、ケース単位で類似事例を検索し、要約をAIに渡す

**ありがちなアンチパターン：** 全マニュアル・全プラン・全ログをベクトル検索に放り込んで、プロンプトで「いい感じにまとめて」と頼む状態

**よりうまく回りやすいパターン：**

- 焦点: トラブルシュート

- 境界: Enterpriseプラン（SSO利用）

- 粒度: ケース単位（1件の問い合わせ〜クローズ）

→ AIに渡す情報が構造化され、責任範囲も明確

### 3-6. コンテキスト設計の品質特性

コンテキスト設計にも品質を測る観点がある：

| 軸 | 品質特性 | 問い | 悪い状態 |
|---|---|---|---|
| **焦点** | 純度（Purity） | 1つのコンテキストが1つの問いの種類に対応しているか？ | 複数の問いが混在（トラブルシュート＋契約相談） |
| **境界** | 密封性（Hermeticity） | 境界外の情報が漏れ込んでいないか？ | 他テナント、他プラン、無関係な機能の情報が混入 |
| **粒度** | 一貫性（Consistency） | 同じユースケース内で粒度がブレていないか？ | ケース単位とメッセージ単位が混在 |

#### 軸横断の品質特性：整合性（Alignment）

3軸が互いに整合しているかどうかも重要：

- 焦点に対して、境界は過不足ないか？（広すぎ＝ノイズ、狭すぎ＝情報不足）

- 境界に対して、粒度は適切か？（粒度が細かすぎると境界内の情報量が爆発）

- 粒度で切った1単位が、焦点に答えるのに十分な情報を含むか？

## 4. コンテキストモデリングで「かなりマシになるところ」と「どうしても残るところ」

### 4-1. コンテキストモデリングでかなりマシになるところ

焦点・境界・粒度が決まっている状態でAIに回答案を出させると、AIの振る舞いそのものは相変わらずゆらぐとしても、以下の点が人間から見てだいぶ読みやすくなる：

- どのケースの何を参考にしたか

- どんな種類の問いに対する答えなのか

- どの前提世界での答えなのか

結果として、ログを上から下まで読んで「結局どういう話だっけ？」と再整理する時間、「これ、そもそもこのプランには関係ない話じゃない？」とツッコミを入れる時間が目に見えて減る。

実務的な変化：

- 担当者の頭の中にだけあった「整理の仕方」が、コンテキストモデリングとして外に出てくる

- 「なぜこの情報を候補にしたのか」がログとして残る

- 「この問いには、この文脈セットでAIを呼ぶ」という形で、仕組みとして共有できる

- 「焦点・境界・粒度」の定義がはっきりするため、RAGの検索精度や回答品質をその単位で定量的にテスト（評価）できるようになる

- 境界が明確になることで、範囲外の質問に対して「担当範囲外です」と自信を持って回答を拒否できるようになり、無理に答えようとするハルシネーションが減る

### 4-2. それでも残るもの：価値判断とリスクテイク

どれだけ文脈を整えても、AIが「最後の責任」まで取ってくれるわけではない。

たとえば：

- サポートの現場で、「このラインなら無償対応にしよう」と判断するかどうか

- 調達条件の検討で、「コストを取るか、リードタイムを取るか」を決める瞬間

- 経営会議で、「どこまでリスクを取って新規事業に振るか」を決める場面

こうした局面では、AIは材料を揃えるところまでは手伝ってくれるが、「どっちを選ぶか」「どのラインで責任を取るか」は、やっぱり人間の仕事。

コンテキストモデリングをどれだけ頑張っても、以下の領域は原則としてそのまま残る：

- 最終的な価値判断

- リスクの取り方

- モデル内部のブラックボックス性

### 4-3. 説明責任の線引きとしてのコンテキストモデリング

コンテキストモデリングには**説明責任（Accountability）の線引き**としての価値がある。

AIは説明責任を負えない。「なぜその結論にしたのか」を、自分の言葉で語ることはできない。

けれど、人間側はこう言うことはできる：

- この問いに対して、

- このユーザー（この案件、この期間）を前提にし、

- このケース群と、この条件のもとで、

- AIに案を出させた。

つまり、**なぜこの問いをAIに投げたのか、なぜこの焦点・境界・粒度で文脈を切ったのか、なぜこの文脈を「前提としてよし」とみなしたのか**についてなら、人間が説明責任を負えるようになる。

コンテキストモデリングは、「AIの中身を完全に説明する」ためのものではない。**「AIの中身」ではなく「AIに渡した世界」のほうを、人間が説明できるようにするための設計**である。

この線が引けていれば、「この範囲までは、仕組みとしてこういう前提でAIに任せています」「それを踏まえたうえで、最終判断はこうしました」と、筋の通った説明がしやすくなる。

## 5. AI時代のアーキテクトは「意味のインフラ」を設計する

コンテキストモデリングが扱っているのは、「焦点・境界・粒度をどう決めるか」という、その決め方のルールそのもの。これは、もともと現場の担当者が頭の中で暗黙にやっていたこと。ただ、AIが間に入るようになったことで、この暗黙の作業を外に出さないと、いろいろなところが噛み合わなくなってきた。

これまでのアーキテクトは「技術の番人」として語られることが多かった。AIが入った世界では、それにもう一段、「**意味のインフラ**」を設計する仕事が乗ってくる。

誰が、どんな文脈でAIに問いを渡し、どこまでの世界を前提に話をしているのか。その「意味の流れ」を設計できていれば、AIの振る舞いが多少ゆらいでも、システム全体としてどう受け止めるかを説明しやすくなる。

「AIがこう言いました」ではなく、「この文脈を前提に、この問いについて、AIにこういう役割を任せています」と言えるようにする。そのための"意味のインフラ"を引くのは、やはりアーキテクトの仕事。

## おわりに：あなたの組織では、誰がコンテキストを設計しているか

AIを入れるプロジェクトでは、「どのモデルを使うか」「どのツールをつなぐか」といった話が目立ちがち。それ自体は重要だが、その前後にあるコンテキストは、まだ誰のものでもないまま放置されていることが多い。

もし「焦点・境界・粒度」が暗黙のままなら、今は、個人のセンスとプロンプトに依存している状態だと言える。

**本稿のメッセージ：**
AI時代のアーキテクトは、「AIの中身」ではなく「AIに渡す世界」と、人間がどこまで責任を持つかという線引きを設計する役割を引き受けることになる。そして、その世界を設計するための実務的なハンドルが、「焦点・境界・粒度」という3つの軸だ。

## 参考文献

### 非決定性・エージェント / 確率モデル

- Russell, S., & Norvig, P. (2010). Artificial Intelligence: A Modern Approach (3rd ed.). Prentice Hall.

- Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction (2nd ed.). MIT Press.

### 焦点（Focus / Question under discussion）

- Roberts, C. (2012). Information structure in discourse: Towards an integrated formal theory of pragmatics. Semantics and Pragmatics, 5, 1–69.

### 境界（Boundary / Bounded context）

- Evans, E. (2003). Domain-Driven Design: Tackling Complexity in the Heart of Software. Addison-Wesley.

### 粒度（Granularity）

- Kimball, R., & Ross, M. (2013). The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling (3rd ed.). Wiley.

- Maier, J. F., Eckert, C. M., & John Clarkson, P. (2017). Model granularity in engineering design – concepts and framework. Design Science, 3, e1.

### インテント分類

- Tur, G. and Deng, L. (2011). Intent Determination and Spoken Utterance Classification. In Spoken Language Understanding (eds G. Tur and R. De Mori).
