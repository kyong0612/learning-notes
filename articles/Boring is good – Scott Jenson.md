---
title: "Boring is good – Scott Jenson"
source: "https://jenson.org/boring/"
author:
published: 2025-09-16
created: 2025-09-30
description:
tags:
  - "clippings"
---
大規模言語モデル（LLM）への最初の熱狂は冷め始めており、それはむしろ健全です。行き過ぎた期待ではなく、もっと現実的で――言ってしまえば「退屈な」――姿勢に切り替える時期です。[MITの最近のレポート](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/)によれば、この技術を導入した企業の95%がまだ成果を出せていません。混乱するのも無理はありません。

私は混乱したときには文章を書くようにしています。オンラインでの議論が過熱しすぎていたので、シリーズの最初の回である[Hype is a Business Tool](https://jenson.org/hype)を書きました。第2回の[The Timmy Trap](https://jenson.org/timmy)では、私たち自身がこの誇大広告の一部になっている理由を説明しました。LLMの流暢さを真の知性と勘違いし、実際以上に賢いと信じ込んでしまったのです。LLMは社会的なプロトコルをうまく突き、私åたちをだましてきました。

この最終回では「それでもなぜ気にかけるべきなのか？」という問いに答えたいと思います。この技術には問題が多く、[バブル崩壊](https://www.theaioptimist.com/p/the-beginning-is-near-the-ai-bubble)の兆しもあります。「[幻滅期](https://en.wikipedia.org/wiki/Gartner_hype_cycle)」に達したとき、そこから何が生まれるのでしょうか。不確実な状況を乗り切るうえで役に立った私のキャリアからの教訓が2つあります。1つ目は技術は下流へ流れること、2つ目は私たちはたいてい間違った道から始めることです。

## レッスン1：技術は下流へ流れる

ポール・デイビッドは1989年の論文[The Dynamo and the Computer](https://www.almendron.com/tribuna/wp-content/uploads/2018/03/the-dynamo-and-the-computer-an-historical-perspective-on-the-modern-productivity-paradox.pdf)で、技術が成熟するにつれてその影響が劇的に変化する様子を描きました。彼は強力な電動モーターを指す古い言葉「ダイナモ」を例に挙げています。この動力源は産業革命を完全に変えました。

当時の工場は水力を得るために川のそばに建てられていましたが、ダイナモによってその制約から解放されました。初期の工場には大きなダイナモが1台あるだけで、建物全体に動力を伝えるためには複雑な滑車システムが必要でした。そのせいで作業の流れも複雑化していました。しかし、ダイナモが小型化され、価格も下がると、工場内のあちこちに配置できるようになりました。これこそが本当の転機で、組立ラインを作れるようになったのです。動力が現場の流れに合わせられるようになったことで、生産性は大きく向上しました。

デイビッドは、この歴史的な変化を1980年代後半の状況になるほどと重ね合わせました。1台の不格好なメインフレームの制約に合わせて働くのではなく、小型のデスクトップコンピューターがオフィスのワークフローに合わせられるようになったのです。今のLLMにも同じパターンが起きています。大きく中央集権的なものから、小さく分散したものへの移行です。

LLMの小型化を後押ししているのは主にオープンソースのコミュニティです。彼らは大規模で中央集権的なモデルが必要だという前提に挑戦する、さまざまなモデルを生み出しています。こうした小さなLLMはSLM（[Small Language Model](https://en.wikipedia.org/wiki/Small_language_model)）と呼ばれ、より少ないデータとパラメーターで学習し、[量子化](https://milvus.io/ai-quick-reference/what-is-the-role-of-quantization-in-llms)も抑えられています。[MicrosoftのPhi3](https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/)は小さなタスクには十分で、8年前の私のPCでもCPUを10%も使わずに動きます。

懐疑的になる気持ちも分かります。これらの小さなオープンソースモデルは優れてはいるものの、大手のOpenAIやGoogleの基盤モデルほどのスコアを[出せないことが多い](https://lmarena.ai/leaderboard)ので、格下に感じられます。しかし、それこそが誤解です。性能が勝っていると言いたいのではありません。問題は「問いの立て方」です。司法試験に合格させるような問題を出す必要はないのです。

いくつかの企業は、SLMをもっと小さく目立たないタスクに使いながら、新しい問いの立て方を試しています。例えば裏側で[クエリを書き換える](https://www.zenml.io/llmops-database/llms-for-enhanced-search-retrieval-and-query-understanding)といった、とても単純な用途です。ユーザーはLLMが関わっていることすら知りません。ただ結果が良くなるだけです。低レベルの構文処理に撤することで、LLMに人間のふりをさせずに済み、幻覚のような問題も起きません。さらに嬉しいことに、この用途ならとても小さな特注のローカルLLMを使える可能性があります。

こうした小さな用途は、大規模で中央集権的なモデルよりもSLMに有利になります。その副次効果として、倫理的にトレーニングしやすく、運用コストも低くて済みます。カスタムLLMを作るコストが下がり、容易になるにつれて、この手の活用は広がっていくでしょう。

![](https://jenson.org/wp-content/uploads/2025/09/Ipod-shrinking.jpg)

初代iPodの重さは180gでしたが、技術の進歩とともに12g強まで軽くなり、よりニッチな用途へと姿を変えました。LLMも同じように、技術と市場の成熟につれて大きく姿を変えるはずです。さらに小さく、特化し、そして残念ながらもっと退屈な形で使われるようになるでしょう。人々が「幻覚」にうんざりし、LLMを小さく予測可能な言語処理に集中させた方がどれだけ強力かに気づけば、この流れは一気に加速します。

## レッスン2：私たちはたいてい間違った道から始める

MITのレポートに失敗例があふれているのには理由があります。人々が技術の使い方を理解しないまま、誇大広告に踊らされて突っ走ってしまうからです。1980年代の[未熟なデータベース導入](https://en.wikipedia.org/wiki/The_Social_Life_of_Information)、90年代後半の[ドットコムバブル](https://en.wikipedia.org/wiki/Dot-com_bubble)、2000年代初頭の[モバイルWeb](https://www.phonearena.com/news/Evolution-of-mobile-web-browsing_id9059)でも同じことが起きました。ハイプが起きると、私たちは安易な方向へ流され、技術の弱点を理解しないままプロダクトに組み込んでしまいます。取り残される不安ばかりが先行し、価値を生むことが後回しになるのです。いずれは気づきますが、それは「問いを間違えていた」と理解した後の話です。多くの企業がそこに至る前に失敗してしまいます。

それでも私がLLMを使い続け、探求しているのは、その企業を応援したいからではありません。この新しい素材の「木目」を知りたいからです（元家具職人なので、つい木の比喩を使ってしまいます）。今のモデルで何がうまくいかないのかを確かめながら、有効な使い道を探っています。このシリーズのブログをLLMに手伝わせようとしたこともありますが、うまくいきませんでした（面白い話ではあるのですが、細かく語ると退屈でしょう）。

正直に言うと、私自身も最初は間違った道に進んでいました。LLMを「知的アシスタント」と捉えて、執筆のプロセスをショートカットしようとしたのです。けれど、執筆が難しいのには深い人間的な理由があります。「[知らないことすら知らない](https://en.wikipedia.org/wiki/There_are_unknown_unknowns)」からです。理解するために書くのであって、大量のひどい文章を書いては捨てる必要があります。LLMで「自動的に書く」ことは、この痛みを避けてしまう行為です。ジェームズ・T・カークの言葉の通り、私たちには痛みが必要なのです。[We need our pain!](https://youtu.be/WLzJAebfEIg?si=JDOerGQK1JrI73WO&t=42)

先ほどのクエリ書き換えの例と同じように、私は小さな勝利を積み重ねることで成果を得てきました。LLMの本当の強みである言語的・構文的なタスクに絞ったのです。主に校正や、だらだらした音声メモを要約する用途で使っています。退屈に思える使い方ですが、作業の負担を大きく減らし、文章の質も向上しました。しかも、かなりの確率でうまく機能します（[もちろん完璧ではありませんが](https://www.linkedin.com/posts/scottjenson_ive-been-trying-to-use-llms-at-a-very-low-activity-7372683310671712256-Yx2X?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAABvl0Bs0pzy_RyJRWXZl84o4mJX7IXDk8)）。ただし、文章そのものは書かせません。痛みは必要だからです。

## 正しい道へ流れ込む

LLMは知性的ではなく、これからもそうはなりません。私たちは「知的な仕事」をやらせようとしてきましたが、a) 実際にはそれほど得意ではない、b) 人間の仕事を置き換えるのは想像以上に複雑だ、という事実が分かってきました。その結果、人々はLLMを逆向きに使っています。トップダウンで自動化しようと必死になるのではなく、ボトムアップで補助するべきなのに、です。

以上の2つの教訓を組み合わせると、私たちが向かうのは生産性が高いけれど退屈な世界だと分かります。つまり、低レベルの言語タスクにSLMを使う世界です。念のため言っておきますが、私はLLMの専門家ではありません。山から降りてきた預言者のように語るつもりもありません。この技術には他にも可能性があるでしょう。ただ、今のアプローチがうまくいっておらず、**何か**を変える必要があると指摘したいのです。他の多くの人がそう考えるように、私はこのAIバブルが弾け、多くの痛みをもたらすと予想しています。しかしその後、技術は小さく、効率的で、できればより倫理的な形へと「下流」に流れていくはずです。私たちもまた、モデルが得意とするタスクに使うことで、正しい道に戻る必要があります。

成熟した技術は魔法のようには見えません。インフラのように見えます。小さくなり、信頼性が高まり、そしてとても退屈になります。

私たちの目的は、人を驚かせることではなく、問題を解決することなのです。
