---
title: "Introducing SWE-grep and SWE-grep-mini: RL for Multi-Turn, Fast Context Retrieval"
source: "https://cognition.ai/blog/swe-grep"
author:
  - "Ben Pan"
  - "Carlo Baronio"
  - "Albert Tam"
  - "Pietro Marsella"
  - "Mokshit Jain"
  - "Swyx"
  - "Silas Alberti"
published: 2025-10-16
created: 2025-10-18
description: "Cognitionが開発したSWE-grepとSWE-grep-miniは、高度に並列化されたコンテキスト取得に特化した高速エージェントモデル。最先端のコーディングモデルと同等の取得能力を持ちながら、処理時間は1桁少ない。強化学習により、4ターンで最大8つの並列ツール呼び出しを効率的に実行できるよう訓練されている。"
tags:
  - "AI"
  - "機械学習"
  - "強化学習"
  - "コード検索"
  - "コンテキスト取得"
  - "Cognition"
  - "Windsurf"
  - "Devin"
  - "SWE-grep"
  - "エージェント"
---

## 概要

CognitionはSWE-grepとSWE-grep-miniを発表した。これらは高度に並列化されたコンテキスト取得に特化した高速エージェントモデルで、最先端のコーディングモデルと同等の取得能力を持ちながら、処理時間は1桁少ない。WindsurfのFast Contextサブエージェントとして実装されており、プレイグラウンドでも利用可能。

## 課題背景：スピードと知能のトレードオフ

現代のコーディングエージェントは、**スピード**と**知能**の間に根本的なトレードオフを抱えている。最先端モデルは複雑なタスクを解決できるが、単一のファイルを編集する前に数分の検索時間が必要で、開発フローを中断させる。WindsurfとDevinのエージェント軌跡を分析した結果、最初のターンの60%以上がコンテキスト取得に費やされていることが判明した。

### 従来のコンテキスト取得方法

1. **埋め込み検索（RAG）**
   - 利点：コードベースのインデックス化後、クエリは高速
   - 欠点：
     - 複雑なクエリ（コードベース全体を複数回ジャンプする必要があるもの）では不正確
     - 埋め込みが無関係な情報に過度の重みを与え、逆効果になる可能性

2. **エージェント検索**
   - 利点：柔軟性が高く、CLIツールを使用してコードベースを探索
   - 欠点：
     - 遅い：ユーザーのデバイスと推論エンドポイント間で数十回の逐次的なラウンドトリップが必要
     - 数万トークンの無関係な情報に注意を払う必要があり、コンテキスト汚染を引き起こし、回答品質を大幅に低下させる

## SWE-grepの高速化技術

SWE-grepが1桁速い理由は以下の3つの要素による：

### 1. 並列ツール呼び出しと制限されたシリアルターン

各シリアルターンには、ツール呼び出しとネットワークのオーバーヘッドによる大きなレイテンシコストがかかる。従来のエージェント検索が10-20シリアルターンを要するのに対し、SWE-grepは**4シリアルターン**のみで強力な結果を達成。各ターンで**8つの並列ツール呼び出し**（grep、glob検索、読み取りなど）を実行し、コードベースの異なる部分を同時に探索することで、数秒で深い検索を実現。

### 2. 高速ツール呼び出し

単一のツール呼び出しにかかる時間が重要になるため、ツール呼び出しの実行方法を最適化（インデックス化、マルチスレッド、慎重に制限されたツールセット）し、このカスタムツールセットでSWE-grepモデルを共同設計。

### 3. 高速推論

**Cerebras**（最速の推論プロバイダー）と協力してカスタムSWE-grepモデルをデプロイ・最適化：

- **SWE-grep-mini**: 2,800トークン/秒以上
- **SWE-grep**: 650トークン/秒以上
- Haiku 4.5（140トークン/秒）と比較して、それぞれ20倍、4.5倍高速

## 強化学習による訓練

### モデル設計

SWE-grepモデルは、最大4ターン（3ターンの探索 + 1ターンの回答）で、ターンごとに最大8つの並列ツール呼び出しをネイティブに発行するよう訓練されている。制限されたツールセット（`grep`、`read`、`glob`など）を与えられ、クロスプラットフォーム互換性と安全性を保証。

並列度を4から8に増やすことで、同じパフォーマンスを維持しながら検索ターン数を6から4に削減できることを発見。

### 強化学習アルゴリズム

**マルチターン強化学習**を使用してSWE-grepを直接訓練し、その後SWE-grep-miniに蒸留して追加の強化学習を実施。

報酬関数は、ファイル取得とライン取得タスクに関する重み付きF1スコアの平均（ground truthデータセットに対して）。この目的だけで、SWE-grepは訓練中に自然により多くのツール呼び出しを行うことを学習。

### ポリシー勾配の改良

標準的なポリシー勾配に対して、以下の改良を実施：

- **シーケンスごとの重要度サンプリング**：訓練と推論ライブラリの数値の違いにより、サンプリングされたデータが事実上off-policyデータになる問題を解決
- **leave-one-outベースライン**：分散を減らすために使用
- **サロゲート損失関数**の設計により、正しい勾配推定を実現

### 訓練の安定化技術

複数ターンにわたる大量の並列ツール呼び出しは、環境からの多くのトークンを導入し、不安定性を引き起こす（特に小規模モデル）。以下の技術が有効：

- 過度に長い軌跡を損失からマスク
- 極端な重要度サンプリング比を持つ軌跡をマスク
- フォーマット報酬の削除
- 不正にフォーマットされたツール呼び出しや回答を持つ軌跡を中断し、ゼロ報酬を割り当て
- ターンごとに使用されるツール呼び出しの平均数で**アドバンテージ**をスケーリング

## データと評価

### Cognition CodeSearch Eval

実世界のリポジトリ、ユーザークエリ、関連ファイルとライン範囲のラベル付けされたground truthからなる内部データセット。最も難しいバグレポートと内部テストから作成。

### 評価メトリクス

1. **重み付きF1スコア**（F-β、β=0.5）：ファイルとライン範囲 vs. ground truth
   - 再現率よりも精度を優先：コンテキスト汚染は、一部のコンテキストを欠くよりも有害
2. **エンドツーエンドレイテンシ**

### ベンチマーク結果

各モデルに4ターン、最大8並列ツール呼び出しを許可して評価：

**主要な発見**：

- SWE-grepとSWE-grep-miniは、最先端モデルと同等またはそれ以上の性能を持ちながら、**1桁速い**

### ダウンストリーム分析

#### コーディングタスク（SWE-Bench Verified）

難易度の高いSWE-Bench Verifiedタスクのランダムサブセットで評価：

- Fast Contextサブエージェント使用時、同じ数のタスクを達成しながら、エンドツーエンド時間が大幅に短縮
- 検索ファイルステップ数も削減

#### コードベースQ&A

オープンソースリポジトリに対する例題クエリでエンドツーエンドレイテンシを測定：

- Fast Contextエージェント vs Claude Code vs Cursor CLI
- Modal容器内でエージェントをホストし、stdin/stdoutを通じて入出力をパイプ化
- ローカル使用体験を反映するように設計

## Fast Context：Fast Agentsへの第一歩

WindsurfのFast Contextサブエージェントは、**Fast Agents**ロードマップの最初のステップ。SWE-grepモデルは、DeepWiki、Devin、Windsurf Tabなどの製品に展開予定。

### Fast Contextサブエージェントの利点

1. **メインエージェントのコンテキスト予算（と知能）を節約**
   - サブエージェントに取得を委任することで、貴重なエージェントトークンを節約
   - 無関係な情報によるコンテキスト汚染を回避
   - 関連トークンのみに注意を払うことが可能

2. **汎用性の高い能力**
   - AIアシストコーディングスタックのすべてのレイヤーが恩恵を受ける
   - オートコンプリートからCascade、Devinまで

3. **検証可能なタスク**
   - ファイルとライン範囲のリストを取得（要約ではない）
   - 客観的なground truthデータセットを定義可能
   - クリーンで決定論的な報酬を計算して強化学習を実施

### フローウィンドウの概念

Mihaly Csikszentmihályiの「フロー」の定義に基づき、Cognitionは以下を推定：

- エージェントの応答を待つ間、1秒経過するごとにフロー中断確率が幾何学的に10%増加
- 「**フローウィンドウ**」として5秒を目標に設定

### 今後の方向性

- より可変的なターン長
- さらに高い知能
- ツール速度の最適化
- 最先端のコーディングエージェント自律性の推進と、「十分に良い」バーを満たしながらの高速化の両方を研究
- **Semi-Async Valley of Death**（半非同期の死の谷）を避けることが重要

## 利用方法

### Windsurf

Windsurf Cascadeを通常通り使用するだけで、コード検索が必要なクエリを行うとFast Contextが自動的にトリガーされる（`Cmd+Enter`で強制トリガーも可能）。最新リリースから段階的にロールアウト中。

### プレイグラウンド

<https://playground.cognition.ai/> でFast Contextエージェントとクラウド Code、Cursor CLIの直接比較が可能。

## 関連研究

- Kevin-32B：CUDAカーネル記述のためのマルチターン強化学習
- OpenAIのo1のレビューとコーディングエージェントの評価方法
- SWE-benchテクニカルレポート
