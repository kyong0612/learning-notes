---
title: "Context Rot: How Increasing Input Tokens Impacts LLM Performance"
source: "https://research.trychroma.com/context-rot"
author:
  - "Kelly Hong"
  - "Anton Troynikov"
  - "Jeff Huber"
published: 2025-07-14
created: 2025-11-11
description: |
  LLMは通常、コンテキストを均一に処理すると想定されているが、実際には入力長が増加すると性能が非均一に低下する。本レポートでは、GPT-4.1、Claude 4、Gemini 2.5、Qwen3を含む18のLLMを評価し、コンテキスト長が増加するにつれてモデルの性能が信頼性を失うことを実証した。Needle in a Haystackの拡張、LongMemEval、反復単語タスクを通じて、単純なタスクでも入力長の増加により性能が劣化することを示した。
tags:
  - "clippings"
  - "LLM"
  - "context-window"
  - "evaluation"
  - "performance"
  - "long-context"
---

## 概要

大規模言語モデル（LLM）は通常、コンテキストを均一に処理すると想定されているが、実際には入力長が変化すると性能が大きく変動する。本レポートでは、GPT-4.1、Claude 4、Gemini 2.5、Qwen3を含む18のLLMを評価し、モデルがコンテキストを均一に使用せず、入力長が増加するにつれて性能が信頼性を失うことを実証した。

## 主要な発見

### 1. コンテキスト長による性能劣化

- すべての実験において、入力長が増加するとモデル性能が一貫して劣化する
- 単純なタスクでも、コンテキスト長が増加すると性能の非均一性が増大する
- 最新の最先端モデルでも、この傾向は観察される

### 2. Needle-Question Similarity（針-質問類似度）

- 針-質問ペアの類似度が低いほど、入力長の増加に伴う性能劣化がより顕著になる
- 短い入力長では、低類似度ペアでもモデルは良好に動作する
- より現実的なシナリオでは、正確な質問-回答マッチは稀であり、意味的曖昧さが長い入力処理の課題を複合化する

### 3. Distractors（妨害要素）の影響

- 単一の妨害要素でも、ベースライン（針のみ）と比較して性能が低下する
- 4つの妨害要素を追加すると、さらに性能が劣化する
- 妨害要素は均一な影響を持たず、入力長が増加するにつれてその影響が増幅する
- モデルファミリー間で、曖昧さへの対処方法に明確な違いが観察される
  - Claudeモデル：幻覚率が最も低く、不確実な場合は控えめに棄権する傾向
  - GPTモデル：幻覚率が最も高く、妨害要素が存在する場合に自信を持って誤った回答を生成する傾向

### 4. Needle-Haystack Similarity（針-干し草の山類似度）

- 針-干し草の山の類似度は、モデル性能に均一な影響を与えない
- Paul Grahamエッセイの干し草の山では、arXiv針がPGエッセイ針よりも大幅に良好な性能を示す（針が干し草の山に意味的に溶け込まない場合の方が性能が良い）
- arXiv干し草の山では、arXiv針とPGエッセイ針の間の性能差は最小限

### 5. Haystack Structure（干し草の山の構造）

- 構造的整合性がモデル性能を一貫して損なう
- 論理的なアイデアの流れを保持する干し草の山よりも、シャッフルされた干し草の山の方が性能が良い
- これは直感に反する結果であり、モデルの内部処理における注意メカニズムへの影響を示唆

### 6. LongMemEval

- すべてのモデルで、フォーカスされたプロンプト（関連部分のみ）と完全なプロンプト（113kトークン）の間で性能に大きな差が観察される
- Claudeモデルは、フォーカスと完全プロンプトの間で最も顕著な性能差を示す（主に曖昧さによる棄権が原因）
- 思考モードが有効なモデルでも、両方の入力長で改善が見られるが、最新モデルでも入力長間の性能差は残る

### 7. Repeated Words（反復単語）

- コンテキスト長が増加すると、すべてのモデルで性能が一貫して劣化する
- ユニークな単語の位置精度は、ユニークな単語がシーケンスの先頭近くに配置される場合に最も高い
- コンテキスト長が増加すると、モデルは出力トークン制限に達するまで反復単語を生成する傾向がある
- 一部のモデルは、タスクを試行しない場合がある（例：Claude Opus 4は2.89%、GPT-4.1は2.55%）

## 実験設計

### Needle in a Haystack Extension

4つの制御実験を設計：

1. **Needle-Question Similarity**: 埋め込みを使用して針-質問ペア間のコサイン類似度を計算
2. **Impact of Distractors**: 高類似度針-質問ペアを使用し、4つの妨害要素を手動で作成
3. **Needle-Haystack Similarity**: 2つの主題的に異なる干し草の山（Paul GrahamエッセイとarXiv論文）を使用
4. **Haystack Structure**: 元の構造とシャッフルされた構造を比較

各モデルは以下でテスト：

- 8つの入力長
- 11の針位置
- 最大コンテキストウィンドウ全体で評価

### LongMemEval

- 会話型質問応答のための長コンテキストベンチマーク
- 2つの条件を比較：
  - フォーカスされた入力：関連部分のみ（平均~300トークン）
  - 完全な入力：完全な113kトークンLongMemEval入力（無関係なコンテキストを含む）

### Repeated Words

- モデルは反復単語のシーケンスを複製し、特定の位置に単一のユニークな単語を挿入する必要がある
- 1090のバリエーション：12の単語数 × 複数のインデックス位置
- 7つの異なる単語組み合わせをテスト

## 評価されたモデル

### Anthropic

- Claude Opus 4
- Claude Sonnet 4
- Claude Sonnet 3.7
- Claude Sonnet 3.5
- Claude Haiku 3.5

### OpenAI

- o3
- GPT-4.1
- GPT-4.1 mini
- GPT-4.1 nano
- GPT-4o
- GPT-4 Turbo
- GPT-3.5 Turbo

### Google

- Gemini 2.5 Pro
- Gemini 2.5 Flash
- Gemini 2.0 Flash

### Alibaba

- Qwen3-235B-A22B
- Qwen3-32B
- Qwen3-8B

## 制限事項と今後の研究

### 制限事項

1. **現実世界の使用例の網羅性**: 実際の長コンテキストアプリケーションは、統合や多段階推論を必要とする場合が多く、より複雑である
2. **メカニズムの説明不足**: 性能劣化の背後にあるメカニズムを説明していない
3. **タスク難易度との分離**: 入力長とタスク難易度を分離することの重要性が指摘されているが、完全な分離は困難

### 今後の研究方向

1. **コンテキストエンジニアリング**: コンテキストウィンドウの慎重な構築と管理の重要性
2. **メカニズム的解釈可能性**: 構造的特性がモデルの動作にどのように影響するかの調査
3. **より厳格な評価**: 現在のベンチマークを超えた、より厳格な長コンテキスト評価の必要性

## 結論

実験を通じて、LLMは入力長にわたって一貫した性能を維持しないことを実証した。非語彙的検索やテキスト複製のような単純なタスクでも、入力長が増加すると性能の非均一性が増大する。

結果は、現在のベンチマークを超えたより厳格な長コンテキスト評価の必要性、およびコンテキストエンジニアリングの重要性を強調している。関連情報がモデルのコンテキストに存在するかどうかだけでなく、その情報がどのように提示されるかがより重要である。最も能力の高いモデルでさえこれに敏感であり、信頼性の高い性能には効果的なコンテキストエンジニアリングが不可欠である。

## 技術的詳細

### 評価方法

- 温度=0で評価（o3やQwenの「思考モード」など、互換性がない場合を除く）
- Qwenモデルには、32,768から131,072トークンに拡張するためにYaRNメソッドを適用
- モデル出力は、整列されたGPT-4.1判定者を使用して評価（付録で説明）
- 5つの埋め込みモデルを使用して類似度を計算：text-embedding-3-small、text-embedding-3-large、jina-embeddings-v3、voyage-3-large、all-MiniLM-L6-v2

### データセット

- **Needle in a Haystack**: Paul GrahamエッセイとarXiv論文から作成
- **LongMemEval**: 306のプロンプト（平均~113kトークン）、知識更新、時間的推論、マルチセッションカテゴリ
- **Repeated Words**: 7つの異なる単語組み合わせ、1090のバリエーション

## 参考文献

完全なコードベースとデータセットは[GitHub](https://github.com/chroma-core/context-rot)で公開されている。

主要な参考文献：

- Needle in a Haystack (Kamradt, 2023)
- LongMemEval (Wu et al., 2025)
- NoLiMa (Modarressi et al., 2025)
- AbsenceBench (Fu et al., 2025)
- Michelangelo (Vodrahalli et al., 2024)
