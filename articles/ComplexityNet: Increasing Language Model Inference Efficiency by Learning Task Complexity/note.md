# ComplexityNet: Increasing Language Model Inference Efficiency by Learning Task Complexity

ref: <https://arxiv.org/html/2312.11511v3>

## ComplexityNet: タスク複雑さを学習してLLM推論効率を向上させる

### 概要

ComplexityNetは、タスクの複雑さを評価し、様々な能力を持つ大規模言語モデル（LLM）にタスクを適切に割り当てるフレームワークです。このフレームワークをPythonコード生成タスクに適用し、Mostly Basic Python Problems（MBPP）データセットを使用しました。まず、タスクの複雑さを正確に定量化するためのラベル付けを開発し、小型言語モデルを微調整して異なるLLM間での正確な出力生成の可能性を予測できるようにしました。このモデルはタスク複雑さの分類において79%の精度を達成し、微調整なしのベースラインモデルの34%から大幅に向上しました。タスク割り当てのステップでは、最も複雑なモデルのみを使用する場合と比較して計算リソース使用量を90%削減しつつ、86.7%の高いコード生成精度を維持しました。本研究は、タスクの複雑さに基づいてタスクを分類するための小型モデルの微調整が、大規模言語モデルの使用における精度と効率性のバランスを改善できることを示しています。

### 導入

大規模言語モデル（LLM）の進化はAI分野における大きな前進ですが、推論コストに関する課題も伴います。モデルが高度化するにつれて、必要な計算リソースも大幅に増加しています。例えば、GPT-4はGPT-3.5に比べて約10倍の計算を使用すると推測されています（API価格から概算）。タスクの難易度に関わらず、トークンあたりの一律のコストが発生することが問題です。

この計算リソースの増加は、特に小規模な組織や個人研究者にとって、これらの技術の持続可能性とアクセシビリティに関する懸念を生じさせています。ユーザーがタスクの単純さに関わらず高度なモデルを使用する傾向があり、計算リソースの大きな無駄が生じています。主要プラットフォームでは手動でのモデル選択が可能ですが、タスクに最適なモデルを自動的に選択するための体系的なアプローチが欠如しています。

この問題に対処するため、本研究では以下の問いを提起します：

「与えられた問題に対して、正しい回答を返す最小のモデルクラスは何か？」

この問いを定量化するため、問題の複雑さを「タスクを正しく達成できる最も単純かつ能力の低いLLM」として定義します。

### 複雑さの定義と方法論

LLMに関する複雑さの概念は、特に評価が主観的なタスク（例：意味のある詩を書く）においては定義が難しい場合があります。そのため、本研究では明確な正解がある問題（数学問題やプログラミング問題など）に範囲を限定しています。

さらに簡略化するため、本研究ではパラメータ数とパフォーマンスに明確な違いがある3つの言語モデルを使用しています：

- Code Llama 7B（7Bパラメータ、推論コスト$0.0002/1Kトークン）
- GPT-3.5（175Bパラメータ、推論コスト$0.002/1Kトークン）
- GPT-4（1兆以上のパラメータ推定、推論コスト$0.03/1Kトークン）

これら3つのモデルに基づき、指示文を入力として受け取り、定義した複雑さを出力して適切なモデルを選択する分類モデルの作成を目指します。

### タスク複雑さデータセットの作成プロセス

タスクの複雑さを判断するため、複数のLLMでの相対的な成功率に基づく経験的な方法を採用しました。明確な回答を持つタスクに集中し、成功条件はLLMの出力が解と一致することです。

各タスクに対して、3つの主要LLM（Code Llama、GPT-3.5、GPT-4）を各5回（ゼロでない温度設定で）クエリし、その成功回数を記録しました。タスクの複雑さは1〜5の整数で表し、1が非常に単純なタスク、5が非常に複雑なタスクを表します。

実証のため、Pythonコーディングタスクを選択し、Mostly Basic Python Problems（MBPP）データセットを使用しました。このデータセットの各行には、タスク（通常「関数を書いてください...」で始まる）、タスクを達成するPythonコード（解答）、モデルの出力を検証するための一連のPython assertion文が含まれています。

自動パイプラインを構築し、MBPPデータセットからのタスクを使用してLLMをクエリしました。OpenAI APIを通じてGPT-4とGPT-3.5を呼び出し、Code Llamaはローカルで実行しました。事前に決定されたシステムプロンプトを使用して、モデルが説明なしでコードのみを出力し、assertion文のコードと同じ関数定義に従うようにしました。

各モデルの出力をデータセットのassertion文と照合して回答の正確さを検証し、LLM出力のランダムノイズを減らして方法の堅牢性を向上させるために5回繰り返しました。成功率に基づいて、タスクに異なる複雑さレベルを割り当てました。

微調整前に、Code Llama、GPT-3.5、GPT-4がそれぞれ0/5回正解したデータポイントをデータセットから削除しました（MBPPデータセットのエラーによるもの）。

### 微調整プロセスとタスク割り当て

データセットが確立されたら、指示文の複雑さを分析する小型言語モデル（複雑さモデル）を微調整できます。本研究では、OpenAI APIで簡単に微調整できるDaVinci-002を複雑さモデルとして選択しました。

全複雑さラベルデータセットを訓練セットとテストセットに分割しました。訓練セットで複雑さモデルを微調整した後、予測されたタスク複雑さレベルに従ってサンプル外のタスクを異なるLLMに割り当てることができます。

本研究では、複雑さクラスごとに異なるLLMに割り当てるシンプルなルールを採用しました。このスキームは、これらの複雑さクラスをCode Llama、GPT-3.5、またはGPT-4のいずれかにマッピングします。複雑さレベル1と2をCode Llamaに、レベル3と4をGPT-3.5に、レベル5をGPT-4に割り当てました。

### 結果

微調整されたComplexityNetモデルは、タスク複雑さの分類において79%の精度を達成しました。これは、微調整なしのベースラインモデルの34%から大幅に向上しています。

コスト削減と精度のトレードオフについては、Code Llamaのコストを1単位、GPT-3.5を10単位、GPT-4を100単位と近似し、複雑さモデルの計算コストは出力が単一トークンであり、モデルの複雑さが最も単純なモデルと同等であることを考慮して無視できると仮定しました。

N=180のデータセットで観察された複雑さの経験的分布と、推論中に観察された複雑さの過大評価および過小評価に基づいて、コスト削減を推定しました。すべてのタスクにGPT-4を使用すると仮定した場合と比較してベンチマークを測定しました。

計算式に基づくと、推論コストは90%削減されました。この劇的な削減は、複雑さモデルの高い精度と、Code LlamaとGPT-3.5がPythonタスクで成功する能力によるものです。また、このメソッドは86.7%の高いコード生成精度を維持しました。

### 考察

#### LLMの生態学的ニッチ

5回試行ラベリング法で微調整されたモデルの高い分類精度と、結果として生じる90%のコスト削減は、LLM利用に対する現在のアプローチ（すべてのタスクに最も能力の高いモデルを使用する）の大きな非効率性を強調しています。私たちの発見は、モデルレベルでの修正を伴わないLLM推論プロセスを改良するためのトップダウン戦略の可能性を示しています。

こうした発見は機械行動の進化的研究と共鳴し、より大きく能力の高いモデルの進歩に直面して、小型や旧型のモデルの継続的な関連性の問題を提起します。しかし、自然界のエコシステムで観察される多様な役割と同様に、これらの「ヴィンテージ」LLMも独自のニッチを切り開く可能性があります。これは、支配ではなく多様性が生態学的バランスを決定するLLMの動的で多面的なエコシステムを示唆しています。

#### フレームワークの拡張性

本研究では、決定論的な回答に対応するコーディングタスクの指示文の複雑さを分析しました。これはエッセイや詩の生成などのより抽象的なタスクの複雑さを判断することの実現可能性についての疑問を投げかけます。これを行うために、MMLU（多タスク言語理解データセット）などの異なるデータセットを活用し、複雑さを判断するためのアプローチが有効かどうかを検証できます。私たちの全体的な手順はassertion文や検証文を持つデータセットに一般化できることに注意することが重要です。また、多くのデータセットの組み合わせでモデルを訓練することが、幅広いタスクと指示文の複雑さを捉えるのに役立つと推測しています。

### 結論

本研究では、一連のLLMの推論効率を向上させるためにトップダウン最適化アプローチを適用するフレームワークを提案しました。小型言語モデルを微調整してタスクの複雑さを判断し、最も適切なサイズの言語モデルに割り当てました。このアプローチを3つの異なる能力のLLMにわたるコード生成タスクに実装し、推論コストを90%削減しながら86.7%の精度率を維持するという注目すべき結果を達成しました。マッピング、タスク割り当てルール、微調整プロセスなどの分野において大幅な改善の余地があることを強調することが重要です。次のステップには、このアプローチがコード生成よりも複雑または明確でないタスクなど、より広範なタスクにどのように機能するかを探ることが含まれます。
