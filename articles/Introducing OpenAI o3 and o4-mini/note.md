# Introducing OpenAI o3 and o4-mini

ref: <https://openai.com/index/introducing-o3-and-o4-mini/>

OpenAIは2023年4月16日、o-シリーズの最新モデルである**OpenAI o3**と**o4-mini**をリリースしました。これらは回答前により長く考えるよう訓練された最もスマートで高性能なモデルで、大きな特徴として全てのChatGPTツール（ウェブ検索、ファイル分析、Pythonによるデータ分析、視覚的入力の理解、画像生成）を組み合わせて使用できるようになりました。

## 主な変更点

### OpenAI o3

- OpenAIの最も強力な推論モデル
- コーディング、数学、科学、視覚認識などの分野で最先端の性能
- 複雑な質問に対する多面的分析が可能
- 困難な実世界タスクにおいてOpenAI o1より20%少ないエラー率
- 画像分析タスクで特に優れたパフォーマンス

### OpenAI o4-mini

- 小型で高速、コスト効率の良い推論モデル
- 数学、コーディング、視覚タスクで特に優れたパフォーマンス
- AIME 2024と2025で最高のベンチマーク性能
- o3-miniと比較して非STEMタスクやデータサイエンスでも向上

### 両モデルの共通点

- 指示に従う能力の向上
- より有用で検証可能な回答
- より自然で会話的な対話
- 過去の会話を参照して応答をパーソナライズする能力

## 強化学習のスケーリング継続

OpenAI o3の開発において、大規模強化学習が「より多くの計算=より良いパフォーマンス」という傾向を示すことが確認されました。訓練計算量と推論時間の両方で1桁増加させても、パフォーマンスの向上が継続しています。

両モデルはツールの使用方法だけでなく、いつ使用するかについても強化学習を通じて訓練されています。これにより視覚的推論やマルチステップのワークフローなど、より複雑な状況でのツール活用能力が向上しています。

## 画像を使った思考

o3とo4-miniは、思考の流れに画像を直接統合できる初のモデルです。ホワイトボード、教科書の図、手書きのスケッチなどの画像を解釈し、その画像を使って考えることができます。ツールを使用して画像を回転、拡大、変換するなど、推論の一部として操作することも可能です。

## エージェント的ツール使用

o3とo4-miniはChatGPT内のすべてのツールにアクセスでき、APIでのFunction Callingを通じてカスタムツールも利用できます。問題の解決方法について推論し、詳細で思慮深い回答を素早く（通常1分以内に）提供するために、いつどのようにツールを使用するかを決定するよう訓練されています。

## 採用とアクセス

- ChatGPT Plus、Pro、Team：o3、o4-mini、o4-mini-highが即日利用可能
- ChatGPT Enterprise、Edu：1週間後にアクセス可能
- 無料ユーザー：クエリ送信前に「Think」を選択することでo4-miniを試用可能
- API開発者：Chat Completions APIとResponses APIを通じて利用可能

## 安全性

モデルの能力向上に伴い、安全性も向上しています。o3とo4-miniには、生物学的脅威、マルウェア生成、ジェイルブレイクなどの分野に関する新しい拒否プロンプトを含む完全に再構築された安全性訓練データが組み込まれています。また、危険なプロンプトをフラグする系統的な緩和策も開発されました。

## 将来の展望

今回のアップデートは、o-シリーズの特殊な推論能力とGPTシリーズの自然な会話能力およびツール使用のより多くを収束させる方向性を反映しています。将来のモデルでは、これらの強みを統合し、シームレスで自然な会話と、能動的なツール使用および高度な問題解決をサポートする予定です。

## 視覚的要素

記事には以下の視覚的要素が含まれています：

1. o3についての紹介ビデオ
2. 思考と画像を組み合わせた分析を示す図
3. さまざまなベンチマークにおけるパフォーマンスを示すグラフ
4. コスト対パフォーマンスを示す複数のグラフ

これらの視覚的要素は、モデルの能力と改良点を直感的に理解するのに役立ちます。
