---
title: "AI Agent時代における「使えば使うほど賢くなるAI機能」の開発"
source: "https://tech.layerx.co.jp/entry/2025/10/23/222742"
author:
  - "島越（shimacos / @nt_4o54）"
published: 2025-10-23
created: 2025-10-26
description: "AI Agent時代におけるパーソナライゼーションの新しいアプローチについて。LLM以前のモデル中心の学習から、Context Engineeringによるプロンプト最適化へのパラダイムシフトと、DSPyを用いた実践的な実装方法を解説。"
tags:
  - AI-Agent
  - LLM
  - 機械学習
  - パーソナライゼーション
  - プロンプト最適化
  - DSPy
  - Context-Engineering
---

## 概要

LayerXのバクラク事業部AI・機械学習部による、AI Agent時代における「使えば使うほど賢くなるAI機能」の開発手法についての記事。LLM以前とLLM登場後でのパーソナライゼーションのアプローチの違いと、プロンプト最適化の具体的な実装方法を紹介。

## LLM以前のパーソナライゼーション

### パーソナライズドAI-OCRの事例

LayerXでは、LLM登場以前から機械学習モデルを内製しており、2024年11月に「パーソナライズドAI-OCR」をリリース。この機能は以下の2つのモデルで構成：

- **候補抽出モデル**: ドキュメントから選択可能な候補を抽出
- **推薦モデル**: 顧客の過去の選択履歴から候補を並び替え

### 従来のアプローチの特徴

1. **モデル中心の最適化**: ユーザーのフィードバックを用いて定期的にモデルを再学習
2. **データ収集の工夫**: UI/UXを考慮し、ユーザー負担を最小化した構造化データの収集
3. **自動更新**: Vertex AI Pipelinesによる定期的な特徴量とモデルの更新

## LLM時代のパーソナライゼーション

### パラダイムシフト

**モデル中心** → **Context Engineering中心**へ

- LLMのファインチューニングは計算コスト・運用負荷が高い
- LLMは既に汎用知識を持つため、プロンプトでの指示で多くのケースに対応可能
- 入力される情報（コンテキスト）の設計による最適化が主流に

### Context Engineeringの課題

- プロンプトの管理・最適化
- 個別ユースケースへのコンテキスト調整
- 複数のLLMを組み合わせたワークフロー設計
- ユーザーフィードバックの効果的な活用

## プロンプト自動最適化の手法

### In-Context Learning (ICL)

- Few-shot Exampleをプロンプトに含めることでタスクパターンを学習
- 強力だが、手作業での試行錯誤が必要
- 最適化できる要素が限定的

### プロンプト最適化の体系

論文「A Systematic Survey of Automatic Prompt Optimization Techniques」によると、以下の要素で体系化される：

1. **Seed Prompts**: 初期プロンプト生成戦略
2. **Inference evaluation and feedback**: 予測評価とフィードバック取得
3. **Candidate prompt generation**: 改善プロンプトの生成
4. **Filter and retain**: 高性能プロンプトの選択戦略
5. **Iteration depth**: 終了基準の特定

### 評価とフィードバックの重要性

- **LLM-as-a-Judge**: 評価にLLMを活用
- **TextGrad**: 文章の簡潔さや正確さなど定性的指標での最適化を可能に
- **ユーザーフィードバック**: 最低限、出力の受容可否を収集する仕組みが必須

**事例: Greptile**
AI Code Reviewサービスで、絵文字リアクションやPRコメントから複合的に学習してパーソナライゼーションを実現

### ワークフロー最適化

単一のLLMだけでなく、複数のLLMを組み合わせたワークフロー全体の最適化も重要：

- **AFlow**: ワークフロー生成を自律的に行う手法
- **ShinkaEvolve** (Sakana AI): プログラムを最適化していく手法

## DSPyによる実践

### DSPyとは

Databricksのリサーチサイエンティストが開発したフレームワーク。プロンプトを意識せずにLLMアプリケーションを作成可能。

### 実装例: 経費精算承認Agent

**タスク**: 経費精算の承認作業を行うAgent

#### データセット

- 1000件の擬似データを生成
- 適切/不適切な申請を混在（不適切: 30-40%）
- 訓練:検証:テスト = 640:160:200

#### 実装

```python
class ExpenseApprovalSignature(dspy.Signature):
    """経費精算フォームを審査し、承認/否認を判定します。"""
    expense_form: str = dspy.InputField(desc="経費精算フォームの全情報")
    approval_status: Literal["approved", "rejected"] = dspy.OutputField(desc="承認状態")
    comment: str = dspy.OutputField(desc="判定理由の詳細なコメント")

class ExpenseApprovalModule(dspy.Module):
    def __init__(self):
        super().__init__()
        self.prog = dspy.ChainOfThought(ExpenseApprovalSignature)
    
    def forward(self, expense_form: str):
        return self.prog(expense_form=expense_form)
```

#### 検証したOptimizer

| Optimizer | アルゴリズム | 内容 |
|-----------|------------|------|
| BootstrapFewShotWithRandomSearch | Few-shot自動化 | ランダムにFew-shotを生成し、検証セットで最良のものを選択 |
| KNNFewShot | Few-shot自動化 | KNNで近傍のサンプルを抽出 |
| MIPROv2 | Few-shot & Instruction自動化 | ベイズ最適化でプロンプトとFew-shotを同時最適化 |

### 実験結果

| Optimizer | 正解率 | ベースラインからの改善 |
|-----------|--------|----------------------|
| なし（ベースライン） | 87.94% | +0.00% |
| BootstrapFewShotWithRandomSearch | 92.46% | +4.52% |
| KNNFewShot | 91.46% | +3.52% |
| **MIPROv2** | **92.96%** | **+5.02%** |

### プロンプトの変化

#### ベースライン

```
経費精算フォームを審査し、承認/否認を判定します。
不適切な要素がある場合は'rejected'、問題がなければ'approved'と判定してください。
判定理由も具体的に説明してください。
```

#### MIPROv2最適化後

```
あなたは企業の経費精算担当者として、経費精算フォームを厳密かつ公正に審査する役割を担っています。
企業の財務健全性と不正防止を守るため、日付、取引先、勘定科目、金額、領収書の有無、備考の内容など
全ての情報を慎重に検証してください。不正確な日付や金額の異常、取引先と経費種別の不整合、
領収書の欠落、過去の期限切れの申請など、どんな不適切な要素も見逃さずに発見し、
「approved」（承認）または「rejected」（否認）を決定してください。
判定結果に至るまでの考察はステップバイステップで思考過程として詳細に記述し、
具体的かつ説得力のあるコメントで理由を明確に説明してください。
```

## 重要な知見

### プロダクト開発における実装ポイント

1. **評価指標の設計**: ユーザー体験として定義できる指標を準備
2. **フィードバック収集**: 最低限、出力の受容可否を収集できる仕組みを構築
3. **運用コスト削減**: テキストのみの保持で、ユーザー別のパーソナライゼーションが可能
4. **継続的改善**: 評価とフィードバックのサイクルをプロダクトに組み込む

### LLM時代の開発の利点

- モデルの再学習に比べて運用負荷が小さい
- パーソナライゼーションの幅が広がる
- 定性的な評価指標での最適化が可能
- テキストフィードバックも活用しやすい

## まとめ

AI Agent時代のパーソナライゼーションは、従来のモデル中心のアプローチから、Context Engineeringによるプロンプト最適化へとシフトしている。DSPyのようなフレームワークを活用することで、データ駆動でプロンプトを自動最適化し、「使えば使うほど賢くなるAI機能」を実現できる。

実務では、評価指標の設計、フィードバック収集の仕組み、最適化のタイミングと単位など、考慮すべき点は多いが、これらの手法を運用に載せることで「業務の完全自動運転化」に近づくことができる。
