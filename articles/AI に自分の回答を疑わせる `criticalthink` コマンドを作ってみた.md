---
title: "AI に自分の回答を疑わせる `/criticalthink` コマンドを作ってみた"
source: "https://aba.hatenablog.com/entry/2025/10/08/201243"
author:
  - "[[ABA]]"
published: 2025-10-08
created: 2025-10-10
description: "LLMに回答を生成させた後、その回答を批判的に検証させることで精度を向上させるCQoT(Critical-Questions-of-Thought)論文に基づき、コーディングエージェント用の`/criticalthink`コマンドを開発。AIの提案に対して前提の妥当性、論理的整合性、見落としているリスクを自己分析させ、人間が最終判断を下すための補助線として機能する。"
tags:
  - "AI"
  - "LLM"
  - "批判的思考"
  - "コーディングエージェント"
  - "Claude"
  - "プロンプトエンジニアリング"
---

## 概要

AIの回答を批判的に検証させることで精度を向上させる`/criticalthink`コマンドの開発記録。Federico Castagna らの論文「Critical-Questions-of-Thought」(CQoT)にインスパイアされ、コーディングエージェント向けに実装した実践的なツール。

## きっかけ：CQoT論文との出会い

**CQoT(Critical-Questions-of-Thought)論文の核心**

LLMに回答を生成させた後、その回答を批判的に検証させるステップを挟むと精度が向上する。論文ではToulminの議論モデルに基づいた8つの批判的質問を使用：

1. 推論は明確な前提から始まっているか？
2. 前提は証拠や事実で裏付けられているか？
3. 前提と結論の間に論理的なつながりがあるか？
4. その論理的つながりは妥当か？
5. 推論は論理的誤謬を避けているか？
6. 結論は前提から論理的に導かれているか？
7. 推論は既存の知識や原則と整合しているか？
8. 推論の結論は妥当で合理的か？

**評価プロセス**

AI自身がPass/Failで自己評価し、一定基準(8つ中7つ以上がPass)を満たすまで推論プロセスを繰り返し見直す仕組み。

## 問題意識：コーディングエージェントの課題

コーディングエージェントは便利だが、以下のような問題がある：

- **ハルシネーション**: 存在しないAPIを捏造する
- **安易な提案**: 「全部書き直しましょう」と簡単に言う
- **不完全な実装**: エラー処理を書かずにハッピーパスだけ実装して「完成です」と言う
- **運用コスト無視**: 「Kubernetes + Istioで完璧です」と提案するが、運用コストの話は一切ない

**根本的な課題**

AIの回答を疑うための視点を毎回自力で用意するのが面倒。「この提案、本当に大丈夫か？」と思っても、何をチェックすればいいのか、その場で整理するのは手間がかかる。

## `/criticalthink`コマンドの実装

**使い方**

AI が回答を生成した直後に `/criticalthink` と入力するだけ。

**分析観点**

AIは直前の自分の回答を以下の観点で自己分析：

- どんな前提を置いているか
- その前提は妥当か
- 論理的におかしいところはないか
- 見落としているリスクはないか
- AIがよくやらかすパターン(問題回避、ハッピーパスバイアス、過剰設計、ハルシネーション等)に該当しないか

**実例**

「Redisでレート制限を実装します」という提案に対して `/criticalthink` を実行すると：

- 「Redisが落ちたときのフォールバック戦略がない」
- 「RedisがSPOFになる」

といった指摘が返ってくる。

## CQoTとの違い

### CQoT(論文)

- **タイミング**: 回答生成プロセスの中に組み込む自動パイプライン
- **対象領域**: 数学・論理問題など「正解がある」領域
- **目的**: 論理的な誤りを事前に防ぐ
- **効果**: MT-Benchで平均約5%の精度向上を達成
- **4ステップのパイプライン構造**:
  1. 推論計画
  2. 批判的質問による検証
  3. 判定
  4. 最終回答

### `/criticalthink`(実装)

- **タイミング**: 回答が出た後にユーザーが手動で実行する後付けツール
- **対象領域**: ソフトウェア設計など「正解がない」領域
- **目的**: トレードオフやリスクを洗い出す
- **役割**: AIを「より慎重な設計レビュー相手」にする
- **人間中心**: 人間が最終判断を下すための材料を提供

**比喩的表現**

CQoTがAIを「より優れた論理学者」にするなら、`/criticalthink`はAIを「より慎重な設計レビュー相手」にする。

## 実際の使用体験

### 気づきの例

「READMEをレビューして」という入力に対して、AIが「このREADMEはslash-criticalthinkについて説明しています」と要約。その後`/criticalthink`を実行したら：

> 「『レビュー』の意図を確認していない。要約なのか、エラーチェックなのか、品質分析なのか、不明確なまま進めている」

**気づき**: 「レビューして」と言っただけでは、何を求めているのか曖昧だった。

### 限界の認識

- AI の批判的分析も完璧ではない
- 過剰に保守的な警告が混ざることもある
- 批判自体が的外れなこともある
- **重要**: この分析結果も鵜呑みにせず、自分で判断する必要がある

## 使い方のコツ

### 効果的な使用場面

すべての回答に使う必要はない(トークン消費と時間がかかる)。判断が重要な場面で使用：

- アーキテクチャの決定
- 大規模なリファクタリング
- セキュリティやパフォーマンスに関わる実装
- 外部ライブラリの導入

### チェックポイント機能との併用

不適切な批判的分析の履歴が残ると、その後のAIの思考が歪む(コンテキスト汚染)。

**推奨ワークフロー**:

1. AIから提案を受ける
2. `/criticalthink`で分析
3. 分析結果を吟味
4. 分析が不要だった場合、前のメッセージに戻る(批判的分析の履歴を破棄)
5. 新しい質問を続ける

これで、批判的思考の利点だけを取り出して使える。

## 余談：この記事自体の検証

**メタな実験**

このブログ記事はClaude Codeに書いてもらい、書き終わった後に`/criticalthink`を実行。

**発見された致命的な問題**

「CQoT論文のPDFを読まずに記事を作成している」

Claude CodeはREADMEを読んで概要は把握したつもりだったが、論文自体は精読していなかった。

**PDF精読後に追加された重要情報**:

- CQoTで使われている8つの批判的質問の具体的な内容
- 4ステップのパイプライン構造(推論計画 → 批判的質問による検証 → 判定 → 最終回答)
- MT-Benchでの定量的な評価結果(平均約5%の精度向上)
- 「回答生成前」ではなく「回答生成プロセスの中」で機能する仕組み

**教訓**

`/criticalthink`がなければ、表面的な理解に基づく記事になっていた。AIでは見落としていた前提の欠陥を明らかにし、このコマンドが目指している「批判的思考の補助線」として機能した実例。

## まとめ

**核心的メッセージ**

- AIは便利だが、盲信すると危ない
- CQoT研究が示すのは、AIに「自分を疑わせる」ことで出力の質を上げられるということ
- `/criticalthink`は、その考え方をコーディングエージェントで手軽に使えるようにしたツール
- AIの提案を受け入れる前に、一度立ち止まって考えるための補助線として機能

**最終的な判断を下すのは、常に人間である。**
