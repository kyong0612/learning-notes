---
title: Humanity's Last Exam
source: https://scale.com/leaderboard/humanitys_last_exam
author:
  - Scale AI
  - Center for AI Safety (CAIS)
published: 2025-01
created: 2025-05-25 14:46:47
description: AI研究の最前線における包括的なベンチマーク。現在のAIモデルが人間の専門知識レベルでいかに苦戦するかを示す
tags:
  - AI benchmark
  - evaluation
  - Scale AI
  - CAIS
  - machine learning
  - academic assessment
---

## 概要

「Humanity's Last Exam」は、Scale AIとCenter for AI Safety (CAIS)が共同で開発した革新的なAIベンチマークです。このベンチマークは「人類の最後の試験」として設計され、現在のAI研究の最前線における評価基準として機能します。

## プロジェクトの詳細

### 規模と範囲

- **問題数**: 2,500問
- **分野**: 100以上の学術分野（数学、人文学、自然科学など）
- **協力者**: 50カ国、500以上の機関から約1,000人の専門家が参加
- **資金**: 協力者向けに50万ドルの賞金プール

### 設計と目的

- **形式**: 多肢選択問題および完全一致問題、マルチモーダル（テキストと画像）
- **目的**: 「最終的な閉問題学術ベンチマーク」として、人間の知識の最前線でAIをテストする
- **背景**: 既存のベンチマーク（MMLU等）でAIモデルが90%以上の精度を達成する「ベンチマーク飽和」問題に対処

### 品質保証

- **方法論**: LLM難易度チェックと2段階の人間専門家レビューを含む厳格なプロセス
- **品質管理**: エラー検出のためのバグバウンティプログラムを実施
- **学術的根拠**: ArXivで詳細な方法論と結果を含む学術論文を公開

## 主要な結果

### 現在のAIモデルの性能

- **最高スコア**: o3 high（20.3%）
- **その他の主要モデル**:
  - Gemini 2.5 Pro: 18.3%
  - Claude-3.5-Sonnet: 17.0%
  - GPT-4o: 2.7%
- **キャリブレーション誤差**: 34-89%の高い値

### 重要な発見

1. **性能ギャップ**: 最先端のAIモデルでも専門レベルの学術問題では大幅に苦戦
2. **ベンチマーク革新**: 既存の評価基準での高い成績にもかかわらず、真の理解度では大きな限界が存在
3. **研究価値**: AI能力の現実的な評価と今後の研究方向性の指針を提供

## データセットの利用可能性

- **公開データセット**: 一般に利用可能
- **プライベートテストセット**: 継続的な評価のために維持
- **最終更新**: 2025年4月30日

## 学術的意義

このベンチマークは、AIの真の能力と限界を理解するための重要な評価ツールとして位置づけられています。特に、現在のAIモデルが人間の専門知識レベルにはまだ到達していないことを明確に示し、今後のAI研究の方向性を示唆する重要な研究成果となっています。
