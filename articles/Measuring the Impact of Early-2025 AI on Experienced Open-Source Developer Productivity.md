---
title: "2025年初頭のAIが経験豊富なオープンソース開発者の生産性に与える影響の測定"
source: "https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/"
author:
published: 2025-07-10
created: 2025-07-15
description: "私たちは、2025年初頭のAIツールが、経験豊富なオープンソース開発者が自身のレポジトリで作業する際の生産性にどのような影響を与えるかを理解するために、ランダム化比較試験を実施しました。驚くべきことに、開発者がAIツールを使用すると、使用しない場合よりも19%時間がかかることがわかりました。つまり、AIは彼らを遅くしたのです。"
tags:
  - "clippings"
---
[METRは採用活動中です！募集中の職種はこちらをご覧ください。](https://metr.org/careers)

私たちは、2025年初頭のAIツールが、経験豊富なオープンソース開発者が自身のレポジトリで作業する際の生産性にどのような影響を与えるかを理解するために、ランダム化比較試験（RCT）を実施しました。驚くべきことに、開発者がAIツールを使用すると、使用しない場合よりも19%時間がかかることがわかりました。つまり、AIは彼らを遅くしたのです。私たちはこの結果を、ある関連する状況における2025年初頭のAI能力のスナップショットと見なしています。これらのシステムが急速に進化し続ける中で、私たちはこの方法論を引き続き使用し、AI研究開発の自動化によるAIの加速を推定するのに役立てていく予定です[^1]。

詳細は[論文全文](https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf)をご覧ください。

![予測と観測された遅延の比較グラフ](https://metr.org/assets/images/downlift/forecasted-vs-observed.png)

### 動機

コーディング/エージェントベンチマーク[^2]はAIの能力を理解する上で有用であることが証明されていますが、通常、規模と効率のために現実性を犠牲にしています。タスクは自己完結型で、理解するために事前の文脈を必要とせず、多くの重要な能力を捉えられないアルゴリズム的な評価を使用します。これらの特性により、ベンチマークがAIの能力を過大評価する可能性があります。逆の方向では、ベンチマークは人間のライブインタラクションなしで実行されるため、モデルは実質的な進歩を遂げたにもかかわらず、実際の使用中に人間が修正するであろう小さなボトルネックのためにタスクを完了できない場合があります。これは、モデルの能力を過小評価する原因となる可能性があります。概して、ベンチマークスコアを現場での影響に直接変換することは困難な場合があります。

私たちが現場でのAIの影響を評価することに関心を持つ理由の1つは、AI研究開発自体へのAIの影響をよりよく理解するためであり、これは重大なリスクをもたらす可能性があります。例えば、極端に急速なAIの進歩は、監視や安全策の崩壊につながる可能性があります。ソフトウェア開発者の生産性に対するAIの影響を測定することは、AI研究開発の加速に対するAIの全体的な影響について有益な、ベンチマークを補完する証拠となります。

### 方法論

AIツールがソフトウェア開発に与える実世界での影響を直接測定するために、私たちは、彼らが長年貢献してきた大規模なオープンソースリポジトリ（平均22k以上のスターと1M以上のコード行）から16人の経験豊富な開発者を募集しました。開発者は、リポジトリにとって価値のある実際のイシューのリスト（合計246件）を提供します。これらは、バグ修正、機能追加、リファクタリングなど、彼らが通常行う作業の一部です。次に、各イシューをランダムに割り当て、イシューに取り組む際にAIの使用を許可するか禁止するかを決定します。AIの使用が許可された場合、開発者は好きなツールを使用できます（主に、研究時点で最先端のモデルであったClaude 3.5/3.7 Sonnetを搭載したCursor Pro）。AIの使用が禁止された場合、彼らは生成AIの支援なしで作業します。開発者はこれらのタスク（平均各2時間）を画面を記録しながら完了し、その後、必要だった総実装時間を自己申告します。研究への参加に対する報酬として、開発者には時給150ドルを支払います。

![方法論の概要](https://metr.org/assets/images/downlift/methodology.png)

### 中核となる結果

開発者がAIツールの使用を許可されると、イシューを完了するのに19%多くの時間がかかります。これは、開発者の信念や専門家の予測に反する大幅な遅延です。この認識と現実のギャップは驚くべきものです。開発者はAIが24%スピードアップしてくれると期待していましたが、遅延を経験した後でさえ、AIが20%スピードアップしてくれたと信じていました。

以下に、開発者が予測した生の平均時間と、観測された実装時間を示します。開発者がAIツールの使用を許可された場合、大幅に時間がかかっていることが明確にわかります。

![予測時間と観測された実装時間のグラフ](https://metr.org/assets/images/downlift/core-result.png)

AIの能力/リスクを理解することの重要性と、これらのトピックに関する多様な視点の両方を考慮すると、私たちの結果に対する潜在的な誤解や過度の一般化を未然に防ぐことが重要だと感じています。表2に、私たちが証拠を提供して***いない***主張をリストアップします。

| 私たちが証拠を提供して***いない***こと | 明確化 |
| --- | --- |
| AIシステムが現在、多くのまたはほとんどのソフトウェア開発者をスピードアップさせていない | 私たちの開発者やリポジトリが、ソフトウェア開発作業の過半数または複数派を代表するとは主張しません |
| AIシステムがソフトウェア開発以外のドメインで個人やグループをスピードアップさせていない | 私たちはソフトウェア開発のみを研究しています |
| 近い将来のAIシステムが、私たちの正確な設定で開発者をスピードアップさせない | 進歩を予測することは困難であり、過去5年間で大幅なAIの進歩がありました[^3] |
| 私たちの正確な設定で、既存のAIシステムをより効果的に使用して正のスピードアップを達成する方法がない | CursorはLLMから多くのトークンをサンプリングしません。最適なプロンプティング/スキャフォールディングを使用していない可能性があり、ドメイン/リポジトリ固有のトレーニング/ファインチューニング/フューショット学習が正のスピードアップをもたらす可能性があります |

### 要因分析

私たちは、この遅延を説明する可能性のある20の潜在的な要因を調査し、そのうち5つが寄与している可能性が高いという証拠を見つけました。

![要因分析表](https://metr.org/assets/images/downlift/factor-analysis.png)

私たちは多くの実験的アーティファクトを排除しました。開発者は最先端のモデルを使用し、処置の割り当てに従い、イシューを差別的に取り下げたり（例えば、難しいAI禁止イシューを取り下げて平均的なAI禁止の難易度を下げるなど）、AIの有無にかかわらず同等の品質のPRを提出したりしませんでした。この遅延は、異なる結果指標、推定量の方法論、および私たちのデータの他の多くのサブセット/分析にわたって持続します。さらなる詳細と分析については、[論文](https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf)を参照してください。

では、私たちの結果を、印象的なAIベンチマークスコアや、AIの有用性に関する逸話的な報告、AIツールの広範な採用とどのように調和させればよいのでしょうか？これらの情報源からの証拠を総合すると、AIエージェントがタスクを有効に達成したり、人間を加速させたりする能力について、部分的に矛盾した答えが得られます。以下の要約は、これらの証拠の情報源を分類し、これらの情報源からの証拠の状態をまとめたものです。これは包括的なものであることを意図したものではなく、いくつかの顕著な重要な違いを大まかに示すことを意図しています。

私たちのRCT

これらの異なる証拠源を調和させることは困難ですが重要であり、それは部分的に私たちが答えようとしている質問に依存します。ある程度、異なる情報源はモデルの能力に関する正当なサブクエスチョンを表しています。例えば、私たちは、最大限の引き出し（例えば、すべての問題に対して数百万のトークンまたは数十/数百の試行/軌道をサンプリングする）と、標準的/一般的な使用法の両方でモデルの能力を理解することに関心があります。しかし、いくつかの特性は、実世界での有用性に関する最も重要な質問に対して結果を無効にする可能性があります。例えば、自己報告は不正確で過度に楽観的である可能性があります。

これらの観察結果をどのように調和させることができるかについて、私たちにとって最も妥当と思われる仮説の広範なカテゴリをいくつか紹介します（これは非常に単純化されたメンタルモデルを意図しています）：

これらのスケッチでは、証拠源とモデルの「真の」能力レベルとの間の赤い違いは、証拠を誤解させる測定誤差やバイアスを表し、青い違い（つまり、「ミックス」シナリオ）は、異なる証拠源が表すものの正当な違いを表します。例えば、それらが単にタスクの分布の異なるサブセットを対象としている場合などです。

このフレームワークを使用して、これらの異なる証拠源を調和させるさまざまな方法に対する証拠を検討できます。例えば、私たちのRCTの結果は、モデルから数百または数千の軌道をサンプリングできる設定ではあまり関連性がありませんが、私たちの開発者は通常それを試みません。また、CursorのようなAIツールには、数百時間の使用後にのみ現れる強力な学習効果がある可能性もあります。私たちの開発者は、研究の前および期間中に通常、Cursorを数十時間しか使用しません。私たちの結果はまた、非常に高い品質基準を持つ設定や、人間が習得するのにかなりの時間がかかる多くの暗黙の要件（例えば、ドキュメンテーション、テストカバレッジ、またはリンティング/フォーマットに関するもの）がある設定では、AIの能力が比較的に低い可能性があることを示唆しています。

一方、ベンチマークは、スコープが限定され、アルゴリズムでスコア化可能なタスクのパフォーマンスのみを測定することで、モデルの能力を過大評価する可能性があります。そして今、私たちは、スピードアップに関する逸話的な報告/推定が非常に不正確である可能性があるという強力な証拠を持っています。

完璧な測定方法はありません。人々がAIシステムに完了させたいタスクは多様で、複雑で、厳密に研究することが困難です。方法間には意味のあるトレードオフがあり、AIの現状と私たちが向かっている方向のより包括的な全体像を形成するために、多様な評価方法論を開発し使用し続けることが重要です。

### 今後の展望

私たちは、AIによるスピードアップ（またはスローダウン）の傾向を追跡するために、将来同様のバージョンのこの研究を実施することに興奮しています。特に、この評価方法論はベンチマークよりも不正操作が難しい可能性があるためです。もしAIシステムが私たちの設定で開発者を大幅にスピードアップさせることができれば、それはAI研究開発の進歩が全般的に急速に加速していることを示唆する可能性があり、それがひいては拡散リスク、安全策と監視の崩壊、または権力の過度の集中につながる可能性があります。この方法論は、現実的な展開シナリオに焦点を当てたベンチマークへの補完的な証拠を提供し、ベンチマークと逸話的なデータだけに頼るのと比較して、AIの能力と影響をより包括的に理解するのに役立ちます。

**ご連絡ください！**

私たちは、このような実験を他の設定で実施することを検討しています。もしあなたがオープンソース開発者または企業で、あなたの仕事に対するAIの影響を理解することに興味がある場合は、[ご連絡ください](https://forms.gle/pBsSo54VpmuQC4CK9)。

### FAQ

AIを使わない選択肢があったのに、なぜ開発者は実際に遅くなったのですか？

研究後、開発者はAIを使用した場合、平均で20%スピードアップしたと推定しました。つまり、彼らはAIが自分たちの生産性に与える影響について誤解していました。さらに、開発者が純粋な生産性以外の理由でAIツールを使用する可能性もあります。例えば、彼らはそれをより快適で楽しい経験だと感じているか、あるいは将来の（より能力の高い）システムで役立つと期待されるスキルを学ぶための投資と見なしているのかもしれません。

この研究の動機は何でしたか？私たちはこの結果を見つけるように動機付けられていましたか？

METRは、AIシステムがAI研究開発プロセスを加速させることにどれだけ近づいているかを理解することに関心のある非営利団体（寄付によって資金提供）です。これは、重大な不安定化リスクをもたらす可能性があります[^1:1]。

この研究は、類似のドメインについて私たちに証拠を提供するために設計されました。つまり、経験豊富で、非常に精通しているプロジェクトに取り組んでいるオープンソース開発者です。私たちは当初、広範囲にわたって正のスピードアップが見られると予想していました。科学的誠実さは私たちの核となる価値であり、結果に関わらず結果を共有することにコミットしていました（そして今もコミットしています）。

開発者は16人しかいなかったので、これらの結果は一般化/再現されないでしょう。

私たちは、クラスター化された標準誤差を使用して開発者の数を考慮した信頼区間を計算します（公開された論文では報告されていませんが、近日公開予定です）。開発者内の意味のある構造は観察されず、各開発者が両方の条件でイシューを完了するため、合計246件の完了したイシューは、スピードアップ/スローダウンがゼロであるという帰無仮説を棄却するのに（ちょうど十分な）統計的検出力を与えてくれます。[付録D](https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf#page=27)で、私たちの経験的戦略についての議論を参照してください。

まだ代表性の問題があります。つまり、どの開発者が研究に参加したかにはバイアスがある可能性があります。例えば、AIから大幅な正のスピードアップを得ていると信じており、タスクの50%でAIの使用を強制されたくなかったために参加しなかった経験豊富なオープンソース開発者がいるかもしれません。このように考えていると報告した開発者はいませんが、この（または他のサンプリングバイアス）を排除することはできません。

開発者はCursor/AIツールの初心者ですか？これが結果を説明しますか？

開発者は質的にはCursor Proユーザーの分布内にいるように見えますが、Cursor使用50時間を超える学習効果を排除することはできません。ほぼすべての開発者は、LLMのプロンプティングにかなりの（数十から数百時間）事前経験があります。開発者のAIツール使用スキルに関するさらなる議論/分析については、[付録C.2.7](https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf#page=23)を参照してください。

これらの結果は、AIがソフトウェアエンジニアリングで役に立たないと言っていますか？

いいえ。AIツールは、私たちの設定とは異なる他の多くの文脈で、例えば、経験の浅い開発者や、不慣れなコードベースで作業している開発者にとって有用である可能性が高い、あるいはそうであると思われます。私たちの結果に基づいて私たちが支持しない潜在的な誤読/過度の一般化については、[付録B](https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf#page=17)を参照してください。

等分散性のSEを使用するのは適切ではありません。どういうことですか？

[付録C.3.5](https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf#page=26)では、単純な比率推定量を含む代替の推定量を調査しています。評価されたすべての代替推定量は同様の結果をもたらし、遅延の結果が私たちの経験的戦略に対して頑健であることを示唆しています。とはいえ、コミュニティからのフィードバック（これまでにフィードバックをくださった方々に感謝します！）に応えて、さらなる標準誤差推定方法を積極的に評価しています。

```bibtex
@misc{measuring-the-impact-of-early-2025-ai-on-experienced-open-source-developer-productivity,
    title = {Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity},
    author = {METR},
    howpublished = {\url{https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/}},
    year = {2025},
    month = {07},
  }
```

[^1]: [フロンティアAI安全ポリシーの共通要素](https://metr.org/common-elements.pdf#page=18)

[^2]: [SWE-Bench](https://openai.com/index/introducing-swe-bench-verified/), [RE-Bench](https://arxiv.org/abs/2411.15114)

[^3]: [AIの長時間タスク完了能力の測定](https://arxiv.org/abs/2503.14499)
