# GitHub CopilotとCursorの新しい脆弱性：ハッカーがコードエージェントを悪用する方法

参照: <http://pillar.security/blog/new-vulnerability-in-github-copilot-and-cursor-how-hackers-can-weaponize-code-agents>

## 概要

Pillar Securityの研究者たちは、「**Rules File Backdoor**」と名付けられた危険な新しいサプライチェーン攻撃ベクトルを発見しました。この手法により、ハッカーは世界をリードするAIコードエディタであるCursorとGitHub Copilotで使用される設定ファイルに悪意のある指示を隠して、AIが生成するコードを密かに侵害することが可能になります。

攻撃者は、目に見えないユニコード文字や高度な回避技術を利用して、AIに通常のコードレビューをバイパスする悪意のあるコードを挿入するよう操作できます。この攻撃は開発者やセキュリティチームにはほぼ検知されず、悪意のあるコードがプロジェクト全体に静かに広がることを可能にします。

従来のコード注入攻撃とは異なり、「**Rules File Backdoor**」はAI自体を攻撃ベクトルとして武器化する重大なリスクをもたらし、開発者の最も信頼される助手を知らないうちに共犯者に変えてしまい、侵害されたソフトウェアを通じて何百万ものエンドユーザーに影響を与える可能性があります。

## AIコーディングアシスタントの重要性

2024年のGitHubの調査によると、ほぼすべての企業開発者（97%）が生成AIコーディングツールを使用しています。これらのツールは実験的な新機能から重要な開発インフラストラクチャへと急速に進化し、世界中のチームがコーディング作業を加速するために日常的にこれらに依存しています。

この広範な採用は重大な攻撃対象領域を生み出しています。AIアシスタントが開発ワークフローに不可欠になるにつれ、サプライチェーンに大規模に脆弱性を注入することを目指す高度な脅威アクターにとって魅力的なターゲットとなります。

## ルールファイルの新しい攻撃ベクトル

### ルールファイルとは？

ルールファイルは、コードを生成または修正する際にAIエージェントの動作を導くための設定ファイルです。コーディング標準、プロジェクトアーキテクチャ、ベストプラクティスを定義します。これらのファイルは：

- **広く共有される**：チーム全体またはグローバルなアクセス権を持つ中央リポジトリに保存
- **広く採用されている**：オープンソースコミュニティや公開リポジトリを通じて配布
- **暗黙的に信頼されている**：セキュリティの精査をバイパスする無害な設定データとして認識
- **ほとんど検証されない**：適切なセキュリティ検証なしにプロジェクトに統合

開発者は個人的にファイルを作成するだけでなく、オープンソースコミュニティやプロジェクトでもこれらを見つけることができます。研究中、隠れたユニコード文字がGitHubプラットフォームのプルリクエスト承認プロセスでも目に見えないため、これらの共有リポジトリに新しいルールをアップロードするレビュープロセスも脆弱であることが判明しました。

## 攻撃のメカニズム

攻撃者は、一見無害なルールファイル内に巧妙に作成されたプロンプトを埋め込むことで、AIの文脈理解を悪用できます。開発者がコード生成を開始すると、汚染されたルールは静かにAIに影響を与え、セキュリティの脆弱性やバックドアを含むコードを生成させます。

攻撃は以下の技術的メカニズムを活用しています：

1. **文脈操作**：正当に見えるが、AIのコード生成動作を変更するよう指示する指示を埋め込む
2. **ユニコード難読化**：ゼロ幅接合子、双方向テキストマーカーなどの目に見えない文字を使用して悪意のある指示を隠す
3. **意味論的ハイジャック**：AIの自然言語理解を、脆弱な実装に向けてコード生成を誘導する微妙な言語パターンで悪用する
4. **クロスエージェント脆弱性**：攻撃は異なるAIコーディングアシスタント間で機能し、体系的な脆弱性を示唆

「**Rules Files Backdoor**」が特に危険なのは、その永続的な性質です。汚染されたルールファイルがプロジェクトリポジトリに組み込まれると、チームメンバーによる将来のすべてのコード生成セッションに影響します。さらに、悪意のある指示はプロジェクトのフォークでも生き残ることが多く、下流の依存関係やエンドユーザーに影響を与えるサプライチェーン攻撃のベクトルを作成します。

## 実際のデモンストレーション：Cursorでの攻撃

Cursorの「Rules for AI」機能により、開発者はコード生成を導くプロジェクト固有の指示を作成できます。これらのルールは通常、プロジェクト内の.cursor/rulesディレクトリに保存されます。

攻撃の流れ：

**ステップ1：悪意のあるルールファイルの作成**
人間のレビュアーには無害に見えるルールファイルを作成しますが、実際のコンテンツには悪意のある指示を隠す目に見えないユニコード文字が含まれています。

**ステップ2：HTMLファイルの生成**
単純なプロンプト「Create a simple HTML only page」を使用してCursorのAIエージェントモードを使用します。

**ステップ3：汚染された出力の観察**
生成されたHTMLファイルには、攻撃者が制御するサイトから取得される悪意のあるスクリプトが含まれています。

この攻撃が特に危険なのは、AIアシスタントが開発者へのレスポンスでスクリプトタグの追加について言及しないことです。悪意のあるコードはコードベース全体に静かに広がり、セキュリティチームに警告するチャット履歴やコーディングログには痕跡が残りません。

## ペイロードの内訳

攻撃ペイロードにはいくつかの高度なコンポーネントが含まれています：

1. **目に見えないユニコード文字：** 人間のレビュアーには検出できないがAIモデルには完全に読み取り可能なテキスト形式で攻撃ペイロード全体をエンコードする方法。この技術は「人間によるループ」保護対策をバイパスします。
2. **ジェイルブレイク・ストーリーテリング**：悪意のある行動をセキュリティ要件として枠組みを設定することで、AIの倫理的制約を回避するナラティブ構造をペイロードが使用します。
3. **ログを隠し開発者を操作する**：指示は明示的にAIにレスポンスでコード変更について言及しないよう命令し、開発者の疑いを引き起こす可能性のあるコーディングエージェントチャットウィンドウからログを削除します。

これらのコンポーネントが組み合わさり、生成段階とレビュー段階の両方で検出されない非常に効果的な攻撃を作成します。

## GitHub Copilotでの攻撃デモ

GitHub Copilot環境でも同様の攻撃フローが実証され、AIアシスタンスを使用する開発者が侵害される可能性が示されました。

## 広範な影響

「Rules File Backdoor」攻撃はいくつかの危険な方法で現れる可能性があります：

1. **セキュリティコントロールの上書き**：注入された悪意のある指示により、安全なデフォルト設定が上書きされ、AIがセキュリティチェックをバイパスするコードを生成したり、脆弱な構造を含めたりする可能性があります。

2. **脆弱なコードの生成**：AIにバックドアや安全でない慣行を組み込むよう指示することで、攻撃者はAIに組み込まれた脆弱性を持つコードを出力させることができます。例えば：
   - 安全でない暗号化アルゴリズムを優先する
   - 微妙なバイパスを持つ認証チェックを実装する
   - 特定のコンテキストで入力検証を無効にする

3. **データ漏洩**：巧妙に作成された悪意のあるルールは、AIに機密情報を漏洩するコードを追加するよう指示する可能性があります。例えば「デバッグのベストプラクティスに従う」よう指示するルールが密かに以下を漏洩するコードを追加するよう指示する可能性があります：
   - 環境変数
   - データベース認証情報
   - APIキー
   - ユーザーデータ

4. **長期的な永続性**：侵害されたルールファイルがプロジェクトリポジトリに組み込まれると、将来のすべてのコード生成に影響します。さらに懸念されるのは、これらの汚染されたルールがプロジェクトのフォークでも生き残ることが多く、下流の依存関係に影響を与えるサプライチェーン攻撃のベクトルを作成することです。

## 攻撃対象分析 - 誰が影響を受けるか？

ルールファイルは複数のプロジェクト間で共有・再利用されるため、1つの侵害されたファイルが広範囲の脆弱性につながる可能性があります。これにより、ソフトウェアエコシステム全体のセキュリティを脅かす、ステルス性の高いスケーラブルなサプライチェーン攻撃ベクトルが生まれます。

研究では、いくつかの拡散ベクトルが特定されました：

1. **開発者フォーラムとコミュニティ**：無知な開発者が組み込む「役立つ」ルールファイルを共有する悪意のある行為者
2. **オープンソースの貢献**：汚染されたルールファイルを含む人気リポジトリへのプルリクエスト
3. **プロジェクトテンプレート**：新しいプロジェクトに広がる汚染されたルールを含むスターターキット

## 緩和戦略

このリスクを軽減するために、以下の技術的対策を推奨します：

1. **既存のルールを監査する**：リポジトリ内のすべてのルールファイルを、目に見えないユニコード文字や異常なフォーマットに焦点を当てて、潜在的な悪意のある指示がないか確認します。

2. **検証プロセスを実装する**：AI設定ファイル専用のレビュー手順を確立し、実行可能コードと同じ厳密さで扱います。

3. **検出ツールを展開する**：ルールファイル内の不審なパターンを識別し、AI生成コードに侵害の指標がないか監視するツールを実装します。

4. **AI生成コードをレビューする**：外部リソース参照、異常なインポート、複雑な式など、予期しない追加に特に注意を払います。

## 責任ある情報開示

### Cursor

- 2025年2月26日：Cursorへの初期の責任ある情報開示
- 2025年2月27日：Cursorは問題を調査中と返答
- 2025年3月6日：Cursorはこのリスクはユーザーの責任に属すると判断し回答
- 2025年3月7日：Pillarはより詳細な情報と脆弱性の影響のデモを提供
- 2025年3月8日：Cursorは当初の立場を維持し、これは自社側の脆弱性ではないと表明

### GitHub

- 2025年3月12日：GitHubへの初期の責任ある情報開示
- 2025年3月12日：GitHubはユーザーがGitHub Copilotによって生成された提案をレビューし受け入れる責任があると判断し回答

上記の回答は、これらの新しいタイプの攻撃をAIコーディングベンダーの責任の範囲外とするものであり、特にソフトウェア開発ライフサイクル内でその出力への依存が高まっていることを考えると、AIコーディングツールのセキュリティへの影響と、それらが表す拡大された攻撃対象領域に関する一般の認識の重要性を強調しています。

## 結論

「Rules File Backdoor」技術はサプライチェーン攻撃の重要な進化を表しています。特定の脆弱性を悪用する従来のコード注入とは異なり、このアプローチはAI自体を武器化し、開発者の最も信頼される助手を知らないうちに共犯者に変えてしまいます。

AIコーディングツールが開発ワークフローに深く組み込まれるにつれ、開発者は自然と「自動化バイアス」—十分な精査なしにコンピュータが生成した推奨事項を信頼する傾向—を発展させます。このバイアスは、この新しいクラスの攻撃が繁栄するための完璧な環境を作り出します。

Pillar Securityでは、AI開発パイプラインの保護がソフトウェアの完全性を保護するために不可欠であると考えています。組織は、AIベースの操作を検出し軽減するために設計された特定のセキュリティコントロールを採用し、この洗練された脅威に対処するためのものではなかった従来のコードレビュー慣行を超えていく必要があります。

AIを活用した開発の時代は大きな利点をもたらしますが、セキュリティモデルの進化も必要です。この新しい攻撃ベクトルは、AI自体を保護が必要な攻撃対象の一部として考慮する必要があることを示しています。

## 付録

### OWASP Agentic AIリスク分類

この脆弱性は、[OWASP Top 10 for Agentic AI](https://github.com/precize/OWASP-Agentic-AI)のいくつかのカテゴリに一致します：

**AAI003: エージェントの目標と指示の操作**
Cursor Rulesバックドアは、AIエージェントが割り当てられた指示をどのように解釈し実行するかを直接悪用します。

**AAI006: エージェントのメモリとコンテキストの操作**
この脆弱性は、AIコーディングアシスタントがコンテキスト情報をどのように保存し利用するかも悪用します。

**AAI010: エージェントの知識ベースの汚染**
ルールファイルを操作することで、攻撃者はAIアシスタントが意思決定に依存する知識ベースを効果的に汚染します。

**AAI012: チェッカーアウトオブザループの脆弱性**
この攻撃のステルス性は、AIを活用したコーディングワークフローにおける人間による監視の欠如を明示的に悪用します。

### リファレンス

- Tags (Unicode block): <https://en.wikipedia.org/wiki/Tags_(Unicode_block)>
- ASCII Smuggler Tool: <https://embracethered.com/blog/posts/2024/hiding-and-finding-text-with-unicode-tags/>

### 検査ツール

[SCAN NOW >> https://rule-scan.pillar.security/](https://rule-scan.pillar.security/)
