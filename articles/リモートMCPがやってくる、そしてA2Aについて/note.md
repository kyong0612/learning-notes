# リモートMCPがやってくる、そしてA2Aについて

ref: <https://blog.lai.so/remote-mcp/>

## Streamable HTTP Transport (MCP TypeScript SDK 1.10.0)

* MCP TypeScript SDK 1.10.0 で、従来のSSE Transport（2024-11-05）を置き換える**Streamable HTTP Transport**が導入されました（Python SDKは未対応）。
* **従来の課題:** クライアントはサーバーに継続的に接続（標準入出力やSSE）してセッションを維持する必要がありました。
* **新方式:** クライアントは1回のHTTP POSTリクエストでセッションを開始できます。
* **リアルタイムプッシュ (オプション):** サーバーからクライアントへのデータ送信には、引き続きServer-Sent Events (SSE) を利用できます。これは、サーバーからの要求が必要なSampling仕様の実装に役立ちます。
* **参考資料:** azukiazusa氏の記事「[MCP サーバーの Streamable HTTP transport を試してみる](https://azukiazusa.dev/blog/mcp-server-streamable-http-transport/?ref=blog.lai.so)」では、Node.jsとExpressでの実装例が紹介されています。

![](https://blog.lai.so/content/images/thumbnail/mcp-server-streamable-http-transport.png)

## ステートレスモードとCloudflareのAgents SDK

* Streamable HTTP Transportには**ステートレスモード**が追加されました。
  * セッションを確立せず、リクエストごとに独立した関数としてエンドポイントを動作させます。
  * サーバーレスプラットフォーム（AWS Lambda、Vercelなど）でのリモートMCPサーバーデプロイに適しています。
* **従来のセッション管理:** リファレンス実装では、セッションごとにTransportオブジェクトをインスタンス化し、サーバープロセス内で保持していました。マルチプロセス/サーバーレス環境では、プロセス間での共有が困難でした。
* **Cloudflare Workersのアプローチ:**
  * **Agents SDK**は**Durable Objects**を活用し、セッションごとのTransportオブジェクトを永続化します。
  * Node.jsサーバーとCloudflare Workers環境の差異（Request/Responseオブジェクトなど）を吸収する変換レイヤーも提供します。
  * 最近、Cloudflare Workersの**無料プランでDurable Objectsが利用可能**になり、リモートMCPサーバー構築が容易になりました。
  * **参考実装 (筆者):** [tltr MCP Server on Cloudflare Workers (Gist)](https://gist.github.com/laiso/8e45236886bd24dc865dde557db11465?ref=blog.lai.so) (試作版、セッション非対応)

![](https://blog.lai.so/content/images/thumbnail/gist-og-image-54fd7dc0713e-3.png)

* **他のプラットフォーム (Vercel, AWS Lambda):**
  * Durable Objectsのようなネイティブ永続化メカニズムがないため、開発者が自前で状態管理を実装する必要があります（例: Redis, DynamoDB）。
  * **ステートレスモード**はこの永続化が不要なため、デプロイが簡素化されます。
  * **参考実装 (moritalous氏):** [AWS Lambdaサンプル (GitHub)](https://github.com/moritalous/mcp-streamablehttp-lambda-sample?ref=blog.lai.so) (ステートレスモード活用)
* **ステートレスモードの認証:**
  * 認証不要なサーバーに適していますが、クライアント実装前提であれば**認証が必要な場合でも利用可能**です（例: リクエストごとにJWTアクセストークンを含める）。
* **将来展望:** これらの更新は、リモートMCPサーバーのユースケースやスケーリング問題に対応するものであり、今後の活用が期待されます。

## A2A（Agent2Agent）プロトコルとの比較

* Googleが発表したAIエージェント向けAPI仕様**A2Aプロトコル**は、リモートMCPを置き換えるものでしょうか？
* **A2Aの特徴:**
  * サーバーは`/.well-known/agent.json`で**Agent Card** (JSON) を公開し、メタ情報を提供します。
    * 例: Googleの「両替エージェント」のAgent Card

        ![](https://blog.lai.so/content/images/2025/04/image-9.png)
  * Agent Cardには`skills`が含まれますが、MCPのToolのような引数型情報は持ちません。
  * A2Aは**プレーンなテキスト**を送受信し、その解釈や処理はサーバー側の実装（LLMやルールベース）に委ねられます。
* **MCPとの違い:**
  * MCPのToolは**引数の型情報 (inputSchema)** を要求し、LLMがこれを埋めて呼び出します。

    ![](https://blog.lai.so/content/images/2025/04/image-10.png)
  * メッセージングの手続きが異なり、A2Aはより**抽象的なサーバー間呼び出し仕様**です。
  * **結論:** A2AとMCPは**レイヤーが異なり、置き換えられるものではありません**。A2Aサーバー内部でMCPサーバーを呼び出すシナリオは考えられます。
* **A2Aのその他の仕様:**
  * **Task:** 処理中のリソース管理。
  * **Push Notification:** 進捗管理やリアルタイム通知。
  * これらはLLM呼び出しを含む時間のかかるマルチエージェントシステムをサポートするための仕組みです（MCPのスコープ外）。
* **A2Aへの期待について:**
  * A2AがMCPのような熱狂を生むと期待するのは**時期尚早**です。
  * A2Aは分散システムの部品として利用される**渋めのバックエンド技術**であり、エンドユーザーへの直接的な影響は不明です。ECサイトの決済ネットワークのように、消費者レベルでは意識されない可能性もあります。

---

**重要なポイント:**

* MCP TypeScript SDK 1.10.0で導入された**Streamable HTTP Transport**は、1回のHTTP POSTでセッションを開始でき、サーバーレス環境でのデプロイを容易にする**ステートレスモード**も提供します。
* Cloudflare Workersの**Agents SDK**は**Durable Objects**を活用してセッション管理を簡素化します。
* Googleの**A2Aプロトコル**は、MCPとは異なるレイヤーの抽象的なサーバー間呼び出し仕様であり、MCPを置き換えるものではありません。

**制限事項:**

* 現時点（記事執筆時）で、MCP Python SDKにはStreamable HTTP Transportの更新は含まれていません。
* A2Aプロトコルの具体的な適用方法やエンドユーザーへの影響はまだ不明です。

この要約は、元の記事の主要な情報と構造を保持しつつ、簡潔にまとめたものです。技術的な正確性も維持するよう努めました。

## 補足情報（詳細版）

### Streamable HTTP Transport 詳細

MCP TypeScript SDK 1.10.0 (プロトコルバージョン `2025-03-26`) で導入された、クライアント・サーバー間の通信方式です。従来の常時接続方式（標準入出力やSSE Transport v`2024-11-05`）が抱えていた、特にリモート環境やサーバーレス環境でのスケーラビリティやリソース管理の課題を解決することを目的としています。

* **技術的基盤:** 標準的な **HTTP/1.1 (または HTTP/2) のストリーミング機能** を活用します。
  * **クライアント → サーバー:** クライアントは単一の HTTP POST リクエストを開始します。リクエストボディはストリーミングされ、クライアントはメッセージを逐次送信できます。
  * **サーバー → クライアント:** サーバーはこのPOSTリクエストに対するレスポンスとして、自身のメッセージをストリーミングで返します。これにより、サーバーは処理の完了を待たずに、結果や進捗をリアルタイムに近い形でクライアントに送信できます。
  * **双方向性:** この単一のPOSTリクエストとレスポンスのストリーム内で、実質的な双方向通信（リクエスト/レスポンスの応酬）が行われます。
* **Server-Sent Events (SSE) の役割 (オプション):**
  * 基本的なメッセージ交換は上記のPOSTストリームで行われますが、サーバーから能動的に（クライアントからのリクエストなしに）通知を送りたい場合があります。
  * 具体的には、MCPの **Sampling 仕様**（サーバーがクライアントに追加情報を要求するケースなど）や、長時間タスクの非同期な進捗通知に対応するために、**オプション**としてSSEを利用できます。
  * クライアントはSSE専用の別接続（HTTP GET）を確立し、サーバーはこの接続を通じてプッシュ通知を行います。
* **利点の詳細:**
  * **サーバーレス親和性向上:** リクエストごとに処理を開始・終了するモデル（特にステートレスモード）は、AWS Lambda, Cloudflare Workers, Vercel Functions など、実行時間に制限があったり、状態保持が難しいサーバーレス環境に最適化されています。インフラ管理のオーバーヘッドを削減できます。
  * **標準Web技術の活用:** HTTP/SSEはWeb開発における標準技術であり、既存のWebインフラ（ロードバランサー、CDN、APIゲートウェイ、プロキシ）、監視ツール、開発者の知識やライブラリをそのまま活用できます。
  * **実装の柔軟性:** 常時接続の管理（接続維持、再接続ロジック、アイドルタイムアウトなど）が不要になるため、特定のユースケース（特にステートレスなAPI）ではサーバー実装が簡素化されます。
* **ステートレスモード vs ステートフルモード:**
  * **ステートレスモード:** 各リクエストは独立しており、サーバーは過去のリクエスト情報を記憶しません。状態はクライアント側で管理するか、リクエスト自体に含める（例: JWTトークン）必要があります。サーバー側の実装はシンプルでスケールしやすいですが、会話の文脈維持などはクライアントの責任となります。
  * **ステートフルモード:** サーバーはクライアントごとのセッション状態（会話履歴、コンテキストなど）を保持します。これにより複雑な対話が可能になりますが、サーバー側での状態管理が必要になります。Cloudflare Workers の Durable Objects はこのステートフルな実装を支援する仕組みの一例です。他のプラットフォームでは外部DB（Redis, DynamoDBなど）での状態管理が必要になる場合があります。
* **考慮事項:**
  * **Python SDK 未対応:** 現時点では、MCP Python SDKはこの `Streamable HTTP Transport` に対応していません。
  * **ネットワーク遅延:** リモート通信であるため、ネットワークの遅延や不安定さがパフォーマンスに影響を与える可能性があります。
  * **デバッグ:** 通信が単一のHTTPリクエスト/レスポンスに集約されるため、問題発生時の切り分けやデバッグが従来の接続方式と異なる場合があります。

### リモートMCP 詳細

Model Context Protocol (MCP) を利用したクライアント・サーバー間の通信を、**ネットワーク越し**に行うアーキテクチャパターンです。

* **基本的な考え方:** クライアント（例: ローカルPC上のCursor）と、AI機能を提供するMCPサーバーが、インターネットやローカルネットワークなどのネットワークを介して接続・通信します。
* **ローカルMCPとの対比:**
  * **ローカル:** MCPサーバー（またはその一部）がクライアントと同じマシン上で動作します。セットアップは簡単ですが、リソースはローカルマシンに依存し、機能共有は困難です。
  * **リモート:** MCPサーバーは別のマシン（物理サーバー、仮想マシン、クラウドインスタンス、サーバーレス環境など）で動作します。ネットワーク通信が発生しますが、リソースのスケーラビリティや機能共有の面で優れています。
* **なぜリモートMCPが必要か？ (動機):**
  * **計算リソースの集約:** 大規模なAIモデル（特にGPUを必要とするもの）は高価で管理も複雑です。これらを強力な中央サーバーに集約し、複数のクライアントから共有することでコスト効率を高めます。
  * **独自/機密データの利用:** 社内データベースや独自のAPIにアクセスするようなカスタムツールを、データを外部に出すことなく安全なサーバー環境で実行し、その結果だけをクライアントに提供したい場合。
  * **スケーラビリティと可用性:** 多数のユーザーが同時に利用する場合、クラウドのスケーラブルなインフラ上でMCPサーバーを運用することで、負荷に対応し、安定したサービスを提供できます。
  * **サービスとしての提供:** 開発したAIツールや機能を、MCPインターフェースを通じて他の開発者やサービスに提供したい場合。
* **具体的なユースケース例:**
  * **サーバーレスAIツール:** 特定のタスク（例: コードレビュー、ドキュメント生成）を実行するMCPサーバーをAWS Lambdaで構築し、Cursorから呼び出す。
  * **社内コード検索:** 社内の大規模コードベースをインデックス化し、セマンティック検索を提供するMCPサーバーを構築・運用。
  * **GPU推論サービス:** 最新のLLMや画像生成モデルをGPUサーバー上でホストし、MCP経由で推論機能を提供。
* **アーキテクチャ上の考慮事項:**
  * **ネットワーク:** 遅延、帯域幅、安定性がパフォーマンスに直接影響します。適切なネットワーク設計が必要です。
  * **セキュリティ:** 通信経路の暗号化 (TLS/SSL)、認証（誰がアクセスできるか）、認可（何を実行できるか）の実装が不可欠です。
  * **状態管理 (ステートフルな場合):** 複数のクライアントセッションの状態をどのように管理・永続化するかが課題となります（前述のステートレス/ステートフルの議論）。
  * **デプロイと運用:** サーバーのデプロイ、監視、ロギング、アップデートなどの運用体制が必要です。
* **`Streamable HTTP Transport` との関係:** このトランスポートは、特にサーバーレス環境や標準的なWebインフラ上でリモートMCPサーバーを構築・運用する際の技術的な障壁を低減し、より容易にリモートMCPを実現するための重要な選択肢となります。
