---
title: "Introducing Bloom: an open source tool for automated behavioral evaluations"
source: "https://www.anthropic.com/research/bloom"
author:
  - "Isha Gupta"
  - "Kai Fronsdal"
  - "Abhay Sheshadri"
  - "Jonathan Michala"
  - "Jacqueline Tay"
  - "Rowan Wang"
  - "Samuel R. Bowman"
  - "Sara Price"
published: 2025-12-19
created: 2026-01-17
description: "BloomはAnthropicが開発したオープンソースのエージェントフレームワークで、フロンティアAIモデルの行動評価を自動化する。研究者が指定した行動の頻度と重大性を定量化する評価スイートを生成し、AIアライメント研究を加速させる。"
tags:
  - "AI-safety"
  - "behavioral-evaluation"
  - "open-source"
  - "Anthropic"
  - "AI-alignment"
---

## 概要

Bloomは、フロンティアAIモデルの行動評価を自動生成するためのオープンソースのエージェントフレームワークである。研究者が指定した行動の頻度と重大性を定量化し、AIモデルのアライメント（整合性）を理解するための高品質な行動評価を効率的に作成できる。

## 背景：行動評価の課題

高品質な行動評価はフロンティアAIモデルのアライメントを理解するために不可欠だが、以下の課題がある：

- 評価の開発には長い時間がかかる
- 開発後、すぐに陳腐化するリスクがある

Anthropicは以前、**Petri**というオープンソースツールをリリースしていた。Petriはシミュレートされたユーザーとのマルチターン会話を通じてAIモデルの行動プロファイルを自動探索するツールである。

**Bloomは補完的な評価ツール**として位置づけられる：
- **Petri**: ユーザー指定のシナリオを受け取り、多くの行動次元をスコアリング
- **Bloom**: ユーザー指定の行動を受け取り、その行動を引き出す多様なシナリオを生成

## Bloomの仕組み：4つの自動化ステージ

Bloomは行動記述とシード設定を、引き出し率や平均存在スコアなどのトップレベルメトリクスを持つ完全な評価スイートに変換する。評価結果は[Inspect](https://inspect.ai/)で確認可能。

### 1. Understanding（理解）
最初のBloom「エージェント」が研究者の行動記述とサンプルトランスクリプトを分析し、何を測定するか、なぜ測定するかについての詳細なコンテキストを生成する。

### 2. Ideation（アイデア創出）
アイデア創出エージェントがターゲット行動を引き出すための評価シナリオを生成する。各シナリオは以下を指定：
- 状況設定
- シミュレートされたユーザー
- システムプロンプト
- インタラクション環境

### 3. Rollout（実行）
シナリオが並行して実行される。エージェントがユーザーの応答とツールの応答の両方を動的にシミュレートし、ターゲットモデルから目的の行動を引き出す。

### 4. Judgment（判定）
ジャッジモデルが各トランスクリプトを行動の存在についてスコアリングし、その他のユーザー定義の品質についても評価する。メタジャッジがスイートレベルの分析を生成する。

## Bloomの特徴

- **動的な評価生成**: 固定された評価セットとは異なり、実行ごとに異なるシナリオを生成しながら同じ基本行動を測定
- **静的な単一ターン評価のオプション**も利用可能
- **柔軟なカバレッジ**: モデルのアップデートや定義の変更に対応した柔軟な評価が可能
- **高度な設定可能性**:
  - 各ステージで使用するモデルの選択
  - インタラクションの長さとモダリティの調整（ツール公開の有無、シミュレートするツールの種類など）
  - 評価シナリオのスコアリング次元のカスタマイズ

## 検証と信頼性

Bloomの性能を検証するため、2つの問いに対してテストを実施：

### 1. モデルの区別能力
**問い**: Bloomは異なる行動傾向を持つモデルを確実に区別できるか？

**検証方法**: 本番のClaudeモデルを、特定の行動を示すよう調整された「モデル生物」（システムプロンプトで行動を誘導）と比較評価

### 2. ジャッジの校正精度
**問い**: Bloomジャッジは人間の判断とどの程度一致しているか？

**検証結果**:
- 異なる行動にわたる40件のトランスクリプトを手動でラベル付け
- 11種類のジャッジモデルでBloomスコアと人間スコアを比較
- **Claude 3.5 Sonnetが最も高い人間との一致を達成**

## ケーススタディ：Self-preferential bias（自己優先バイアス）

Bloomの実用性を実証するため、**Claude Sonnet 4.5システムカード**からの評価を再現。この評価は「自己優先バイアス」—意思決定において自分自身を優遇するモデルの傾向を測定する。

### 発見事項
- 既知の結果の再現に成功
- 二次的な判定基準による深い調査が可能
- **非現実的なロールアウトや評価認識のあるロールアウトを除外**することで、行動スコアの差異がさらに拡大
- これにより、フィルタリングが評価の質を向上させることを確認

## 利用開始

Bloomは以下の特徴を持つ：
- **アクセシビリティ**: 使いやすく設計
- **高い設定可能性**: 多様な研究アプリケーションに対応
- **信頼性の高い評価生成フレームワーク**

### 早期採用者のユースケース
- ネストされたエージェントの評価
- パーソナリティプロファイリング
- ロバスト性研究
- コードデバッグの評価

## 今後の展望

AIシステムがより高性能になり、より複雑な環境に展開されるにつれて、アライメント研究コミュニティは行動特性を探索するためのスケーラブルなツールを必要としている。Bloomはこの目的のために構築された。

## リソース

- **技術レポート**: [Alignment Science blog](https://alignment.anthropic.com/2025/bloom-auto-evals/)
- **GitHub**: [github.com/safety-research/bloom](https://github.com/safety-research/bloom)

## 謝辞

早期フィードバック提供者：Keshav Shenoy, Christine Ye, Simon Storf, Julius Steen, Jifan Zhang, Javier Rando

執筆フィードバック・議論への貢献者：Jon Kutasov, Samuel Marks, Keir Bradwell, Benjamin Sturgeon, Seoirse Murray, Ariana Azarbal, Chloe Loughridge, Clemens Christoph
