---
title: "Prompting for Agents"
source: "https://www.youtube.com/watch?v=XSZP9GhhuAc"
author:
  - "Hannah Moran"
  - "Jeremy Hadfield"
  - "[[Anthropic]]"
published: 2025-05-22
created: 2025-08-03
description: |
  この講演では、基本的なプロンプトエンジニアリングから一歩進んで、エージェント向けのプロンプト手法について解説されました。プロンプトエンジニアリングは自然言語でのプログラミングとして捉えられ、エージェントの場合は従来の構造化されたプロンプトとは異なるアプローチが必要であることが強調されました。
tags:
  - "clippings"
  - "AI"
  - "Agent"
  - "LLM"
  - "PromptEngineering"
  - "Anthropic"
  - "Claude"
---
# 「Prompting for Agents」講演内容まとめ

**講演者**

- Hannah Moran（Anthropic Applied AI team）
- Jeremy Hadfield（Anthropic Applied AI Product Engineer）

**開催日時・場所**
2025年5月22日、サンフランシスコ、「Code w/ Claude」イベント

---

## 講演概要

この講演では、基本的なプロンプトエンジニアリングから一歩進んで、エージェント向けのプロンプト手法について解説されました。プロンプトエンジニアリングは自然言語でのプログラミングとして捉えられ、エージェントの場合は従来の構造化されたプロンプトとは異なるアプローチが必要であることが強調されました。

---

## エージェントの定義と特徴

### エージェントとは

Anthropicでは、エージェントを「ツールをループで使用するモデル」として定義しています。エージェントには以下の特徴があります：

- **継続的な作業**: タスクを与えられ、適切だと判断するツールを使用して継続的に作業する
- **動的な意思決定**: ツール呼び出しから得られる情報に基づいて決定を更新する
- **自立的な完了**: タスクが完了するまで独立して作業を継続する

### エージェントの構成要素

1. **環境**: エージェントが作業する場所
2. **ツール**: エージェントが利用できる機能
3. **システムプロンプト**: エージェントが何をすべきか、何を達成すべきかを指示する部分

重要な原則として、「シンプルであればあるほど良い」とされ、エージェントに作業を任せ、モデルがモデルらしく機能できるようにすることが推奨されています。

---

## エージェント使用の判断基準

### エージェントを使用すべき場面の4つのチェックポイント

#### 1. タスクの複雑さ

- 人間がステップバイステップで完了できるプロセスが明確な場合、エージェントは不要
- タスクの実行方法が不明確で、目標は分かっているが具体的な手順や必要なツール、情報が不明な場合にエージェントが有効

#### 2. タスクの価値

- エージェントがタスクを完了することで高い価値が得られるか
- 低価値のタスクやワークフローの場合、ワークフローの方が適している
- 収益を生み出すような高レバレッジなタスクに使用すべき

#### 3. タスクの実行可能性

- エージェントがタスクを完了するために必要なツールを提供できるか
- ツールを定義できない、または必要な情報やツールへのアクセスを提供できない場合、タスクの範囲を縮小する必要がある

#### 4. エラーのコストと発見しやすさ

- エラーの修正や検出が困難で高コストな場合、人間をループに含める必要がある
- エラーから回復可能で、コストが高くない場合、エージェントの独立作業を継続できる

### エージェントの適用例

**適切な用途：**

- **コーディング**: 設計文書からPRまでの過程で、具体的な実装手順が不明確だが最終目標が明確
- **検索**: エラーが発生しても引用や他の方法で修正可能
- **コンピューター使用**: エラーから回復可能で、再試行が容易
- **データ分析**: データの形式や構造が不明だが、求める洞察や可視化が明確

---

## エージェント向けプロンプトのベストプラクティス

### 1. エージェントの立場で考える

- エージェントの環境とそれが体験することの理解が最重要
- エージェントの環境＝ツールセット＋ツールからの応答
- 人間が理解できないタスクは、AIも実行できない
- 実際にエージェントの立場をシミュレーションして、混乱するかどうかを確認する

### 2. 合理的なヒューリスティックの提供

プロンプトエンジニアリングは「概念エンジニアリング」であり、モデルが特定の環境で良好に機能するために持つべき概念と行動を決定することが重要です。

**重要な概念の例：**

- **不可逆性**: Claude Codeでは、ユーザーや環境に害を与える可能性のある不可逆的な行動を避ける
- **停止条件**: 答えを見つけたら検索を停止する明確な指示
- **予算管理**: シンプルなクエリには5回未満、複雑なクエリには10-15回のツール呼び出しという予算の設定

### 3. ツール選択の明確化

- Claude 4のSonnetとOpusは最大100個以上のツールを処理可能
- どのタスクにどのツールを使用すべきかの明確な原則が必要
- 企業固有のコンテキストの考慮（例：Slackを多用する企業では会社関連情報の検索にSlackを優先）

### 4. 思考プロセスの誘導

- 拡張思考モードを有効にするだけでなく、思考の使い方を明確に指示
- 検索の場合：複雑さの判断、使用するツール呼び出し数、探すべきソース、成功の判断基準を事前に計画
- Claude 4の新機能：ツール呼び出し間でのインターリーブ思考
- 検索結果の品質評価、検証の必要性、免責事項の追加などを思考で実行

### 5. 予期しない副作用への対応

- エージェントはワークフローや分類プロンプトより予測困難
- ほとんどの変更が意図しない副作用を引き起こす可能性
- 例：「完璧なソースが見つかるまで検索を続ける」→完璧なソースが存在しない場合、コンテキストウィンドウまで検索を続ける

### 6. コンテキストウィンドウの管理

Claude 4モデルは200kトークンのコンテキストウィンドウを持ちますが、長時間実行されるエージェントタスクではこの制限に達する可能性があります。

**対処法：**

- **コンパクション**: 190,000トークン近くで自動実行され、コンテキストを要約・圧縮して新しいClaudeインスタンスに渡す
- **外部ファイルへの書き込み**: モデルがメモリをファイルに書き込み、コンテキストウィンドウを実質的に拡張
- **サブエージェント**: 複数のエージェントを使用し、サブエージェントが実際の検索を実行してリードエージェントに圧縮された結果を提供

### 7. Claudeらしさの活用

- Claudeは既に優れたエージェント性能を持っている
- 最初は基本的なプロンプトとツールでシステムを試し、問題が発生した箇所から改善する
- Claudeができないと前提せず、その能力に驚かされることが多い

---

## ツール設計の重要性

### 良いツールの特徴

1. **明確で正確なツール名**: 機能を反映した名前
2. **十分なテスト**: 正常に動作することの確認
3. **明確な説明**: 他のエンジニアが理解できる程度の詳細な説明
4. **使いやすさと明確性**: 人間が使用できるレベルの使いやすさ

### ツール設計の注意点

- 類似した名前や説明を持つ複数のツールは避ける
- 6つの検索ツールがそれぞれ異なるデータベースを検索する場合、モデルを混乱させる
- 類似したツールは統合して単一のツールにまとめる

---

## エージェントの評価方法

### 評価の課題

- エージェントは長時間実行され、多くの処理を行う
- 予測可能なプロセスを常に持つとは限らない
- 分類タスクのような単純な正誤判定では評価困難

### 評価のコツ

#### 1. 効果サイズとサンプルサイズの関係

- 効果サイズが大きければ必要なサンプルサイズは小さくなる
- プロンプトの変更が明らかに改善をもたらす場合、大規模な評価は不要
- 小規模な評価から始めて、一貫したテストケースで継続的に測定

#### 2. 現実的なタスクの使用

- 競技プログラミング問題ではなく、実世界のコーディングタスクを使用
- 実際に解決しようとしている問題を反映したタスクで評価

#### 3. LLMを評価者として活用

- 明確なルーブリックを提供してLLMに評価させる
- 異なる構造やテキストを持つ多様な出力を処理可能
- 人間による評価に完全に代替はできないが、有効な補助手段

### 評価手法の例

#### 1. 答えの正確性

- LLMを評価者として使用し、答えの正確性を判定
- 整数「47」だけでなく「四十七」などの表記バリエーションにも対応

#### 2. ツール使用の正確性

- 適切なツールが適切なタイミングで使用されているかを確認
- 例：特定の質問に対してウェブ検索を5回以上実行したかをプログラム的にチェック

#### 3. 最終状態の確認（ToWebench参考）

- エージェントが正しい最終状態に到達したかを確認
- 例：フライト変更の依頼に対して、実際にデータベースのフライト情報が変更されたかを確認

---

## デモンストレーション

講演では、「Rivian R1Sに何個のバナナが入るか？」という質問を使用したデモが行われました。このデモでは以下の点が実証されました：

1. **計画的な思考**: モデルが最初に検索プロセスを計画
2. **並列ツール呼び出し**: 複数のウェブ検索を同時実行
3. **インターリーブ思考**: ツール呼び出し間での結果の反省と評価
4. **動的な調整**: 得られた情報に基づく次のステップの決定

最終的に約48,000個という回答が得られ、正解範囲（30,000-50,000）内に収まったことが確認されました。

---

## 質疑応答

### プロンプト構築のアプローチについて

- 長いプロンプトから始めて反復するのではなく、短くシンプルなプロンプトから開始
- Claudeが即座にタスクを実行できることが多いため、問題が発生した箇所を特定してから改善
- テストケースを収集し、成功するケースを徐々に増やしていく

### Few-shot例の効果について

- 従来のプロンプト技術（few-shot例、chain of thought）は最新のフロンティアモデルやエージェントには効果が限定的
- モデルが既に思考方法を学習済みのため、具体的な例で制限するより、思考の使い方を指導する方が効果的
- 規範的すぎない例の提供は有効だが、過度に詳細な例は避ける

---

## まとめ

エージェント向けのプロンプトエンジニアリングは、従来の分類や生成タスクとは根本的に異なるアプローチが必要です。最も重要なのは、エージェントの立場で考え、適切なヒューリスティックを提供し、ツールの設計と選択を慎重に行うことです。また、評価においては小規模から始めて継続的に改善していくアプローチが推奨されます。Claudeの既存の能力を活用しつつ、必要に応じて段階的に改善していくことが成功の鍵となります。
