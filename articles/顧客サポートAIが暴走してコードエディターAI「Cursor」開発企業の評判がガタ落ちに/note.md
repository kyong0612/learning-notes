# 顧客サポートAIが暴走してコードエディターAI「Cursor」開発企業の評判がガタ落ちに

ref: <https://gigazine.net/news/20250506-ai-glitch-chatbot/>

## 概要

AIスタートアップ企業Anysphereが提供するコードエディター「Cursor」の顧客サポートAIが、存在しない情報をユーザーに提供するという問題が発生しました。この出来事は開発者コミュニティで急速に広まり、同社の評判に悪影響を与えています。専門家は、AIに全面的に依存することの危険性を示す教訓的な事例であると指摘しています。

## 問題の詳細

### AnysphereとCursorについて

* Anysphereは、AIによるコード生成や文章生成機能を組み込んだエディター「Cursor」を展開し、年間売上高1億ドル（約145億円）に達するなど急成長を遂げている企業です。
* 同社は顧客サポートにも自社開発のAIアシスタントを起用していました。

### 発生した問題

* Cursorのユーザーが、デバイス切り替え時にサービスからログアウトされる不具合について問い合わせたところ、「Sam」と名乗るサポート担当者（AI）から「新しいポリシーに基づく予期された動作である」との回答を得ました。
* しかし、そのような新しいポリシーは存在せず、「Sam」という人物も架空のものであり、AIによる「幻覚」であったことが判明しました。

## 反響とAnysphereの対応

* このニュースは開発者コミュニティで広まり、ユーザーからの利用キャンセル報告や、Anysphereの透明性の欠如に対する不満の声が上がりました。
* Anysphereの共同設立者であるマイケル・トゥルエル氏は、「ユーザーをログアウトさせるバグを調査中であり、混乱を招いたことをお詫びします」とコメントしました。

## 専門家の見解と教訓

* **Google元チーフサイエンティスト キャシー・コジルコフ氏:**
  * 「この混乱は、AIは間違いを犯すこと、AIはその間違いの責任を取れないこと、ユーザーは人間を装った機械に欺かれることを嫌うことをリーダーが理解していれば避けられたはずだ」と指摘。
* **セキュリティ会社Upwind CEO アミラム・シャチャー氏:**
  * AIチャットボットの幻覚は今回が初めてではないと指摘。2022年のエア・カナダの事例（AIチャットボットが誤った割引情報を案内し裁判沙汰になった）を挙げています。
  * 「根本的に、AIはユーザーの考えを理解していない。適切な制約がなければ、AIは裏付けのない情報で自信満々に回答してしまう。Cursorの顧客のように高度な技術を持つユーザーにとって、いい加減な説明は許されないだろう」と述べています。

## 結論と重要なポイント

* 顧客サポートにAIを導入する場合、AIが誤った情報を提供するリスク（ハルシネーション）を十分に理解し、対策を講じる必要がある。
* AIは人間の監視なしに完全に自律的に機能させるべきではなく、特に顧客対応のような重要な業務においては、最終的な判断や責任は人間が負う体制が不可欠である。
* 企業の透明性と、問題発生時の迅速かつ誠実な対応が、ユーザーの信頼を維持するために重要である。

## 関連事例

* テック企業Salesforceが営業マンに代わる営業AIを販売するため営業マン1000人を雇用
* ChatGPTが同時多発的に奇妙なことを言い始めて「ChatGPTが発狂した」「発作を起こした」という報告が相次ぎOpenAIが慌てて修正
* Apple Intelligenceのプレリリース版で「ニュースの要約ミス」「詐欺メールを優先表示する」など問題が多数発見される
* 人間に代わってタスクを行う「AIエージェント」の台頭でクリスマスのプレゼント選びまでAI任せになる未来が到来するかもしれない
