---
title: "コンテキストエンジニアリングがなぜ重要なのか"
source: "https://zenn.dev/knowledgesense/articles/47afd29ecfc3bb"
author:
  - "sasakuna"
published: "2025-07-23"
created: 2025-07-25
description: |
  LLMエージェントの台頭に伴い、プロンプトだけでなく情報そのものの管理が重要になっています。コンテキストエンジニアリングは、LLMの性能を最大化し、必要十分な情報を提供することを目的とした手法であり、本記事ではその背景と具体的な4つのアプローチ（書き出し、選択、圧縮、分割）について解説します。
tags:
  - "context"
  - "llm"
  - "agent"
  - "rag"
  - "ContextEngineering"
---

## 導入

こんにちは、株式会社ナレッジセンスの須藤英寿です。

今回は、コンテキストエンジニアリングがエージェントにとってなぜ重要なのかを解説します。

![](https://storage.googleapis.com/zenn-user-upload/aee9844d772b-20250722.png)

説明の過程で、上記のブログの内容を参照しています。

## サマリー

ここ最近コンテキストエンジニアリングという言葉が話題になっています。

ツイートの中でも登場するプロンプトエンジニアリングと似た言葉ですが、コンテキストエンジニアリングという言葉が登場した背景にはエージェントの台頭が関係しています。

これまでLLMは基本的に「人」が利用するものでした。そのため入力するプロンプト、そのものに焦点を当てられていました。しかし、「エージェント」は人の手が基本的に介在することなく、自動的にLLMが動作し続けます。そのためプロンプトだけではなく、情報そのものをどう管理するかまで考える必要性が出てきました。この情報の扱い方を考えることこそコンテキストエンジニアリングです。

コンテキストエンジニアリングのゴールは２つあります。１つ目は、LLMの性能を最大限に引き出すこと。これはプロンプトエンジニアリングに通じるものがあります。そして２つ目は、LLMにとって必要十分な情報を提供すること、です。

今回は、コンテキストエンジニアリングが必要になる背景と、手法について解説していきます。

## 課題意識

LLMに複雑な指示をした際に、その指示がLLMの持つ問題解決能力を上回ってしまうと、タスクを完了できなくなることがあります。これは主に２つの制約によって発生します。

- 入力長の限界: LLMには入力可能な文章量に制限があるため、その中で解決できないと、それ以上何もできなくなってしまいます。
- 認識の限界: 複数の指示をLLMに任せると"Lost in the Middle"などの問題などにより解決すべき問題を見失うことがあります。

これらの限界は、LLMの進化によって確実に解消していきますが、人の要求する問題解決能力からはまだ大きな隔たりがあります。

## コンテキストエンジニアリングでの解決方法

ここで登場するのがコンテキストエンジニアリングという考え方です。LLMに適切なコンテキストを渡すことでLLMの限界に到達しないように問題を解いていこう、というものです。以下に関連する４つの手法を紹介しています。

- 書き出し: 重要な情報を外部に保管して再利用可能にする
- 選択: 必要なコンテキストだけを取得して、余計な情報を持たない
- 圧縮: コンテキストを厳選して、密度の高い情報にする
- 分割: 複雑な問題を分解して、独立した扱いやすい問題にする

これらの手法を組み合わせることで、LLMに解かせる問題を最小限にして、かつその推論能力を問題の解決に集中させることができます。結果として、LLMが問題を解くのに成功する確率を引き上げることが可能です。

## 手法

ここからは具体的な手法について紹介します。注意点として、ここで紹介する手法はあくまで現時点で想定された解法であり、今後もアップデートが想定される部分です。LLMの出力の品質をいかにして上げられるかが、根幹にあるということを念頭に見ていただければと思います。

![](https://storage.googleapis.com/zenn-user-upload/9eb28e2f0888-20250722.png)

### 書き出し(Write Context)

セッション内で得られた情報を外部に保管し、別のセッションで再利用できるようにすることを目的としています。

- **メモ書きの書き出し**: 重要な内容や方針を外部のメモとして残し、"Lost in the Middle"を防ぎます。
- **記憶の書き出し**: 他の指示に関わる情報を長期的な記憶として保存し、同じ指示や失敗の繰り返しを避けます。

**実践上のヒント**: 情報量が多すぎるとコンテキストを圧迫するため、出力内容の指定、RAGとの連携、古いデータの破棄などでバランスを取ることが重要です。

### 選択(Select Context)

必要な情報だけをLLMに提供するための手法です。

- **メモ書き、記憶の読み込み**: 新しいセッション開始時に過去の情報を読み込み、LLMに次の行動を把握させます。
- **Toolの選択**: LLMが苦手な処理（計算など）を外部の機能に委ねます。Toolを増やすことは、LLMの能力を拡張することに繋がります。
- **情報の検索**: LLMの内部知識にない情報は、RAGやWeb検索で補います。特に企業内の機密情報などを扱う際に有効です。

**実践上のヒント**: Tool選択の精度は最新・最高性能のモデル（o3, gemini-2.5, claude-3.7-sonnetなど）でないと低い傾向にあります。対策として、実行するToolを限定する、高性能LLMを使う、RAGで自然言語による選択を可能にする、といった方法が考えられます。

### 圧縮(Context Compression)

不要な情報を削除・要約することで、コンテキスト長の制約を回避し、推論性能を向上させます。

- **具体例**: メッセージ履歴の要約、Tool出力の要約、古いメッセージの削除など。

**実践上のヒント**: 圧縮は必要な情報まで失うリスクがあるため、最終手段と考えるべきです。タスクを十分に細かく分割し、圧縮が不要な状態を目指すことが理想です。

### 分割(Context Division)

複雑な問題を分割し、各セッションで扱う問題を単純化する手法です。

- **具体例**: マルチエージェントによる分担、短いゴール設定による段階的な問題解決など。

**実践上のヒント**: 分割プロセス自体がエラーの原因になりうるため、可能なら避けるべきです。以下の優先順位で解決を試みることが望ましいです。

1. 分割不要なほど短く明確な指示を出す
2. 単一セッション内で細かなゴールを設定して解決する
3. 同一エージェントが独立したセッションを繰り返して解決する
4. 複数の専門エージェントが分担して解決する

## まとめ

コンテキストエンジニアリングの核心は、「LLMが最高の性能を発揮できる環境をいかにお膳立てするか」にあります。これを実現するためには以下の3つの要素が重要です。

1. **小さな指示**: タスクを細分化する。
2. **解決に必要十分な情報**: 過不足なくコンテキストを提供する。
3. **実行可能な手段の提供**: 適切なToolを用意する。

この考え方はエージェントだけでなく、LLMを活用する全てのシステムに応用可能な普遍的な原則です。
