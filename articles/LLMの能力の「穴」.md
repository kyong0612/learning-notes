---
title: "LLMの能力の「穴」"
source: "https://joisino.hatenablog.com/entry/zeh"
author:
  - "[[佐藤竜馬]]"
  - "[[joisino]]"
published: 2026-01-26
created: 2026-01-28
description: "最先端のLLM（GPT-5.2等）が依然として単純な問題（掛け算、1のカウント、カッコの対応）で失敗することを、ゼロエラー境界（ZEH）という新しい評価指標を用いて分析。LLMの能力の「穴」が信頼性の高い領域への展開における課題であることを議論する。"
tags:
  - "clippings"
  - "LLM"
  - "AI評価"
  - "Zero-Error-Horizon"
  - "GPT-5"
  - "信頼性"
  - "AI安全性"
---

## 概要

本稿は論文「[Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs](https://arxiv.org/abs/2601.15714)」をもとに、最先端のLLMが依然としてごく簡単な問題でミスすることを議論している。GPT-5.2は高度な流体力学のシミュレーションやアセンブリ言語の最適化ができる一方で、以下のような基本的な問題で失敗する：

- **1のカウント**: `11000`に含まれる1の数が偶数か奇数か → 「奇数」と誤答（正解は偶数）
- **カッコのバランス**: `((((()))))) `がバランスしているか → 「取れている」と誤答
- **掛け算**: 127×82 → 10314と誤答（正解は10414）

このような能力のちぐはぐさが、金融取引や原子炉制御といったハイリスク領域へのLLM展開における課題となっている。

## ゼロエラー境界（Zero-Error Horizon; ZEH）

### 定義

モデル・タスク・プロンプト・乱数を固定した条件下で、問題サイズの小さい順に全問題を入力したとき：

- **ゼロエラー境界（n）**: サイズn までは全て正解するが、サイズn+1で失敗する問題がある場合の値n
- **リミッター（ZEH limiter）**: 間違えたサイズn+1の問題例

### 具体例

| タスク | 問題サイズの定義 | ゼロエラー境界 | リミッター |
|--------|------------------|----------------|------------|
| 掛け算 | a,bの大きい方 | 126 | 127×82 |
| 1の偶奇カウント | 文字列長 | 4 | `11000` |
| カッコのバランス | 文字列長 | 10 | `((((()))))) ` |

### 重要な注意点

- プロンプトや乱数を変えると正解することもある
- しかし、**簡単な問題でも間違いうる**ことが重要
- `((((()))))) `はGPT-5.2-Thinkingでも約50%の確率で誤答する頑健なリミッター

## ゼロエラー境界のメリット

### 1. リミッターが確固とした証拠になる

コマンドを実行すれば誰でも一発で検証可能。数学的にもコミュニケーションの上でも好ましい。

### 2. 自動的に驚きのある結果が得られる

リミッターは試行錯誤ではなく、最も小さい間違いを自動評価した結果発見される。敵対的例（adversarial example）とは異なり、リミッターは**自然で普通に起こりうる例**であり、実際上の意義がある。

### 3. 正解率のスケール恣意性を排除

正解率は評価者が問題範囲を恣意的に設定するためバイアスが入りうる。ゼロエラー境界は**モデル自身が難度を定める**ため、客観的な値が得られる。

### 4. 時代遅れになりづらい

固定範囲のベンチマーク（MNIST、CIFAR-10、GLUE等）は飽和するが、ゼロエラー境界はオープンエンドに難度が設定されるため時代遅れになりにくい。

### 5. 構造的なエラーパターンを優遇

同じ正解率90%でも：
- **ランダムに間違う**: ゼロエラー境界 = 4（「穴」が多い）
- **簡単な問題を確実に解く**: ゼロエラー境界 = 97（扱いやすい）

GPT-5.2の1×1〜99×99掛け算の正解率は98.6%だが、ゼロエラー境界は42。ランダムなら10未満になるはずなので、簡単な問題を確実に解く「順当な」間違い方をしていることがわかる。

## 実用上の課題

- 複雑な問題のサブタスクとして単純な計算が登場する
- 思考の連鎖で途中式の掛け算をミスすると最終結論が間違う
- ツール呼び出しを許可しても、呼び出すべきかの判断自体をミスすることがある
- GPT-5.2-Thinkingはツール呼び出し可能にもかかわらず、自分でカッコを数えてミスした

## 結論

- LLMは「すごい問題を解ける」一方で「愚かな間違いをする」という能力のギャップが扱いづらさの要因
- ゼロエラー境界は「愚かな間違い」をシステマチックに評価する方法
- 堅牢なアルゴリズムやルールを身につけるとゼロエラー境界は大きくなる
- GPT-5.2にはまだ「穴」が数多くあり、AIの尻ぬぐいをする仕事はしばらく続く

## 著者情報

- **佐藤 竜馬**（さとう りょうま）
- 京都大学情報学研究科博士課程修了。博士（情報学）
- 国立情報学研究所助教
- 著書：『深層ニューラルネットワークの高速化』『グラフニューラルネットワーク』『最適輸送の理論とアルゴリズム』
- Twitter: [@joisino_](https://x.com/joisino_)

## 関連リンク

- [論文: Even GPT-5.2 Can't Count to Five](https://arxiv.org/abs/2601.15714)
- [LLMのキモい算術](https://joisino.hatenablog.com/entry/kimoi)
- [LLMのアテンションと外挿](https://joisino.hatenablog.com/entry/heads)
- [人間には認知できない情報を活用するAIたち](https://joisino.hatenablog.com/entry/superai)
