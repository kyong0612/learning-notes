---
title: "安定したAIエージェント開発・運用を実現するLangfuse活用方法"
source: "https://tech.layerx.co.jp/entry/stable-ai-agent-dev-with-langfuse"
author:
  - "omori (@onsd_)"
published: 2025-09-10
created: 2025-09-14
description: |
  LayerXのエンジニアomori氏が、AIエージェント「AI申請レビュー」の開発で直面した「挙動の可視化」「プロンプト更新フロー」「変更影響の不明確さ」という3つの課題を、LLMOpsツール「Langfuse」を導入してどのように解決したかを解説。Trace機能による可視化、Gitと連携したプロンプト管理、自動リグレッションテストの仕組みなど、安定した開発・運用サイクルを実現するための具体的な手法を紹介します。
tags:
  - AI Agent
  - LLM
  - MLOps
  - Langfuse
---

この記事は、LayerX社が開発するAIエージェント機能「AI申請レビュー」の開発・運用において直面した課題と、それをLLMOpsツールである**Langfuse**を導入してどのように解決したかについて解説したものです。

## AIエージェント開発で直面した3つの課題

開発チームは主に以下の3つの課題に直面しました。

### 課題1: 挙動の可視化が難しい

AIエージェントは確率的に動作するため、同じ入力でも結果が異なる場合があり、「なぜこの結果になったのか」の追跡・分析が困難でした。

### 課題2: プロンプト更新のフローが未整備

当初プロンプトをS3で管理していましたが、変更履歴が残らず、更新作業が属人化するという問題がありました。

### 課題3: プロンプト変更による影響の不明確さ

プロンプトのわずかな変更が機能全体の精度に予期せぬ影響を与えるリスクがありましたが、その影響を定量的に評価する仕組みがありませんでした。

## 課題解決のためのLLMOpsツール「Langfuse」導入

これらの課題を解決するため、以下の要件を満たすLLMOpsツールとして**Langfuse**の採用を決定しました。

- **プロンプト管理機能**: バージョン管理や変更履歴の追跡が可能。
- **実験管理（精度検証）機能**: 変更による影響を定量的に評価できる。
- **Observability（可観測性)**: LLMの呼び出しをトレースし、監視できる。
- **セルフホスト可能**: 自社のインフラ上で運用できる。

### セルフホスト時の構成図

Langfuseは下図のように、ClickHouseやClickHouse Keeperを用いた冗長構成でセルフホストされています。

![](https://cdn-ak.f.st-hatena.com/images/fotolife/o/onsd/20250909/20250909145845.png)

## Langfuseを使った課題解決

### 1. Trace 機能による挙動の可視化

Langfuseの**Observability機能**を利用し、アプリケーションの挙動をトレースできるようになりました。`@observe`デコレータを付けるだけで、関数単位での処理時間、LLM呼び出しのトークン数やコスト、入出力などを可視化でき、問題調査が容易になりました。

![](https://cdn-ak.f.st-hatena.com/images/fotolife/o/onsd/20250909/20250909142201.png)

### 2. プロンプトをコードと同じように管理して更新フローを標準化

**Prompt Management機能**を活用し、プロンプトのバージョン管理を実現しました。これにより、どのプロンプトでどのような結果が出たかを簡単に追跡できます。

チームでは、以下の更新フローを構築しました。

1. プロンプトをGitリポジトリでコードと同様に管理。
2. 変更はPull Request経由でレビュー。
3. デプロイ時にCIからSDKで自動更新。
4. 問題発生時はLangfuseのUIからラベルを切り替えて即座にロールバック。

これにより、安全で効率的な更新サイクルが実現できました。

![](https://cdn-ak.f.st-hatena.com/images/fotolife/o/onsd/20250909/20250909142501.png)

### 3. プロンプトの自動リグレッションテスト

**Evaluation機能**（DatasetとScore）を活用し、プロンプトの自動リグレッションテストの仕組みを構築しました。

Pull Requestが作成されると、GitHub Actions上でリグレッションテストが実行され、ベースラインを維持し、意図しない性能劣化を防ぐ「ガードレール」として機能します。

![](https://cdn-ak.f.st-hatena.com/images/fotolife/o/onsd/20250909/20250909142359.png)

## これからの課題

### 評価周りの改善

現在は定性的な評価を人間が行っていますが、今後は評価指標を定義し、Langfuseの**LLM as a Judge機能**などを活用して評価自体の自動化を目指します。

### 可観測性の課題

現状、トレースはLangfuse、ログはDatadogと分かれており、両者を行き来しています。今後はDatadogが提供するLLM Observabilityにも注目し、一気通貫で確認できる仕組みを検討しています。

## おわりに

AIエージェント開発特有の課題に対し、Langfuseを導入して改善サイクルを構築した事例が紹介されました。今後もこのサイクルを回し、さらなる価値提供を目指していくとのことです。
