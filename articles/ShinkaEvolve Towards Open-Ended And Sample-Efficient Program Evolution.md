---
title: "ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution"
source: "https://arxiv.org/html/2509.19349v1"
author:
  - Robert Tjarko Lange
  - Yuki Imajuku
  - Edoardo Cetin
published: 2025-09
created: 2025-10-27
description: |
  大規模言語モデル(LLM)を活用した新しいオープンソースのプログラム進化フレームワーク。従来手法と比較して圧倒的なサンプル効率を実現し、科学的発見を加速する。3つの主要な革新(適応的親サンプリング、コード新規性リジェクションサンプリング、バンディットベースLLMアンサンブル選択)により、数学的最適化、エージェント設計、競技プログラミング、LLM訓練など多様なタスクで最先端の成果を達成。
tags:
  - evolutionary-computation
  - llm
  - program-synthesis
  - optimization
  - machine-learning
  - open-source
  - algorithm-design
  - scientific-discovery
---

## 概要

**ShinkaEvolve**は、大規模言語モデル(LLM)を活用した革新的なプログラム進化フレームワークです。Sakana AIが開発したこのオープンソースシステムは、科学的発見における最先端のパフォーマンスと前例のない効率性を実現します。

### 背景と動機

近年、LLMの急速な発展により、自律的に実験を実施し仮説を検証するエージェントシステムを通じた科学的発見が変革されています。しかし、既存の実装には以下の重大な制約がありました:

- **サンプル非効率性**: 従来の手法は数千回の評価を必要とし、計算コストと時間がかかる
- **クローズドソース**: 主要なシステムがクローズドソースであるため、再現性と改善が制限される
- **探索戦略の非効率性**: 以前の世代からの蓄積された知識を効果的に活用できない

## 主要な技術革新

ShinkaEvolveは3つの核心的なアルゴリズム革新により、これらの課題に対処します:

### 1. 適応的親サンプリングとLLMサンプリング

探索(新規領域の探索)と活用(既知の高品質領域の利用)を知的にバランスします:

- **べき乗則サンプリング**: プログラムは適合度でランク付けされ、選択確率は \(p_i = \frac{r_i^{-\alpha}}{\sum_{j=1}^{n}r_j^{-\alpha}}\) に従います
  - \(\alpha = 0\): 均一サンプリング(純粋な探索)
  - \(\alpha \to \infty\): 山登り法(純粋な活用)
  
- **重み付きサンプリング**: パフォーマンスと新規性を組み合わせます
  - パフォーマンス成分: \(s_i = \sigma(\lambda \cdot (F(P_i) - \alpha_0))\)
  - 新規性成分: \(h_i = \frac{1}{1 + N(P_i)}\) (子孫が少ないプログラムを優遇)
  - 最終確率: \(p_i = \frac{w_i}{\sum_{j=1}^{n}w_j}\) where \(w_i = s_i \cdot h_i\)

### 2. プログラム新規性リジェクションサンプリング

効率的な探索空間の探索を保証します:

1. **埋め込みベースの類似性チェック**: コード埋め込みを使用してプログラムの変更可能部分を埋め込み、島部分母集団全体でコサイン類似度スコアを計算
2. **LLM-as-a-novelty-judge**: 最大スコアが閾値(例: η=0.95)を超える場合、LLMにプログラムが意味的に異なるかどうかを評価させる
3. 創造性を高めるために、基盤モデルアンサンブルと温度サンプリングを活用

### 3. バンディットベースLLMアンサンブル選択戦略

進化する状態に動的に適応します:

- **UCB1アルゴリズムベース**: 各LLMに訪問カウンターと期待スコアの推定値を関連付ける
- **相対的改善による報酬**: \(r_i^u = \exp(\max(r_i - r_i^b, 0)) - 1\)
  - \(r_i^b\): ベースライン報酬(親プログラムとデータベース内の初期プログラムの最大値)
  - 大胆で高リスク・高リターンの変異を促進
- **非定常性への対応**: プログラムアーカイブの進化する状態に適応

## 手法の詳細

### 制御フロー

ShinkaEvolveは3つの主要フェーズで構成されます:

#### フェーズ1: 親とインスピレーションのサンプリング

- **アーカイブ管理**: 評価済みプログラムの固定サイズアーカイブを維持(適合度スコアとメタ情報付き)
- **島モデル**: 独立した部分母集団を並行進化させ、多様性を強化し早期収束を防止
- **変異コンテキスト構築**: 主要な親プログラムと、トップパフォーマーおよびランダムアーカイブサンプルから引き出されたインスピレーションプログラムを組み込む

#### フェーズ2: LLMガイド付きプログラム変異

3つの異なる変異アプローチ:

1. **差分ベース編集**: SEARCH/REPLACEブロックを使用した対象修正
2. **完全書き換え**: 変更不可能なブロックをプログラム的に保護しながら、より大きな柔軟性を実現
3. **クロスオーバー変異**: 追加のアーカイブプログラムをサンプリングし、LLMにプログラムを組み合わせるよう促す

テキストマーカー(EVOLVE-BLOCK-START & EVOLVE-BLOCK-END)を使用して、不変コードを保護します。

#### フェーズ3: 実行とフィードバック

- **多目的評価**: スカラー適合度値とパブリックメトリクス、テキストフィードバックを生成
- **メタスクラッチパッド**: 成功したソリューションを定期的に分析し、学習を加速
  - T世代ごとに最近のプログラム評価を要約
  - 一般的な最適化戦略と設計原則を特定
  - 実行可能な推奨事項を変異プロンプトに追加

## 実験結果

ShinkaEvolveは4つの異なる問題領域で包括的に検証されました:

### 1. 円パッキング問題(Circle Packing)

**課題**: 単位正方形内に26個の円を配置し、半径の合計を最大化しながら、円が重ならず、すべての円が正方形の境界内に完全に収まるようにする。

**成果**:

- **わずか150評価**で最先端の結果を達成(従来手法は数千回必要)
- AlphaEvolveの解決策を改善: 2.6360対2.6345
- 3つの明確なフェーズを示す:
  1. 急速な改善フェーズ
  2. 持続的な探索フェーズ
  3. 最終収束フェーズ

**発見されたアルゴリズム**:

- 黄金角スパイラルパターンによる高度な初期化戦略
- SLSQPグラディエントベース改良とシミュレーテッドアニーリングを統合したハイブリッド最適化
- 局所最適から脱出するための知的摂動メカニズム

### 2. AIME数学的推論(Agent Scaffold Design)

**課題**: AIME 2024数学的推論問題(30問の挑戦的な競技レベルの質問)で、問題ごとに最大10のLLMクエリに制約されたエージェントスキャフォールド設計を進化させる。

**成果**:

- **効率性とパフォーマンスのパレートフロンティア**を発見
- 最適パフォーマンスは7 LLMクエリで達成
- **一般化実験**:
  - 2023年問題: 小さな改善(訓練データ汚染の可能性)
  - 2025年問題: より大きな利得(未見の課題への成功的な一般化)
- **クロスLLM転移**: gpt-4.1-mini、gpt-4.1、o4-miniへの成功的な適応

**発見されたアーキテクチャ**: 3段階システム

1. **専門家生成**: 3つの専門的なペルソナ(慎重な数学者、直感的な数学者、アルゴリズム志向の数学者)
2. **批判的ピアレビュー**: 各ソリューションを懐疑的なレビュアーが精査
3. **統合**: 編集長ペルソナがすべてのソリューションと批評を分析し、標準的な解決策を構築

### 3. ALE-Bench競技プログラミング

**課題**: ALE-Agent(Imajuku et al., 2025)によって発見された高性能ソリューションをさらに改善する。

**成果**:

- 10タスク平均で**約2.3%の改善**
- **ahc039タスク**: AtCoderリーダーボードで5位から2位に改善(参加していた場合)
  - キャッシング最適化とkd-tree統計の拡張
  - 「対象エッジ移動」という新しい近傍オペレーターを導入
- **ahc025タスク**: より高速なキャッシング、洗練されたフォールバック重み推定、最適化の置き換え

**制限**: 多くの場合、ShinkaEvolveは初期化ソリューションに近い修正を探索する傾向があり、過学習の可能性を示唆

### 4. LLM訓練: Mixture-of-Experts負荷分散損失

**課題**: MoEアーキテクチャのための効果的な負荷分散損失(LBL)を設計し、効率性と専門化を促進しながら表現力を妨げない。

**実験設定**:

- **小規模MoE(進化用)**: 556Mパラメータ、64エキスパート(トークンあたり8アクティブ)、2.1Bトークン
- **大規模MoE(評価用)**: 2.7Bパラメータ、64エキスパート(トークンあたり8アクティブ)、29.36Bトークン
- 3つのLBL係数で評価: λ ∈ {0.001, 0.01, 0.1}

**発見されたLBL**:

```
L_LBL = N_E · (1/L) Σ_ℓ Σ_i f_ℓ,i P_ℓ,i  [グローバルバッチLBL]
      + (0.1/L) Σ_ℓ s(P_ℓ) Σ_i max(0, τ - f_ℓ,i)  [ShinkaEvolve新正則化]
```

where:

- s(P_ℓ) = 0.5 + (1 - H(P_ℓ)/log N_E): 正規化されたエントロピーの補数
- τ = 0.064/N_E: 最小使用閾値
- H(P_ℓ): ルーティングエントロピー

**成果**:

- 全訓練構成で一貫したエッジを達成
- **パープレキシティの改善**: 特に高い正則化(λ=0.1)で顕著
- **ダウンストリームタスクのパフォーマンス向上**: 7つのベンチマーク(CommonSenseQA、HellaSwag、OpenBookQA、PIQA、SIQA、WinoGrande、ARC)で評価

## アブレーション研究

### 親選択戦略の影響

- **重み付きサンプリング**: ランダム探索と山登り法の両方を一貫して上回る
- **山登り法**: 強い初期パフォーマンスだが、素早くプラトーに達する
- **ランダム探索**: 最も収束が遅く、適合度ベースの選択の重要性を強調

### LLMアンサンブルと優先順位付けの影響

- **バンディットベースLLMアンサンブル**: 単一LLMと固定アンサンブルの両方を大幅に上回る
- **固定アンサンブル**: 単一LLM使用よりも中程度の改善
- **適応戦略**: 適合度改善への貢献に基づいて、より効果的なモデルを動的に優先順位付け

### コード埋め込みベースリジェクションサンプリングの影響

- **埋め込みベースリジェクションサンプリング**: リジェクションサンプリングなしと比較して大幅なパフォーマンス向上
- **追加のLLM-as-a-novelty-judge**: わずかな改善、埋め込み類似性が既に新規性評価の効果的なプロキシであることを示唆
- 冗長な変異を防ぐことにより、計算オーバーヘッドを追加することなく効率を向上

## 実装の詳細

### システムアーキテクチャ

```python
from shinka.core import EvolutionRunner, EvolutionConfig
from shinka.database import DatabaseConfig
from shinka.launch import LocalJobConfig

# 最小限の構成
job_config = LocalJobConfig(eval_program_path="evaluate.py")
db_config = DatabaseConfig()
evo_config = EvolutionConfig(init_program_path="initial.py")

# デフォルト設定で進化を実行
runner = EvolutionRunner(
    evo_config=evo_config,
    job_config=job_config,
    db_config=db_config,
)
runner.run()
```

### 主要な設計決定

- **キューベース実装**: LLMがプログラム提案を順次生成し、評価キューに追加
- **非同期実装(実験的)**: より高いスループットだが、「オフアーカイブネス」の程度を導入
- **島エリート主義**: 各島の最高性能プログラムが移行から保護される
- **EVOLVE-BLOCKマーカー**: 変更不可能なコードが進化プロセス中に変更されないことを保証

### サポートされているLLMプロバイダ

- OpenAI (GPT-4.1、GPT-5、GPT-5-nano)
- Google (Gemini 2.5 Pro、Gemini 2.5 Flash)
- Anthropic (Claude Sonnet 4)
- DeepSeek
- その他のAPI互換プロバイダ

## 議論

### 強み

1. **前例のないサンプル効率**: 既存のアプローチと比較して、桁違いに少ない評価で最先端の結果を達成
2. **広範な適用性**: 数学的最適化からLLM訓練まで、多様な問題領域で実証された成功
3. **オープンソースアクセシビリティ**: Apache 2.0ライセンスの下で完全な実装を公開
4. **人間およびLLM生成ソリューションを超えた革新**: 新しい高性能アルゴリズムと戦略を発見

### 制限事項

1. **固定構成**: 探索-活用バランスの限定的な自動制御
2. **手動タスク仕様**: 目的関数と評価に人間の専門知識が必要
3. **明確に定義された目的への制約**: 明確な数値目的を持つ問題に限定
4. **APIコスト**: 大規模なLLM使用により、リソースに制約のある環境で経済的障壁を作成する可能性

### 今後の方向性

1. **自動化されたタスク仕様**: LLMタスク生成によるより大きな自律性
2. **真のオープンエンデッドネス**: システムが独自の目的を生成する移行
3. **自己参照的改良**: 継続的に発見を改善するためのオンラインメタ学習
4. **より広範な評価領域**: 数値目的を超えた拡張

## 倫理的考慮事項とより広範な影響

### ポジティブな影響

- **民主化**: 以前は独自システムにアクセスできなかった研究者や実践者が高度な進化的最適化を利用可能に
- **リソース効率性**: 例外的なサンプル効率により、リソースに制約のある環境での計算障壁を削減
- **再現性**: オープンソースのリリースにより、透明性とコミュニティ主導の改善を促進

### 潜在的な懸念

- **APIコスト**: 大規模なLLM使用による経済的障壁が、民主化の目標を制約する可能性
- **エネルギー消費**: 多数のLLMクエリの環境への影響
- **デュアルユース**: 強力な最適化ツールの潜在的な悪用

## 主要な貢献者

- **Robert Tjarko Lange**: プロジェクトの開始とリード、コアコードベースの設計と実装、Circle Packing、AIME、ALE-Benchの結果収集、論文執筆
- **Yuki Imajuku**: ALE-Benchインフラストラクチャの設定支援、ALE-Bench結果へのアドバイス、論文セクション執筆支援
- **Edoardo Cetin**: ShinkaEvolveの設計ディスカッションへの参加、適応的LLMサンプリング手法とHydra構成の考案・実装、LLM訓練とMixture-of-Experts進化の結果実装と収集、論文共同執筆

## リソース

- **GitHubリポジトリ**: [https://github.com/SakanaAI/ShinkaEvolve](https://github.com/SakanaAI/ShinkaEvolve)
- **ライセンス**: Apache 2.0
- **対応著者**: Robert Tjarko Lange (<robert@sakana.ai>), Edoardo Cetin (<edo@sakana.ai>)
- **組織**: Sakana AI

## 結論

ShinkaEvolveは、LLM駆動の科学的発見における重要な進歩を表しています。3つの主要なアルゴリズム革新(適応的親サンプリング、新規性リジェクションサンプリング、バンディットベースLLMアンサンブル選択)を通じて、既存のアプローチの主要な制限であるサンプル非効率性とクローズドソースの性質に対処しています。

4つの異なる問題領域での包括的な検証により、以下が実証されました:

- **比類のない効率性**: わずか150評価で最先端の円パッキングソリューション
- **ロバストな一般化**: 未見の問題とさまざまなLLMモデルへの転移
- **実用的な影響**: 実世界の競技プログラミング問題での改善
- **新しい科学的洞察**: MoE訓練のための新しい負荷分散損失の発見

オープンソースのリリース、例外的なサンプル効率、広範な適用性により、ShinkaEvolveは高度な進化的発見ツールへのアクセスを民主化し、コミュニティ主導の改善を可能にします。この研究は、LLMが科学的発見とアルゴリズム設計を加速するための強力なツールとして機能する未来への道を開きます。
