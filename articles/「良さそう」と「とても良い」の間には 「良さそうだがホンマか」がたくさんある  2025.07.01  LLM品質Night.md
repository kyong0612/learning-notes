---
title: "「良さそう」と「とても良い」の間には 「良さそうだがホンマか」がたくさんある / 2025.07.01  LLM品質Night"
source: "https://speakerdeck.com/smiyawaki0820/2025-dot-07-dot-01-llmpin-zhi-night"
author:
  - "Shumpei Miyawaki"
published: 2025-07-01
created: 2025-07-23
description: |
  LLMプロダクトの品質を「良さそう」から「とても良い」へと引き上げるための具体的なアプローチについて解説した資料。開発者の説明責任、ガードレールによるリスク管理、アジャイルな品質保証体制の構築という3つのステップを通じて、LLMプロダクトの品質を継続的に向上させる方法を提案します。
tags:
  - "LLM"
  - "AI"
  - "品質保証"
  - "アジャイル"
  - "ガードレール"
  - "clippings"
---

この資料は、LLMプロダクトの品質を「良さそう」というレベルから「とても良い」というレベルへと継続的に向上させるための戦略を3つのステップで解説しています。

---

### はじめに: 「良さそう」から「とても良い」へ

LLMプロダクトの品質向上は、以下の3つのステップで達成できると提案されています。

1. **「良さそう」から脱却する**: 開発者の説明責任を明確にする。
2. **「とても良さそう」から脱却する**: 防御策としてのガードレールを講じる。
3. **「とても良い」を継続する**: 品質保証をチーム全体に分散させる。

![slide_3.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_3.jpg)

---

### ステップ1: 「良さそう」から脱却する - LLM出力への説明責任

最近のLLMは抽象的な指示でも「いい感じ」の出力を生成しますが、そのままでは多くの問題が潜んでいます。

* **課題**: 請求書PDF以外の入力、制約条件、具体的な出力形式などが考慮されていない。
* **開発者の責任**: なぜその出力になったのか、どうすれば改善できるのかを説明できる必要がある。これは、プロンプト、モデルの特性、利用規約などのレベルでの説明責任を指します。
* **LLMへの指示**: LLMは形式的な言語能力に長けているが、機能的な言語能力には懐疑的であるべき。特に「概念化」（何をどのような構造で出力させるか）は開発者が責任を持つべきです。
* **オンボーディング**: 現場の担当者が納得できるような判定要件や採点基準を設計し、LLMに正しく「オンボーディング」することが、信頼されるシステムへの第一歩となります。

![slide_7.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_7.jpg)
![slide_9.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_9.jpg)

---

### ステップ2: 「とても良さそう」から脱却する - ガードレールの重要性

技術的な不確実性を解消しただけでは、ユーザーにとって「使える」プロダクトにはなりません。そこで重要になるのが「ガードレール」です。

* **ガードレールとは**: アプリケーションの望ましくない動作を観測可能にし、有害なコンテンツの提供を防ぐ仕組みです。多層・多重防御によってリスクを最小限に抑えます。
* **ガードレールの利点**:
    1. **リスク低減**: 個人情報などのサニタイズや、不適切コンテンツの出力リスクを低減します。
    2. **説明責任**: ブラックボックスなシステムに対しても、出力品質に対する最低限の説明を可能にします。
    3. **間接的な定量評価**: ガードレールの通過率をモニタリングすることで、システムの品質を間接的に評価できます。
    4. **観測点の設置**: 入出力データを分析し、エラーの傾向を理解するのに役立ちます。
* **実装**: アラートやフェイルセーフとセットで実装し、ファネルごとの通過率を追跡して、過剰な拒否が起きていないか監視することが重要です。
* **注意点 - 自動化バイアス**: ガードレールに慢心すると、検知漏れ (False Negative) や、人間による最終チェックが形骸化する「rubber stamping」といった問題につながる可能性があります。

![slide_12.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_12.jpg)
![slide_14.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_14.jpg)
![slide_16.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_16.jpg)

---

### ステップ3: 「とても良い」を継続する - アジャイルな品質保証

信頼できる評価は非常に難しく、特に開発初期段階では定量的な評価の価値は限定的です。

* **評価の難しさ**: 「精度98%」といった指標だけでは、評価基準、データセットの妥当性、ビジネスへの影響などが不明瞭です。
* **アジャイルな評価計画**: 開発初期は、安全な動作、可観測性、制御可能性の保証を優先し、運用を通じて定量的な性能が明らかになる仕組みを構築します。
* **チームでの品質保証**:
  * **障壁の解体**: LLMプロダクト開発では「小さくはやく回す」ことが重要。開発者だけでなく、顧客やセールスなど、チーム全員の間の「障壁」を取り払うことが不可欠です。
  * **品質作業の分担**: PO、エンジニア、CSなど、チーム全員が品質にフィードバックできる体制を築きます。「価値ナラティブ」「責任ナラティブ」「テストナラティブ」をチームで共有し、品質に対する共通認識を醸成します。
* **リスクの早期共有**: 機械学習品質マネジメントガイドラインなどを参考に、システムが社会に与える潜在的なリスク（人的・経済的）を早期にチーム内で共有し、対応方針を定めておくことが重要です。

![slide_18.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_18.jpg)
![slide_21.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_21.jpg)
![slide_22.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_22.jpg)

---

### まとめ

本資料の結論は以下の通りです。

1. **説明責任を持つ**ことで「良さそう」から脱却する。
2. **防御策（ガードレール）を講じる**ことで「とても良さそう」から脱却する。
3. **品質保証をチームで分散する**ことで「とても良い」を継続する。

![slide_24.jpg](https://files.speakerdeck.com/presentations/aeb80953416b455a8586bfdeaa7a4c4e/slide_24.jpg)
