# Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation

ref: <https://www.arxiv.org/abs/2503.16789>

## 要約

### 概要

人間とLLMの会話は個人的・職業的生活でますます普及していますが、多くのユーザーはLLMチャットボットから満足のいく回答を得るのに苦労しています。その主な理由の一つは、ユーザーが自分の情報ニーズを正確に伝える効果的なプロンプトを作成する方法を理解していないことです。本研究は、実際の人間-AIチャットボット会話を対象とした初のLLM中心の研究で、ユーザークエリが情報ニーズを表現する際の不足点と、LLMを使用して最適でないユーザープロンプトを書き換える可能性を調査しています。

### 研究目的と方法

本研究では、以下のフレームワークを使用して調査を行いました：

1. 二つのLLMを使用：
   - チャットボット（ユーザーが会話するLLM）
   - リライター（プロンプトを書き換えるLLM）
2. WildChatデータセットから不満足な結果（DSAT）を含む会話を分析
3. リライターLLMを使用して前のユーザーターンを再構成し、チャットボットの反応を測定
4. プロンプト書き換えにおける追加的なインサイト（クエリ改善の側面、モデルの仮定）を収集

実験は、5つの会話ドメインとユーザー意図のペアで、GPT-4o、GPT-4o-mini、llama-3-70B-Instruct、llama-3-8B-Instruct、Ministral-3Bという5つの異なるサイズと種類のLLMを使用して実施されました。

### 主な発見

1. **プロンプト書き換えの効果**：
   - 書き換えられたプロンプトは一貫してより良いLLM応答を生成
   - 特に「情報探索」意図では、GPT-4oとGPT-4o-miniで約80%のケースで書き換え後の応答が優れていた
   - 文章作成タスクでは効果が低いものの、大きなモデルでは依然として良い結果が得られた

2. **会話の長さとの関係**：
   - 会話が深まるほど、プロンプト書き換えの成功率が高まる
   - より長い会話履歴がある場合、ほとんどのモデルでパフォーマンスが向上
   - これは文脈的な推論がユーザーニーズをより正確に捉えられることを示している

3. **小型モデルの有効性**：
   - 小型モデルでもプロンプト書き換えには効果的
   - 小型モデルがリライターとして機能し、より大きなモデル（GPT-4o）がチャットボットとして応答すると、応答品質が大幅に向上
   - これはオンデバイスモデルでも効果的なプロンプト書き換えが可能なことを示唆

4. **ドメイン別の改善側面**：
   - ソフトウェア開発と文章作成では、改善が必要な側面が異なる
   - ソフトウェアプロンプトは「目標の明確化」や「エラーコンテキスト」に焦点
   - 文章作成プロンプトは「適切さ」や「倫理的・文化的感受性」が重要

5. **モデルの仮定**：
   - LLMはプロンプトを解釈する際にユーザーの意図について「もっともらしい」仮定を行う
   - 多くの場合、これらの仮定は妥当であるが、会話の早い段階では明確化質問をすることが望ましい

### 検証と制限事項

1. **人間による検証**：
   - GPT-4oによる評価と人間評価者の間には中程度の一致（Krippendorff's alpha 0.61）
   - 提案された書き換えの74%が強い意図維持を示し、21%がある程度意図を維持

2. **制限事項**：
   - 実環境（in-situ）での効果を評価することの難しさ
   - 特に文章作成タスクにおけるトーン、スタイル、簡潔さの主観性
   - コーディングタスクの評価にはドメイン専門家または制御環境が必要
   - 安全性とユーザー意図保存のバランスの課題

### 結論と今後の展望

この研究は、LLMを活用したプロンプト書き換えが、人間-AI間の対話を改善する有望な戦略であることを示しています。研究結果は以下の点を示唆しています：

1. 小型のオンデバイスモデルでもプロンプト書き換えに有効だが、より良い応答にはより大きなモデルが必要
2. モデルはユーザーについて妥当な仮定を行い、必要な場合には明確化質問をする必要がある
3. LLMは長い文脈の理解と推論能力を向上させる必要がある

これらの方向性は将来の研究課題とされています。
