---
title: "20251029_Cursor Meetup Tokyo ＃02_MK_「あなたのAI、私のシェル」 - プロンプトインジェクションによるエージェントのハイジャック"
source: "https://speakerdeck.com/mk0721/20251029-cursor-meetup-tokyo-number-02-mk-anatanoai-si-nosieru-puronputoinziekusiyonniyoruezientonohaiziyatuku"
author:
  - "[[Masayuki Kawakita]]"
published: 2025-10-29
created: 2025-10-31
description: "Cursor Meetup Tokyo #02でのMKによる発表。AIコーディングアシスタントにおけるプロンプトインジェクション攻撃の実態と防御戦略を解説。RAG経由の間接攻撃、MCPoison/TOCTOU、CurXecute (CVE-2025-54136) など複数の実証済み攻撃シナリオを紹介し、LLMアーキテクチャの根本的な脆弱性である信頼境界の喪失について論じる。"
tags:
  - "clippings"
  - "AI-security"
  - "prompt-injection"
  - "Cursor"
  - "LLM"
  - "vulnerability"
  - "agent-security"
  - "CVE"
---

## 概要

本プレゼンテーションは、AIセキュリティ研究者MK (Masayuki Kawakita) によるCursor Meetup Tokyo #02での発表資料。AIコーディングアシスタントエージェントに対するプロンプトインジェクション攻撃の実態と、その根本的な脆弱性について詳細に解説している。

## 発表者プロフィール

**MK (Masayuki Kawakita)**

- システムエンジニア・AIセキュリティ専門家
- Anthropicのレッドチーム活動に従事
- 複数の国際ハッカーコンテストで受賞歴
- ソフトウェアデザイン誌「AIセキュリティ入門」特集執筆予定

## 主要な攻撃シナリオ

### 1. RAG経由の間接プロンプトインジェクション

**攻撃メカニズム:**

- 外部Webサイトに埋め込まれた隠れたコマンドがAIエージェントを経由して実行される
- HTMLコメントアウト内に仕込まれた悪意ある指示
- 開発者が疲労時に検証なくコマンドを実行してしまう心理的要因を悪用

**技術的背景:**
参考論文「In-Browser LLM-Guided Fuzzing」(arXiv:2510.13543)では、静的防御策がわずか10回の反復で破られる可能性が実証されている。

### 2. MCPoison/TOCTOU攻撃

**脆弱性の詳細:**

- 一度承認されたMCP (Model Context Protocol) 設定が後から変更されても、キー名の一致のみで再検証されない
- Time-of-Check Time-of-Use (TOCTOU) 競合状態の典型例
- **CVE-2025-54136**として正式に報告済み

**影響範囲:**

- バージョン1.3で修正済み
- 古いバージョンを使用している環境は依然として危険

### 3. CurXecute (承認前RCE)

**最も危険な脆弱性:**

- **CVSSスコア: 9.8 (CRITICAL)**
- `.cursor/rules`内にゼロ幅文字で隠された指示を埋め込む
- AIがmcp.json変更を提案
- 承認ボタン押下**前**にファイルが書き込まれる実装バグを悪用
- ユーザー承認を完全にバイパス可能

**攻撃の流れ:**

1. ゼロ幅文字により視覚的に検出不可能な指示を埋め込む
2. AIが悪意あるmcp.json変更を提案
3. 実装バグによりユーザー承認前にファイル書き込みが発生
4. Remote Code Execution (RCE) が成立

### 4. Workspace Trust RCE (Appendix)

**追加の攻撃ベクター:**

- Workspace Trust設定を無効化した環境が標的
- `.vscode/tasks.json`の自動実行機能を悪用
- リポジトリを開いただけでRCEが成立

## 根本的な問題: 信頼境界の喪失

### LLMアーキテクチャの本質的脆弱性

**信頼境界概念の欠落:**

- システムプロンプト、ユーザー入力、外部データがすべてトークン列に混在
- Attentionメカニズムは「重要度」は判定可能だが「信頼性」は判定不可
- すべての入力が等価に扱われる構造的問題

**混乱した代理人問題 (Confused Deputy Problem):**
LLMは信頼できる情報源と汚染された外部データを区別できず、攻撃者の意図を開発者の意図として誤認識する。これにより、AIエージェントは意図せず攻撃者の代理人として機能してしまう。

## 防御戦略: 多層防御アプローチ

### 第1層: 人的防御

- **ゼロトラストマインドセット**: AIは確率的に騙されうる存在と認識
- **AI提案コマンドの精査**: すべての提案を批判的に検証
- **疲労管理**: 疲労時の自動承認を避ける

### 第2層: ツール設定

- **Cursor最新化**: セキュリティパッチの適用
- **セキュリティ設定有効化**: 厳格な承認フローの設定
- **サプライチェーン管理**: MCP拡張機能の出所確認

### 第3層: システム隔離

- **最小権限原則**: 必要最小限のアクセス権限のみ付与
- **機密情報隔離**: 重要データの物理的分離
- **サンドボックス化**: Docker/VMによる実行環境の隔離

### 第4層: 監視・検知

- **EDR (Endpoint Detection and Response)**: エンドポイント監視
- **異常通信検知**: ネットワークトラフィックの監視

## 重要な認識の転換

### 「AIは信頼できる」という神話の終焉

開発者は以下の認識を持つべき:

- AIは完全に信頼できるアシスタントではなく、確率的に騙されうる存在
- セキュリティ警告の無視や疲労時の自動承認は組織全体の崩壊につながる
- 便利さとセキュリティのトレードオフを常に意識

### 組織的対応の必要性

個人の注意だけでは不十分であり、以下が必要:

- セキュリティポリシーの策定
- 定期的なセキュリティトレーニング
- インシデント対応計画の整備
- 技術的防御策の導入

## 結論

AIコーディングアシスタントの普及に伴い、プロンプトインジェクション攻撃は理論上の脅威から実証済みの現実的リスクへと変化している。CVE-2025-54136のようなCRITICALレベルの脆弱性が発見されている現状において、開発者は多層防御アプローチを採用し、AIを「便利だが信頼境界を持たないツール」として適切に扱う必要がある。

## 参考文献

- arXiv:2510.13543 - "In-Browser LLM-Guided Fuzzing"
- CVE-2025-54136 - CurXecute脆弱性の公式レポート

## 補足

本プレゼンテーションは27スライドで構成され、理論的な脆弱性解説だけでなく、実証済みの攻撃シナリオと具体的な防御策を提示している。AIセキュリティの最前線で活動する研究者による、実践的かつ包括的な内容となっている。
