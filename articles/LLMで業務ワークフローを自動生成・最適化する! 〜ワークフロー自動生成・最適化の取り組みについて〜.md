---
title: "LLMで業務ワークフローを自動生成・最適化する! 〜ワークフロー自動生成・最適化の取り組みについて〜"
source: "https://tech.layerx.co.jp/entry/2025/11/19/133143"
author:
  - "[[kyanome]]"
  - "[[makoga]]"
  - "[[yata0e2b3c]]"
  - "[[shibuiyusuke]]"
  - "[[convto]]"
  - "[[takatorix]]"
  - "[[pon (id:abctail30)]]"
  - "[[ぴろしき (id:pirosikick)]]"
  - "[[applism118]]"
  - "[[shibu526]]"
published: 2025-11-19
created: 2025-11-21
description: "LayerX AI Workforce事業部のR&Dチームが開発する、プロンプトとワークフロー構造を同時に自動生成する手法について。300ページ超の報告書から構造化データを抽出するタスクを例に、6ノードのワークフローで98.1%の精度を達成。LLMとPythonの役割分担、大規模データへのチャンキング戦略の自動発見など、実務レベルのタスクへの応用可能性を示す。"
tags:
  - "AI Agent"
  - "機械学習"
  - "LLM"
  - "ワークフロー自動生成"
  - "R&D"
  - "clippings"
---

# 1. 背景

## AIワークフローとは

AIワークフローとは、LLMとコードを複数回呼び出し、結果を組み合わせて複雑なタスクを解決する手法です。シンプルなタスクであればLLMへの単発指示で完了しますが、実務レベルの複雑なタスクでは精度が出ません。例えば、見積書から数百種類の固定資産コードに分類するタスクでは、PDFから情報を抽出し、商品とサービスを区別し、ドメイン知識に基づいて分類する必要があります。

こうした複雑なタスクでは、「文章を要約する」→「情報を抽出する」→「整形する」といったように複数のステップを組み合わせることで、タスクを分解して精度を高めます。

## AIワークフロー構築の課題

### ① ワークフロー構築に手間と時間がかかる

お客様のドメインを理解し、精度の出るワークフローを構築する作業には相当の時間が必要です。どのようなノード構成にするか、各ノードでどのようなプロンプトを使うか、といった設計を試行錯誤しながら進める必要があります。

### ② LLMの変更やデータの変化に対して堅牢でない

対応できないデータが出てきた場合に、ワークフローを修正する必要がありますが、工数がかかります。また、LLMのバージョンアップや、新しいLLMへの切り替えがあると、調整が必要になることもあります。

# 2. ワークフロー自動生成・最適化手法

これらの課題を解決するために、最近はプロンプトとワークフロー構造を同時に自動生成する手法が提案されています。LayerXのApplied R&Dチームでは、先行研究（Zhang et al. "AFlow: Automating Agentic Workflow Generation" ICLR 2025）を参考に、ワークフロー自動生成・最適化手法を開発しています。

## アーキテクチャー

ワークフロー自動生成・最適化アルゴリズムは、以下の4つのコンポーネントで構成されています：

1. **Generator**: LLMを用い、meta promptと過去の試行結果（Context）から新しいワークフロー候補を生成
   - 3種類のノードタイプ：LLMノード、Vision LLMノード、Codeノード
   - どのノードをどの順番で使うか、各ノードでどのようなプロンプト/コードを使うかを自動生成

2. **Executor**: 生成されたフロー（LLMとPythonの組み合わせ）を実行

3. **Evaluator**: 実行結果を定量評価し、そのワークフローの性能を定量的に評価

4. **Memory**: 過去の試行結果（ワークフロー、スコア、フィードバック）を保存し、Generatorにフィードバック

これらのコンポーネントが連携して試行錯誤を繰り返すことで、徐々にワークフロー構造とプロンプト、コードが洗練されていきます。今回検証した2つのタスクでは、5〜7回の試行で高精度なワークフローが見つかりました。

## 実行時間・コスト

1回の試行は10〜15分程度で、コストは約5ドルです。このコストには、ワークフロー生成（Generator）とワークフロー評価（Executor + Evaluator）の両方が含まれます。なお、今回はワークフロー評価に比較的安価なモデル（gpt-4o-miniなど）を使用しています。より高性能なモデル（gpt-4.1、gpt-5など）をワークフロー内で使用する場合は、コストはさらに高くなる点に注意が必要です。

# 3. 実例：プロジェクト完了報告書からの実績データ抽出・計算タスク

## どんなタスクか

プロジェクトの完了報告書PDF（300ページ超、約100万文字）から、プロジェクト実績データ（工数、コスト、スケジュール、品質指標など）を構造化抽出・計算するタスクです。

**注：本タスクは実際の財務報告書からの抽出で検証しましたが、機密性の観点から、本稿ではプロジェクト報告書という形式に置き換え、数値も変更して記載しています。タスクの構造や難易度は同等です。**

## 入力ドキュメント

大規模プロジェクト完了報告書（約300ページ）で、以下のような構成：

- Executive Summary（要約）
- Project Timeline（スケジュール）
- Resource Allocation（リソース配分）
- Deliverables（成果物）
- Quality Metrics（品質指標）
- Budget Performance（予算実績）
- Lessons Learned（教訓）
- Appendix（付録）

## 正解データ

報告書から以下の5つのカテゴリの実績データを抽出：

1. プロジェクトスケジュール（総日数、各フェーズの日数、アクティビティ別の日数）
2. リソース実績（総工数、役割別内訳、インフラコスト）
3. 成果物（コード行数（言語別）、テストカバレッジ、ドキュメント量）
4. 品質指標（バグ統計（総数、重大度別、密度）、パフォーマンス指標）
5. 予算実績（計画予算、実績コスト、差異）

これらは最大6層の深い階層構造で整理されており、合計48個の数値を全て正確に抽出する必要があります。

## タスクの難しさ

1. **超大規模文書**: 300ページ、850,000文字という大規模文書を処理する必要がある。関連情報が様々なセクションに分散しており、それらを統合して抽出する必要がある。

2. **深い階層構造**: 最大6層という深い階層構造でデータが整理されており、例えば「リソース実績 → 人的リソース → 総工数 → 役割別 → エンジニアリング → 内訳 → シニアエンジニア」というパスを辿る必要がある。

3. **計算処理が必要**: 一部のフィールドは文書に明記されておらず、計算処理が必要（総工数 = エンジニア + QA + PM + DevOps、予算差異 = 予算 - 実績、バグ密度 = (総バグ数 / 総コード行数) × 1000など）。

## 自動生成されたワークフロー

アルゴリズムが発見したのは、6つのノードからなるワークフローです。各報告書ごとにこのワークフローを実行します。

```
報告書PDF（300ページ）
  ↓
【ノード1】1ページずつテキスト化（Codeノード）
  ↓
【ノード2】重要ページを判定（LLMノード・300回ループ）
  ↓
【ノード3】重要ページを選択・結合（Codeノード）
  ↓
【ノード4】データを抽出（LLMノード）
  ↓
【ノード5】合計値を計算（Codeノード）
  ↓
【ノード6】単位を正規化（Codeノード）
  ↓
最終出力（精度：98.1%）
```

アルゴリズムは、300ページ（850,000文字）という大規模データに対して、自動的にチャンキング（分割・選択・結合）が必要だと判断しました。LLMのコンテキスト制限（通常10万文字程度）を考慮し、ノード2とノード3で重要なページだけを抽出して85,000文字に圧縮するワークフローを自ら生成しています。この「大規模データへの対処方法」を人間が指示することなく、アルゴリズムが自動発見した点が重要です。

### ノード1：1ページずつテキスト化（Codeノード）

300ページのPDFから、各ページをテキストに変換し、ページ番号とテキストのペアのリストを作成します。

```python
import pypdf

reader = pypdf.PdfReader(pdf_path)
pages = []
for i, page in enumerate(reader.pages, start=1):
    text = page.extract_text() or ""
    pages.append({"page_num": i, "text": text})
```

### ノード2：重要ページを判定（LLMノード・ループ処理）

300ページ全てに対して、各ページを4カテゴリに分類（主要データ、成果物・品質、補足詳細、その他）し、具体的な数値が含まれるかを判定し、keep=true/falseフラグを付与します。各ページをループ処理するため、300ページなら300回LLM呼び出しを行います。

生成されたプロンプトの特徴：

- 4カテゴリによる明確な分類基準
- 数値の有無による判定
- 各ページに対する個別判断

300ページから重要な30ページ程度に絞り込むことで、次のノードの処理負荷を削減します。

### ノード3：重要ページを選択・結合（Codeノード）

ノード2の判定結果から、keep=trueのページだけを選択し、カテゴリ別の優先度でソート（主要データ→成果物→補足）し、上位20ページ、85,000文字まで結合します。

生成されたコードの特徴：

- カテゴリ優先度による効率的なソート
- LLMのコンテキスト制限を考慮した85,000文字制限

300ページ（850,000文字）を20ページ（85,000文字）に圧縮しながら、重要情報は全て保持します。

### ノード4：データを抽出（LLMノード）

85,000文字のテキストから、48個の数値を6層の階層構造で抽出します。明示された数値のみ抽出し（推測・計算禁止）、見つからない項目は0とします。

生成されたプロンプトの特徴：

- 「計算禁止」を徹底することでLLMの誤差を防ぐ
- 48個のフィールドの詳細な定義
- 見つからない場合の明確な処理

LLMには「読み取り」だけをさせ、「計算」は次のノードで確実に行います。

### ノード5：合計値を計算（Codeノード）

ノード4の出力から、合計値を計算（総日数、総工数など）、差異を計算（予算差異など）、バグ密度を計算します。

生成されたコードの特徴：

- Pythonによる確実な計算処理
- 階層構造を辿った値の取得
- ゼロ除算の防止

LLMには計算をさせず、Pythonで確実に処理することで精度を高めます。

### ノード6：単位を正規化（Codeノード）

パーセント値を整数化（99.85% → 9985）し、全てのvalueフィールドを再帰的に処理し、最終的な出力形式に変換します。

# 4. 考察

## LLMとPythonの役割分担

生成されたワークフローを分析すると、興味深い役割分担が見られました。LLMは「読み取り」「分類」「判断」といった意味理解が必要なタスクに使われ、Pythonは「計算」「データ変換」「集約」といった確実性が求められるタスクに使われていました。

例えば、このタスクでは、LLMがテキストから数値を読み取り（ノード4）、Pythonが合計値を計算する（ノード5）という明確な分担がありました。プロンプトには「計算禁止」と明示されており、LLMの計算能力の不確実性を避け、Pythonの確実性を活用する設計になっています。

## チャンキング戦略の自動発見

このタスクで特に重要だったのは、アルゴリズムが大規模データへの対処方法を自動発見したことです。

300ページの文書を処理するために、「重要ページを判定→選択・結合→データ抽出」という3ステップの戦略を生成しました。この戦略により、850,000文字を85,000文字に圧縮しながら、必要な情報は全て保持することができました。

# 5. 限界と今後の方針

## 精度評価について

本稿で示した約90%の精度は、訓練データに対する精度です。これには理由があります。

まず、我々の現在の目標は、アルゴリズムが訓練データに対して適切にフィットできるかを確認することです。訓練データでさえ高精度が出せなければ、実用化は困難です。

次に、我々のアプローチは、未知のデータが来た時にも同じアルゴリズムで再フィッティングすることを前提としています。新しいフォーマットの見積書や報告書が登場した際、数件のサンプルデータを用意し、再度ワークフロー自動生成を実行することで対応します。このため、まずは訓練データでの性能を確実にすることを優先しています。

もちろん、未知のテストデータでの汎化性能の検証は重要です。今後は、訓練データとは別のテストデータを用意し、汎化性能を評価していく予定です。このような段階的なアプローチにより、技術の実用性を着実に高めていきます。

# 6. まとめ

本稿では、ワークフロー自動生成技術により生成されたワークフローの詳細を、300ページ超の報告書からのデータ抽出タスクを例に紹介しました。

このタスクでは、6ノードのワークフローで約98.1%の精度を達成しました。特に注目すべきは、アルゴリズムが自動的にチャンキング戦略を発見し、大規模データを効率的に処理できることが示された点です。また、LLMには「読み取り」を、Pythonには「計算」を担当させるという役割分担も、自動的に発見されました。

これらの結果から、ワークフロー自動生成技術は実務レベルのタスクに応用できる可能性を示唆しています。今後はより複雑なタスクへの適用、さらなる精度向上、そして様々なドメインでの検証を進めていく予定です。

# 参考資料

- より詳細な探索アルゴリズム（Repeated samplingの活用）、コンテキストの設計、フィードバックの与え方などについては、[Speaker Deck](https://speakerdeck.com/kyanome/agentic-workflowzi-dong-sheng-cheng-nixiang-ketaqu-rizu-mi)を参照
- 先行研究: Zhang et al. "AFlow: Automating Agentic Workflow Generation" ICLR 2025
