# Video-MME: マルチモーダルLLMのビデオ分析における包括的評価ベンチマーク

参照: [https://video-mme.github.io/home_page.html](https://video-mme.github.io/home_page.html)

## 概要

Video-MMEは、マルチモーダル大規模言語モデル（MLLM）のビデオ分析能力を評価する初の包括的なベンチマークです。このベンチマークは以下の4つの特徴を持っています：

1. **多様なビデオタイプ**: 6つの主要な視覚ドメインと30のサブカテゴリーをカバーし、幅広いシナリオへの一般化可能性を確保
2. **時間軸の多様性**: 短時間（<2分）、中時間（4〜15分）、長時間（30〜60分）のビデオを含み、11秒から1時間までの範囲をカバー
3. **データモダリティの幅広さ**: ビデオフレーム以外に字幕や音声などのマルチモーダル入力を統合
4. **高品質な注釈**: 専門のアノテーターによる厳格な手動ラベリングを使用し、正確で信頼性の高いモデル評価を実現

合計254時間の900本のビデオが手動で選択・注釈付けされ、2,700の質問回答ペアが作成されています。

## 主要な実験結果

1. **トップパフォーマンスモデル**:
   - Gemini 1.5 Proが商用モデルとして最高のパフォーマンス（平均精度75%）
   - GPT-4oは71.9%の精度

2. **ベンチマークの普遍性**:
   - Video-MMEは画像MLLMとビデオMLLMの両方に適用可能な普遍的なベンチマーク

3. **マルチモーダル情報の重要性**:
   - 字幕と音声情報はビデオ理解を大幅に向上させる

4. **ビデオ長の影響**:
   - すべてのモデルでビデオの長さが増すにつれてパフォーマンスが低下

## リーダーボード

トップパフォーマンスモデル（字幕ありの全体精度）:

1. Gemini 1.5 Pro (Google) - 81.3%
2. AdaReTaKe (HIT & Huawei) - 79.6%
3. Qwen2-VL (Alibaba) - 77.8%
4. GPT-4o (OpenAI) - 77.2%
5. LLaVA-Video (Bytedance & NTU S-Lab) - 76.9%

## ベンチマークの統計

- **ビデオカテゴリ階層**: 6つの主要ドメインと30のサブカテゴリーで構成
- **ビデオ長と課題タイプの分布**: 様々な長さのビデオとMLLMの複数のコア能力を評価

## 実験結果の詳細

### 質問タイプ別の結果

代表的な4つのMLLMの評価結果が示されており、質問タイプによるパフォーマンスの違いを分析しています。

### ビデオ長別の結果

特にGemini 1.5 Proの評価結果が詳しく示されており、ビデオの長さやサブカテゴリによるパフォーマンスの変化が分析されています。

## 制限事項と今後の課題

研究結果からは、長いシーケンスとマルチモーダルデータの処理におけるMLLMの改善が必要であることが示されています。ビデオの長さが増すにつれてパフォーマンスが低下する傾向が見られ、今後のMLLM開発の方向性を示唆しています。

![データ構成](https://video-mme.github.io/static/images/data_sta_2.png)

*左図: ビデオカテゴリ階層、右図: ビデオ長と課題タイプの分布*
