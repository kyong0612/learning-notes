---
title: "優れたシステム設計について私が知っていることのすべて"
source: "https://www.seangoedecke.com/good-system-design/"
author:
published:
created: 2025-08-26
description: "私は悪いシステム設計のアドバイスをよく目にします。典型的なのは、LinkedInに最適化された「キューなんて聞いたことないでしょう」といったスタイルの投稿で、おそらく業界に入ったばかりの人を対象にしています..."
tags:
  - "clippings"
---
私は悪いシステム設計のアドバイスをよく目にします。典型的なのは、LinkedInに最適化された「*キュー*なんて聞いたことないでしょう」といったスタイルの投稿で、おそらく業界に入ったばかりの人を対象にしています。もう一つは、Twitterに最適化された「データベースにブール値を保存するなんて、ひどいエンジニアだ」という賢いトリックです。優れたシステム設計のアドバイスでさえ、ある種悪いものになり得ます。私は*Designing Data-Intensive Applications*が大好きですが、エンジニアが遭遇するほとんどのシステム設計問題にとって特に有用だとは思いません。

システム設計とは何でしょうか？私の見解では、ソフトウェア設計がコードの行を組み立てる方法であるならば、システム設計は*サービス*を組み立てる方法です。ソフトウェア設計のプリミティブは、変数、関数、クラスなどです。システム設計のプリミティブは、アプリケーションサーバー、データベース、キャッシュ、キュー、イベントバス、プロキシなどです。

この記事は、私が知っている優れたシステム設計に関するすべてを、大まかに書き留めようとする試みです。具体的な判断の多くは経験に帰着するものであり、それをこの記事で伝えることはできません。しかし、書けることは書き留めようとしています。

### 良い設計を認識する

良いシステム設計とはどのようなものでしょうか？私は以前、それは[地味に見える](https://www.seangoedecke.com/great-software-design)と書きました。実際には、長い間何も問題が起こらないように見えます。良い設計の存在は、「あれ、思ったより簡単だったな」とか、「この部分のことは全く考えなくても大丈夫だ」といった考えを持つことでわかります。逆説的ですが、良い設計は自己主張しません。悪い設計の方がしばしば印象的です。私はいつも、印象的に見えるシステムを疑っています。システムが分散合意メカニズム、多様なイベント駆動型通信、CQRS、その他の賢いトリックを備えている場合、何か根本的に悪い決定が補われているのではないか（あるいは、単に過剰設計なのではないか）と疑問に思います。

この点について、私はしばしば孤立しています。エンジニアは多くの興味深い部分を持つ複雑なシステムを見て、「すごい、ここではたくさんのシステム設計が行われている！」と考えます。実際には、複雑なシステムは通常、良い設計の欠如を反映しています。「通常」と言ったのは、時には複雑なシステムが必要になることもあるからです。私はその複雑さに価値がある多くのシステムに取り組んできました。しかし、機能する複雑なシステムは、常に機能する単純なシステムから進化するものです。ゼロから複雑なシステムを始めるのは、本当に悪い考えです。

### 状態とステートレス性

ソフトウェア設計の難しい部分は状態（ステート）です。何らかの情報をある程度の時間保存する場合、それをどのように保存し、保管し、提供するかについて、多くの難しい決定を下さなければなりません。情報を保存しない場合、アプリは「ステートレス」です。些細な例ではありませんが、GitHubにはPDFファイルを受け取り、そのHTMLレンダリングを返す内部APIがあります。これは本物のステートレスサービスです。データベースに書き込むものはすべてステートフルです。

どのようなシステムにおいても、ステートフルなコンポーネントの数を最小限に抑えるべきです。（ある意味では、これは自明のことです。なぜなら、システムの*すべて*のコンポーネントの数を最小限に抑えるべきだからですが、ステートフルなコンポーネントは特に危険です。）これをすべき理由は、**ステートフルなコンポーネントは悪い状態に陥る可能性がある**からです。私たちのステートレスなPDFレンダリングサービスは、おおむね賢明なことをしている限り、永遠に安全に動作します。例えば、再起動可能なコンテナで実行すれば、何か問題が発生した場合でも自動的に強制終了され、正常な状態に復元されます。ステートフルなサービスは、このように自動的に修復することはできません。データベースに不正なエントリが（例えば、アプリケーションのクラッシュを引き起こすフォーマットのエントリが）入ってしまった場合、手動で修正する必要があります。データベースの容量が不足した場合、不要なデータを削除するか、拡張する方法を見つけなければなりません。

これが実際に意味することは、状態を認識する1つのサービス（つまり、データベースと通信するサービス）を持ち、他のサービスはステートレスなことを行う、ということです。5つの異なるサービスがすべて同じテーブルに書き込むようなことは避けてください。代わりに、そのうちの4つが最初のサービスにAPIリクエストを送信（またはイベントを発行）し、書き込みロジックはその1つのサービス内に保持します。可能であれば、読み取りロジックについてもこれを行う価値がありますが、これについてはそれほど絶対主義的ではありません。サービスが`user_sessions`テーブルを素早く読み取る方が、内部のセッションサービスに2倍遅いHTTPリクエストを行うよりも*時々*良い場合があります。

### データベース

状態の管理はシステム設計の最も重要な部分であるため、最も重要なコンポーネントは通常、その状態が存在する場所、つまりデータベースです。私はほとんどの時間をSQLデータベース（MySQLとPostgreSQL）で作業してきたので、それについて話します。

#### スキーマとインデックス

データベースに何かを保存する必要がある場合、最初に行うことは、必要なスキーマでテーブルを定義することです。スキーマ設計は柔軟であるべきです。なぜなら、何千、何百万ものレコードができてしまうと、スキーマを変更するのは非常に大きな苦痛になる可能性があるからです。しかし、柔軟にしすぎると（例えば、すべてを「value」というJSONカラムに入れたり、「keys」と「values」テーブルを使って任意のデータを追跡したりすると）、アプリケーションコードに大量の複雑さが持ち込まれ（そして、おそらく非常に厄介なパフォーマンス制約を招くことになり）ます。ここで線を引くのは判断の問題であり、具体的な状況によりますが、一般的に私はテーブルを人間が読めるようにすることを目指しています。データベーススキーマを見て、アプリケーションが何を、なぜ保存しているのか、おおよその見当がつくべきです。

テーブルが数行以上になることが予想される場合は、インデックスを設定すべきです。最も一般的なクエリに一致するようにインデックスを作成するようにしてください（例えば、`email`と`type`でクエリする場合は、それらの2つのフィールドを持つインデックスを作成します）。インデックスはネストされた辞書のように機能するため、カーディナリティが最も高いフィールドを最初に配置するようにしてください（そうしないと、各インデックス検索で、正しい`email`を持つものを見つけるために`type`のすべてのユーザーをスキャンする必要があります）。考えられるすべてのものにインデックスを付けるのはやめましょう。各インデックスは書き込みのオーバーヘッドを追加します。

#### ボトルネック

高トラフィックのアプリケーションでは、データベースへのアクセスがボトルネックになることがよくあります。これは、計算側が比較的非効率な場合（例えば、Unicornのようなプレフォークサーバーで動作するRuby on Rails）でも当てはまります。なぜなら、複雑なアプリケーションは、リクエストごとに何百ものデータベース呼び出しを、しばしば連続して行う必要があるからです（ユーザーが虐待的でないことを確認した後でなければ、組織の一員であるかどうかを確認する必要があるかわからない、など）。ボトルネックを避けるにはどうすればよいでしょうか？

データベースをクエリするときは、*データベースにクエリしてください*。自分で処理するよりも、データベースに仕事をさせる方がほとんどの場合効率的です。例えば、複数のテーブルからデータが必要な場合は、別々のクエリを作成してメモリ内で結合するのではなく、`JOIN`を使用します。特にORMを使用している場合は、内部ループで誤ってクエリを作成しないように注意してください。これは、`select id, name from table`を`select id from table`と100回の`select name from table where id = ?`に簡単に変えてしまう方法です。

時々、クエリを分割したくなることがあります。頻繁には起こりませんが、あまりにも厄介なクエリに遭遇し、単一のクエリとして実行しようとするよりも、分割する方がデータベースにとって簡単だったことがあります。データベースがより良く処理できるようにインデックスやヒントを構築することは常に可能だと確信していますが、時折の戦術的なクエリ分割は、ツールボックスに入れておく価値のあるツールです。

できるだけ多くの読み取りクエリをデータベースレプリカに送信してください。典型的なデータベース設定では、1つの書き込みノードと多数の読み取りレプリカがあります。書き込みノードからの読み取りを避けるほど良いです。その書き込みノードは、すべての書き込みを行うのにすでに十分に忙しいのです。例外は、レプリケーションラグをまったく許容できない場合です（読み取りレプリカは常に書き込みノードより少なくとも数ミリ秒遅れて動作しているため）。しかし、ほとんどの場合、レプリケーションラグは簡単なトリックで回避できます。例えば、レコードを更新した後すぐにそれを使用する必要がある場合、書き込み後にすぐに再読み取りするのではなく、更新された詳細をメモリ内で埋めることができます。

クエリ（特に書き込みクエリ、そして*特に*トランザクション）の急増に注意してください。データベースが過負荷になると、遅くなり、さらに過負荷になります。トランザクションと書き込みは、クエリごとに多くのデータベース作業を必要とするため、データベースを過負荷にしやすいです。大量のクエリスパイクを生成する可能性のあるサービス（例えば、何らかの一括インポートAPI）を設計している場合は、クエリをスロットリングすることを検討してください。

### 遅い操作、速い操作

サービスは、いくつかのことを速く行わなければなりません。ユーザーが何か（例えば、APIやWebページ）と対話している場合、数百ミリ秒以内に応答が見えるべきです。しかし、サービスは遅い他のことも行わなければなりません。一部の操作は単に時間がかかります（例えば、非常に大きなPDFをHTMLに変換するなど）。これに対する一般的なパターンは、**ユーザーにとって有用なことを行うために必要な最小限の作業**を分離し、残りの作業をバックグラウンドで行うことです。PDFからHTMLへの変換の例では、最初のページをすぐにHTMLにレンダリングし、残りをバックグラウンドジョブでキューに入れるかもしれません。

バックグラウンドジョブとは何でしょうか？これに詳細に答える価値があります。なぜなら、「バックグラウンドジョブ」はシステム設計の核となるプリミティブだからです。すべてのテクノロジー企業には、バックグラウンドジョブを実行するための何らかのシステムがあります。主に2つのコンポーネントがあります。Redisなどにあるキューのコレクションと、キューからアイテムを取得して実行するジョブランナーサービスです。`{job_name, params}`のようなアイテムをキューに入れることで、バックグラウンドジョブをエンキューします。また、バックグラウンドジョブを特定の時間に実行するようにスケジュールすることも可能です（これは定期的なクリーンアップやサマリーのロールアップに役立ちます）。バックグラウンドジョブは、通常、非常によく踏まれた道であるため、遅い操作に対する最初の選択肢であるべきです。

時には、独自のキューシステムを構築したくなることがあります。例えば、1ヶ月後に実行するジョブをエンキューしたい場合、おそらくRedisのキューにアイテムを入れるべきではありません。Redisの永続性は通常、その期間にわたって保証されていません（保証されていたとしても、遠い未来にエンキューされたジョブを、Redisのジョブキューでは難しい方法でクエリしたいと思うでしょう）。この場合、私は通常、各パラメータの列と`scheduled_at`列を持つ保留中の操作用のデータベーステーブルを作成します。そして、`scheduled_at <= today`のアイテムをチェックするために日次のジョブを使用し、ジョブが終了したらそれらを削除するか、完了としてマークします。

### キャッシング

操作が遅いのは、ユーザー間で同じ高価な（つまり遅い）タスクを実行する必要があるためであることがあります。例えば、請求サービスでユーザーに請求する金額を計算している場合、現在の価格を調べるためにAPI呼び出しを行う必要があるかもしれません。ユーザーに使用量ごと（OpenAIがトークンごとに行うように）に請求している場合、それは(a)許容できないほど遅く、(b)価格を提供するサービスに多くのトラフィックを引き起こす可能性があります。ここでの古典的な解決策は**キャッシング**です。5分ごとに価格を調べ、その間は値を保存するのです。インメモリでキャッシュするのが最も簡単ですが、RedisやMemcachedのような高速な外部キーバリューストアを使用することも一般的です（これにより、多数のアプリケーションサーバー間で1つのキャッシュを共有できるため）。

典型的なパターンは、ジュニアエンジニアがキャッシングについて学び、*すべて*をキャッシュしたくなるのに対し、シニアエンジニアはできるだけ少なくキャッシュしたいと考えることです。なぜでしょうか？それは、私が最初にした、ステートフル性の危険性についての指摘に帰着します。キャッシュは状態の源です。奇妙なデータが入ったり、真実と同期が取れなくなったり、古いデータを提供して謎のバグを引き起こしたりすることがあります。何かをキャッシュする前には、まずそれを高速化するための真剣な努力をすべきです。例えば、データベースインデックスでカバーされていない高価なSQLクエリをキャッシュするのは馬鹿げています。データベースインデックスを追加すればよいのです！

私はキャッシングを多用します。ツールボックスに入れておくと便利なキャッシングのトリックの1つは、スケジュールされたジョブとS3やAzure Blob Storageのようなドキュメントストレージを大規模な永続キャッシュとして使用することです。*本当に*高価な操作（例えば、大口顧客の週次利用レポート）の結果をキャッシュする必要がある場合、その結果はRedisやMemcachedには収まらないかもしれません。代わりに、結果のタイムスタンプ付きBLOBをドキュメントストレージに入れ、そこから直接ファイルを提供します。上で述べたデータベースバックの長期キューのように、これは特定のキャッシュ技術を使わずにキャッシングの*アイデア*を使用する例です。

### イベント

何らかのキャッシングインフラストラクチャやバックグラウンドジョブシステムと同様に、テクノロジー企業は通常、*イベントハブ*を持っています。これの最も一般的な実装はKafkaです。イベントハブは単なるキューです。バックグラウンドジョブ用のものと同様ですが、「このジョブをこれらのパラメータで実行せよ」とキューに入れる代わりに、「このことが起こった」とキューに入れます。古典的な例は、新しいアカウントごとに「新しいアカウントが作成された」イベントを発行し、その後、複数のサービスがそのイベントを消費して何らかのアクションを起こすことです。「ウェルカムメールを送信する」サービス、「不正利用をスキャンする」サービス、「アカウントごとのインフラストラクチャを設定する」サービスなどです。

イベントを使いすぎるべきではありません。多くの場合、あるサービスが別のサービスにAPIリクエストを行う方が良いです。すべてのログが同じ場所にあり、推論しやすく、他のサービスが何で応答したかをすぐに見ることができます。イベントは、イベントを送信するコードがコンシューマがイベントで何をするかを必ずしも気にしていない場合や、イベントが大量で特に時間的制約がない場合（例えば、新しいTwitterの投稿ごとの不正利用スキャン）に適しています。

### プッシュとプル

データがある場所から他の多くの場所に流れる必要がある場合、2つの選択肢があります。最も簡単なのは*プル*です。これはほとんどのWebサイトの仕組みです。データを持つサーバーがあり、ユーザーがそれを欲しがるとき、彼らは（ブラウザを介して）サーバーにリクエストを行い、そのデータを自分たちに引き下げます。ここでの問題は、ユーザーが同じデータを何度も引き下げる可能性があることです。例えば、新しいメールがあるかどうかを確認するためにメールの受信トレイを更新すると、メールに関するデータだけでなく、Webアプリケーション全体が引き下げられ、リロードされます。

代替案は*プッシュ*です。ユーザーにデータを要求させるのではなく、クライアントとして登録させ、データが変更されたときにサーバーが各クライアントにデータをプッシュダウンします。これがGMailの仕組みです。新しいメールが届いたときにページを更新する必要はありません。なぜなら、それらは到着したときに現れるからです。

Webブラウザを持つユーザーではなく、バックグラウンドサービスについて話している場合、プッシュが良い考えである理由は簡単にわかります。非常に大規模なシステムでも、同じデータを必要とするサービスはせいぜい100程度かもしれません。あまり変更されないデータについては、データが変更されるたびに100回のHTTPリクエスト（またはRPCなど）を行う方が、同じデータを毎秒1000回提供するよりもはるかに簡単です。

仮に、100万のクライアントに最新のデータを提供する必要があるとします（GMailのように）。これらのクライアントはプッシュすべきか、プルすべきか？それは状況によります。どちらにしても、単一のサーバーからすべてを実行することはできないので、システムの他のコンポーネントに委託する必要があります。プッシュしている場合、それはおそらく各プッシュをイベントキューに入れ、多数のイベントプロセッサがそれぞれキューからプルしてプッシュを送信することを意味します。プルしている場合、それはメインアプリケーションの前に座ってすべての読み取りトラフィックを処理する、多数の（例えば100個の）高速な読み取りレプリカキャッシュサーバーを立ち上げることを意味します。

### ホットパス

システムを設計するとき、ユーザーがそれと対話したり、データがそれを通って流れたりするには、さまざまな方法があります。少し圧倒されることがあります。コツは、主に「ホットパス」に焦点を当てることです。システムの最も重要な部分と、最も多くのデータを処理する部分です。例えば、従量制課金システムでは、それらの部分は、顧客が課金されるかどうかを決定する部分と、プラットフォーム上のすべてのユーザーアクションにフックしてどれだけ課金するかを特定する必要がある部分かもしれません。

ホットパスは重要です。なぜなら、他の設計領域よりも可能な解決策が少ないからです。課金設定ページを構築する方法は千通りあり、それらはすべて大体機能します。しかし、ユーザーアクションのファイアホースを賢明に消費する方法はほんの一握りしかないかもしれません。ホットパスはまた、より壮大に失敗します。設定ページを本当に台無しにして製品全体をダウンさせることはできますが、すべてのユーザーアクションでトリガーされるコードを書けば、簡単に大きな問題を引き起こす可能性があります。

### ロギングとメトリクス

問題があるかどうかをどうやって知るのでしょうか？最も用心深い同僚から学んだことの1つは、不都合なパスの間に積極的にログを記録することです。ユーザー向けのエンンドポイントが422を応答すべきかどうかをチェックするために、一連の条件をチェックする関数を書いているなら、満たされた条件をログに出力すべきです。課金コードを書いているなら、下されたすべての決定をログに記録すべきです（例えば、「Xのためにこのイベントには課金していません」）。多くのエンジニアは、これを行うと大量のロギングのボイラープレートが追加され、美しくエレガントなコードを書くのが難しくなるため、これを行いませんが、とにかく行うべきです。重要な顧客が422エラーを受け取っていると不平を言っているときに、そうしておいてよかったと思うでしょう。たとえその顧客が何か間違ったことをしたとしても、彼らのために*彼らが何をしたか*を突き止める必要があります。

また、システムの運用部分について基本的な可観測性を持つべきです。つまり、ホストやコンテナのCPU/メモリ、キューのサイズ、リクエストごとまたはジョブごとの平均時間などです。リクエストごとの時間のようなユーザー向けのメトリクスについては、p95とp99（つまり、最も遅いリクエストがどれだけ遅いか）も監視する必要があります。1つか2つの非常に遅いリクエストでさえ恐ろしいです。なぜなら、それらは不釣り合いに最大かつ最も重要なユーザーからのものだからです。平均だけを見ていると、一部のユーザーがあなたのサービスを使えないと感じていることを見逃しがちです。

### キルスイッチ、リトライ、そして優雅な失敗

私はキルスイッチについて[記事全体](https://www.seangoedecke.com/killswitches)を書いたので、ここでは繰り返しませんが、要点は、システムがひどく失敗したときに何が起こるかについて慎重に考えるべきだということです。

リトライは魔法の弾丸ではありません。失敗したリクエストを盲目的にリトライすることで、他のサービスに余分な負荷をかけていないことを確認する必要があります。可能であれば、大量のAPI呼び出しを「サーキットブレーカー」内に入れてください。連続して5xx応答が多すぎる場合は、サービスが回復するまでしばらくリクエストの送信を停止します。また、成功したかもしれないし、しなかったかもしれない書き込みイベントをリトライしていないことを確認する必要があります（例えば、「このユーザーに請求する」リクエストを送信して5xxが返ってきた場合、ユーザーが請求されたかどうかは*わかりません*）。これに対する古典的な解決策は、「冪等性キー」を使用することです。これはリクエスト内の特別なUUIDで、他のサービスが古いリクエストを再実行するのを避けるために使用します。何かを行うたびに冪等性キーを保存し、同じキーを持つ別のリクエストを受け取った場合は、黙ってそれを無視します。

システムのどこかが故障したときに何が起こるかを決めることも重要です。例えば、ユーザーが現在のウィンドウでリクエストを出しすぎていないか確認するためにRedisバケットをチェックするレート制限コードがあるとします。そのRedisバケットが利用できない場合、何が起こるでしょうか？2つの選択肢があります。*フェイルオープン*してリクエストを通すか、*フェイルクローズ*してリクエストを429でブロックするかです。

フェイルオープンすべきかクローズすべきかは、特定の機能によって異なります。私の見解では、レート制限システムはほとんど常にフェイルオープンすべきです。つまり、レート制限コードの問題が必ずしも大きなユーザー向けのインシデントになるわけではないということです。しかし、認証は（明らかに）常にフェイルクローズすべきです。ユーザーに自分のデータへのアクセスを拒否する方が、他のユーザーのデータへのアクセスを許可するよりも良いです。正しい振る舞いが明確でないケースも多くあります。それはしばしば難しいトレードオフです。

### 最後の考察

ここでは意図的に触れていないトピックがいくつかあります。例えば、モノリスをいつ、どのように異なるサービスに分割するか、コンテナとVMのどちらを使うか、トレース、良いAPI設計などです。これは一部には、それほど重要ではないと考えているため（私の経験では、モノリスで問題ありません）、または、話すにはあまりにも明白すぎると考えているため（トレースは使うべきです）、または、単に時間がないためです（API設計は複雑です）。

私が伝えようとしている主なポイントは、この記事の冒頭で述べたことです。優れたシステム設計は、賢いトリックについてではなく、退屈で十分にテストされたコンポーネントを適切な場所で使う方法を知っていることです。私は配管工ではありませんが、優れた配管も似たようなものだと想像します。あまりにもエキサイティングなことをしていると、おそらく自分自身が汚物まみれになるでしょう。

特に、これらのコンポーネントがすでに既製品として存在する大手テクノロジー企業では（つまり、あなたの会社にはすでに何らかのイベントバス、キャッシングサービスなどがあります）、優れたシステム設計は何も見えないように見えます。カンファレンスで話せるようなシステム設計をしたいと思う分野は、非常に非常に少ないです。それらは存在します！手作りのデータ構造が、そうでなければ不可能だった機能を可能にするのを見てきました。しかし、それは10年間で1、2回しか見たことがありません。退屈なシステム設計は毎日見ています。

編集：この記事は[Hacker News](https://news.ycombinator.com/item?id=44921137)で多くの良いコメントと共に議論されました。「なぜ『自分の書き込みを読むな』なんて言うんだ、誰がそんなことをするんだ」というコメントのすぐ隣に、「うーん、自分の書き込みを読まないのは面倒くさそうだ」というコメントがあって面白かったです。

---

もしこの記事が気に入ったら、新しい投稿に関するメール更新を[購読](https://buttondown.com/seangoedecke)するか、[Hacker Newsで共有](https://news.ycombinator.com/submitlink?u=https://www.seangoedecke.com/good-system-design/&t=Everything%20I%20know%20about%20good%20system%20design)することを検討してください。

2025年6月21日 │ タグ: ,

---





