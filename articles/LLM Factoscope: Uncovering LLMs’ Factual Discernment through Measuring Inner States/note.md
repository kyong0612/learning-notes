# LLM Factoscope: Uncovering LLMs' Factual Discernment through Measuring Inner States

ref: <https://arxiv.org/html/2312.16374v3>

## LLM Factoscope: 大規模言語モデルの内部状態測定による事実識別能力の解明

**参照:** <https://arxiv.org/html/2312.16374v3>

### 概要

大規模言語モデル（LLM）は広範な知識と創造力で様々な分野に革命をもたらしましたが、事実と異なる出力を生成する傾向（ハルシネーション）が重大な問題となっています。特に医療相談や法律助言など、正確性が最重要視される分野では懸念事項です。

本研究では、人間の嘘発見器が生理的反応を利用する点に着想を得て、LLMの内部状態を活用して事実検出を行う柔軟かつ拡張可能なパイプライン「LLM Factoscope」を提案します。LLMが事実に基づくコンテンツとそうでないコンテンツを生成する際に、内部状態に識別可能なパターンが存在することを発見しました。LLM Factoscopeは、独自に収集した事実検出データセットにおいて、様々なアーキテクチャで96%以上の精度を達成しました。この研究は、LLMの内部状態を利用した事実検出の新たな道を開き、信頼性と透明性を向上させるためのLLM内部動作のさらなる探求を促進します。

### 1. はじめに

* LLMは多大な能力を持つ一方で、「ハルシネーション」（事実と異なる出力）の問題を抱えています。
* 医療、法律、教育などの分野では、事実に基づかない出力は深刻な結果を招く可能性があります。
* 従来の事実検出は外部データベースとの照合に依存しますが、これは複雑さと依存性を増大させます。
* 本研究は、外部リソースに頼らず、LLMの内部状態のみを利用して事実検出が可能かを探求します。
* 人間の嘘発見器と同様に、LLMも知識や信念と矛盾する発言をする際に、内部状態に変化が現れるのではないかと仮定します。
* LLMの「生理的」指標として、活性化マップ（静的特徴）と、中間層の出力（最終出力ランク、トップk出力インデックス、トップk出力確率）（動的特徴）を分析します。
* これらの特徴と出力の事実性の複雑な関係性を解明するため、データ駆動型アプローチを採用し、LLM Factoscopeパイプラインを設計しました。

### 2. 関連研究

* **Logit Lens:** 中間層をデコードしてモデルの意思決定プロセスを理解し、有害な出力を修正する手法。本研究でも中間層の出力インデックスと確率の変化を捉えるために利用します。
* **LLM Factual Detection:** LLM出力の事実確認は重要性を増しています。既存手法は訓練データの検査や外部データベース参照に依存し、コストが高いです。入力の事実性検出手法（SPALMA, Marks et al.）や、内部状態操作による出力事実性向上（ITI）、活性化値や自己ラベル付け（CCS）、繰り返しサンプリングによる不確実性分析（Semantic uncertainty, SelfCheckGPT, INSIDE）などがありますが、計算コストや信頼性に課題があります。LLM Factoscopeは、多様な内部状態を活用し、より実用的で高精度、高汎化性を目指します。

### 3. 観測

* **静的観点（活性化マップ）:**
  * 事実情報を出力する際、事実関連ニューロン（事実出力時に最も活性化する頻度が高い上位1%のニューロン）がより強く活性化する傾向が見られました（図1a）。
  * 非事実情報出力時は、これらのニューロンの活性化は弱まります（図1b）。
  * これは、訓練データ中の事実情報によって関連する接続が強化された結果と考えられます。
  * 活性化マップが事実性評価の指標となり得ることを示唆します。
* **動的観点（中間層の出力）:**
  * **最終出力ランク:** 事実出力の場合、最終的な出力トークンのランク（確率順位）は後方層（例: GPT2-XLの22層以降）で安定して上昇し、モデルの確信度が高まることを示します（図2）。一方、非事実出力ではランクが不安定に変動し、モデルの不確実性を反映します。
  * **トップk出力インデックスと確率:** 事実応答では、モデルは一貫して同じ単語を最高確率の出力として優先します（図3a）。非事実応答では、最後の方の層で最高確率の単語が変動し、確信度の欠如を示します（図3b）。また、隣接する層間のトップ1出力のセマンティック類似性は、事実出力の方が非事実出力よりも高いです。
  * これらの動的な変化も事実検出の指標となり得ます。

### 4. LLM Factoscope

* **概要 (図4):**
  * LLMの内部状態を利用して事実検出を行うパイプラインです。
  * 事実データ収集 → 内部状態収集 → 内部状態前処理 → LLM Factoscopeモデル設計 のステップで構成されます。
  * データセットの拡張が容易です。
  * 単語レベルの事実検出データセットをKaggleから構造化データを抽出して開発しました。
  * モデルはSiameseネットワークに基づいており、類似クラスのデータ間の埋め込み距離を最小化し、異なるクラスのペア間の距離を最大化します。
  * 実用例 (図5): ユーザーがLLMの出力の事実性を検証できます。例えば、「シャイニングの監督はスタンリー・キューブリックで、1980年公開」という応答は事実としてマークされ、「ビーンキーパーの監督は映画業界に長くいる男性」という応答は非事実としてマークされます。
* **事実データ収集 (表1):**
  * KaggleからCSV形式の事実関連データセット（アート、スポーツ、文学、地理、歴史、科学、経済など）を収集。
  * 関係性（例: 作品-作者、映画-監督）ごとに複数の同義の質問テンプレートを作成し、多様性を確保。
  * 合計247,246データポイント。
* **内部状態収集:**
  * プロンプトをLLMに入力し、応答とプロンプトの最後のトークンに関連する内部状態を収集します。
  * 収集する内部状態:
    * **活性化マップ:** LLMの全層にわたる活性化値。入力に関連する知識の内部表現。
    * **最終出力ランク:** 各層で最終出力トークンが持つ確率分布上のランク。モデルの出力選好の進化を示す。
    * **トップk出力インデックスと確率:** 各層で最も確率の高い上位k個のトークンとその確率。モデルの確率的推論と処理の認知側面を反映。
  * モデルの次の単語出力が事実と一致するかどうかを評価し、ラベル（事実/非事実）を付与します。
* **内部状態前処理:**
  * **活性化マップの正規化:** データセットの平均と標準偏差を用いて正規化。
  * **最終出力ランクの変換:** 0-1の範囲に変換し、低いランク（高確率）を強調。
  * **トップk出力インデックスの距離計算:** 隣接層間のトークン埋め込みのコサイン類似度を計算し、セマンティックな連続性の進化を測定。
  * トップk出力確率は元々0-1の範囲にあるため、前処理は不要です。
* **LLM Factoscopeモデル設計:**
  * Few-shot learningとSiameseネットワークに着想を得ています。
  * 4つのサブモデル（活性化マップ、トップkインデックス、トップk確率にはResNet18ベースのCNN、最終出力ランクにはGRU）で構成され、各内部状態を処理して埋め込みベクトルを生成します。
  * これらの埋め込みを線形層で統合し、包括的な混合表現 (𝐄mixed) を生成します。
  * 訓練にはトリプレットマージンロスを使用し、同じクラスのインスタンス間の距離を最小化し、異なるクラスのインスタンス間の距離を最大化します。これにより、頑健な表現学習と高い汎化能力を実現します。
  * テスト時には、サポートセット（訓練未使用のサンプル）の埋め込みと比較し、最も近いサンプルのラベルをテストデータのラベルとして予測します。

### 5. 評価

* **実験設定:**
  * タスク: LLM Factoscopeモデルを訓練し、LLM出力の事実性を検出。入力はプロンプトの最後のトークンの内部状態、出力は次のトークンが事実かどうかの二値ラベル。
  * データセット: 7分野、247,246データポイント。事実・非事実データが均等になるようサンプリング。訓練:テスト=8:2。
  * モデル: GPT2-XL-1.5B, Llama2-7B/13B, Vicuna-7B/13B-v1.5, StableLM-7Bで評価。
  * ベースライン: 5つの既存手法（ホワイトボックス2種: 単一層活性化、SAPLMA、ブラックボックス3種: Calibration-Prob, Calibration-LLM Label, SelfCheckGPT）と比較。
* **有効性 (表2):**
  * LLM Factoscopeは、全てのLLMアーキテクチャで96.1%から98.3%の高い精度を一貫して達成。
  * ベースラインやSAPLMAは精度が78.5%から88.8%と変動。これは、LLMの規模が大きくなるにつれて、知識表現に関与する層が変化または複数になるため、単一層の情報のみに依存する方法では不安定になることを示唆します。
  * ブラックボックス手法は、アクセス可能な情報が限られるため、ホワイトボックス手法よりも効果が低かったです。
  * LLM Factoscopeの優位性は、複数の内部状態の変化を層横断的に考慮している点にあると考えられます。
* **汎化性能 (表3):**
  * Leave-one-outアプローチ（特定の関係データを除外して訓練し、除外したデータでテスト）で評価。
  * LLMごとに異なる関係に対する汎化能力に差が見られました（例: Llama2-7BはBook-Authorで高精度だが、Stablelm-7Bは低い）。
  * LLM Factoscopeはほとんどの場合でベースラインを上回りましたが、Stablelm-7Bでは下回るケースも。これはStablelm-7Bの事実/非事実コンテンツの学習効果や、層数の少なさがOODデータに対するセマンティック連続性の維持に影響した可能性が考えられます。
  * 活性化マップはデータタイプに敏感ですが、他の内部状態はデータタイプに依存しないため、これらを活用することが多様なドメインへの汎化能力向上に寄与します。
  * 最良の性能を得るためには、テストデータと訓練データの分布を一致させることが推奨されます。
* **アブレーションスタディ:**
  * **各サブモデルの貢献 (図6, 7):** サブモデルを追加するごとに、精度と汎化性能が一貫してわずかに向上しました。各サブモデルが独自の貢献をしていることを示します。
  * **トップkの影響 (図8):** kの値を変更するとパフォーマンスに影響があり、k=10で最高性能（95.4%）、k=4で最低性能（90.4%）でした（GPT2-XL）。
  * **サポートセットサイズの影響 (図9):** サポートセットのサイズ（50～250）は、モデル性能に大きな影響を与えませんでした（Llama2-7B）。
  * **サブモデルアーキテクチャの影響 (図10):** ResNet18を全結合層に、GRUをRNNに置き換えると、性能がわずかに低下しました。特にトップkインデックス処理のResNet18を全結合層に置き換えると、精度が73.6%まで大幅に低下し、ResNet18の重要性が示されました。

### 6. 結論

* LLMの事実検出に有効な内部状態を発見し、観測結果を提供しました。
* これらの内部状態を利用してLLM出力の事実性を検出するパイプライン「LLM Factoscope」を開発しました。
* LLM Factoscopeは、カスタムデータセットで96%を超える高い事実検出精度を一貫して示しました。
* この研究は、LLMの事実検出のための新しい手法を提供するだけでなく、LLMの内部状態に関する将来の研究の新たな道を開きます。
* モデルの理解と信頼性を向上させることで、重要なアプリケーションにおけるLLMのより透明で説明責任のある、信頼性の高い利用の基盤を築きます。

### 制限事項

* LLMの訓練コーパスが主に事実に基づいているという仮定に依存しますが、非事実コンテンツが含まれる可能性もあります。事実データが非事実データを上回る限り、パイプラインは有効です。
* カスタムデータセットは現実世界の知識の多様性と複雑さを完全には表現できていない可能性があります。より包括的なデータセットがあれば、パフォーマンスが向上する可能性があります。
* 汎化能力は示されていますが、訓練データと大きく異なるデータタイプには課題が生じる可能性があります。新しいデータでファインチューニングすることで、精度と適用範囲を広げることができます。
