---
title: "TypeScriptファーストなコーディングAIエージェントのベンチマーク「ts-bench」を公開しました"
source: "https://blog.lai.so/ts-bench/"
author:
  - "laiso"
published: "2025-09-05"
created: 2025-09-07
description: |
  AIコーディングエージェントのTypeScriptコード編集能力を評価するための、手軽に再現可能なベンチマークプロジェクト「ts-bench」を公開しました。この記事では、筆者がなぜ ts-bench を作ったのか、今後どうしていきたいかについてお話しします。
tags:
  - "TypeScript"
  - "AIエージェント"
  - "ベンチマーク"
  - "ts-bench"
  - "LLM"
---

## 概要

本稿では、AIコーディングエージェントのTypeScriptコード編集能力を手軽に評価できる、再現可能なベンチマークプロジェクト「**ts-bench**」について解説します。開発の背景、仕組み、そして今後の展望について述べます。

[![](https://blog.lai.so/content/images/thumbnail/ts-bench)](https://github.com/laiso/ts-bench/?ref=blog.lai.so)

## ts-benchの仕組み

`ts-bench`は、プログラミング学習プラットフォーム[Exercism](https://exercism.org/?ref=blog.lai.so)のTypeScript問題セットを利用しています。各問題には仕様書、ソースコードのひな形、テストコードが含まれています。

ベンチマークは以下のステップで実行されます。

1. **AIエージェントの実行**: 指示書をプロンプトとしてエージェントに渡し、ソースコードを編集させます。
2. **テストファイルの復元**: エージェントによる意図しないテストコードの変更を防ぐため、テストファイルを元の状態に戻します。
3. **テストの実行と評価**: `yarn test` を実行し、全テストが通れば「成功」と判定します。

このプロセスは、エージェントが複数回の試行錯誤（コード編集とテストの反復）を行うことを許容しており、一度の回答で正解を目指す`pass@1`のような単純な指標よりも、実用的な開発プロセスに近い能力を測定します。結果はGitHub Actions上で確認でき、失敗原因の分析が可能です。

![](https://blog.lai.so/content/images/2025/09/image.png)

## なぜTypeScriptなのか？

多くの既存ベンチマークがPythonに焦点を当てる中、`ts-bench`はTypeScriptを採用しています。これは、実際の開発現場、特にモダンなWeb開発においてTypeScriptが広く使われているためです。

AIエージェントは、ビルドエラーやテスト失敗の解決に苦労することが多く、型チェッカーやビルドツールといった厳格なフィードバックシステムへの対応能力が問われます。`ts-bench`は、静的型付けがもたらす課題をエージェントがどう解決するかを観察することで、コード生成能力以上に**フィードバックループを正確に回す能力**という、より実践的な開発能力を測定することを目指しています。

![](https://blog.lai.so/content/images/2025/09/image-2.png)

## ts-benchを開発した理由

`ts-bench`は、AIコーディングエージェントの性能を客観的かつ効率的に評価するために、以下の4つの課題解決を目的として開発されました。

#### 1. コーディングエージェントの効率的な評価と足切り

基本的なコーディング能力を持たないエージェントを効率的に見極めるための基準として利用できます。例えば、「Claude CodeとDeepSeek V3.1モデル」の組み合わせが低いスコア（正解率32.0%）を記録するなど、特定の組み合わせにおける性能課題を明らかにしました。

#### 2. エージェントとモデルの多様な組み合わせパターンの検証

LLM単体ではなく、プロンプト戦略やファイル操作ロジックを含む「エージェント層」全体を評価します。これにより、例えば`opencode`エージェントが様々なモデルと組み合わされた際のパフォーマンスを比較できます。

![](https://blog.lai.so/content/images/2025/09/image-1.png)

#### 3. 特定バージョンにおける問題の再現と実証

エージェントはバージョンやプロンプトの変更で性能が変動します。`ts-bench`を使えば、特定条件下でのスコアの変化を追跡・実証できます。実際に、Claude Codeのバージョンアップに伴う性能変化と、プロンプト修正による回復が確認されています。

- **v1.0.98**: Success Rate 64%
- **v1.0.24**: Success Rate 80%に改善
- **v1.0.102**: プロンプト修正でv1.0.24同等まで回復

#### 4. 自作エージェントの評価基盤

開発者が独自に作成したエージェントの性能を客観的に評価し、改善点を見つけるための基盤として活用できます。

## 公開の影響とコミュニティからの反響

`ts-bench`はDockerとGitHub Actionsにより高い再現性を実現しており、公開後すぐにコミュニティで活用され始めました。特に、`GPT-OSS`のようなローカルLLMの性能評価に利用されるなど、手軽さが評価されています。

## ts-benchのこれから（課題と展望）

### 課題

1. **難易度の低さ**: 現在のデータセットは、フロンティアモデルにとっては簡単すぎる可能性があります。
2. **コスト**: 大量のAPI呼び出しを伴うベンチマークは実行コストが高いという現実的な問題があります。

### 展望

今後は、トップラインの性能を測定するため、より挑戦的なタスク（例: [SWE-Lancer](https://arxiv.org/abs/2502.12115?ref=blog.lai.so)のような大規模リポジトリ編集タスク）を組み込むことを検討しています。コスト問題については、スポンサーを募るなど、プロジェクトを拡張する方法を模索しています。

[![](https://blog.lai.so/content/images/thumbnail/my-github-icon-2024-2-17.png)](https://blog.lai.so/sponsors-2025/)

## おわりに

`ts-bench`は、AIコーディングエージェントの進化を客観的な指標で後押しするプロジェクトです。GitHubリポジトリへのフィードバックやコントリビューションを歓迎します。

[![](https://blog.lai.so/content/images/thumbnail/ts-bench-1)](https://github.com/laiso/ts-bench?ref=blog.lai.so)
