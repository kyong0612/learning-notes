# Cursor / Clineを使う上でもっとも重要なことの一つ: コンテキストウインドウについて

ref: <https://zenn.dev/tesla/articles/ade9883b2f62c9>

## 主要な問題点

Cursor/Clineを適切に使用しないと、以下のような問題が発生します：

1. 「Lost in Middle」現象により指示が通らなくなる
2. パフォーマンス低下に対し無秩序にルールを追加
3. 早い段階でタスクのコンテキストウィンドウをはみ出す
4. Cursor/Clineがループしたり性能が落ちる
5. 結果として現状のAIの性能に幻滅し使用をやめてしまう

![AIパフォーマンス低下の図](https://storage.googleapis.com/zenn-user-upload/da941ecc097a-20250324.png)

## コンテキストウィンドウとは

コンテキストウィンドウとは、モデルが一度に処理できるトークン数のことです：

- トークンは単語、画像、動画の一部分など、モデルが扱う最小単位
- 英語の場合：100トークン ≈ 75ワード
- 日本語の場合：100トークン ≈ 100文字
- Claude 3.7 Sonnetの場合は最大200Kトークンまで処理可能

## コンテキストウィンドウの限界

LLMのコンテキストウィンドウが限界に近づくと発生する問題：

### 1. 情報保持の非一貫性

- 先行するコンテキストで確立された規則や修正が、後続の応答で維持されない
- セッションが長くなるほど情報の断片化が進行
- 「Lost in the Middle」現象（中間部分での情報喪失）

**弊害**：反復的修正サイクル

- 同じ問題を何度も修正させる必要がある
- 例：エラーハンドリングを共通化するよう修正したのに、次の機能追加で元の実装パターンに戻る

### 2. 推論能力の低下

- 複数ステップの推論タスクでの成功率が著しく低下
- 論理的一貫性の欠如や循環論法などの症状

**弊害**：

- **循環論法と繰り返し**：同じ思考パターンを繰り返す（「Cline ループ」や「Cursor ループ」）
- **セマンティック干渉**：類似する概念間での混同、新しい情報が入力されると古い情報が歪曲または置換される

## Rulesの再定義

### 従来の誤解

- 「業界標準のベストプラクティスを網羅すべき？」
- 「記述される問題をすべて解決できる？」
- 「詳細であればあるほど良い？」

### コンテキスト圧縮としてのRules

LLMの限界を踏まえると、Rulesの役割は「コンテキストの効率的な圧縮」：

1. **情報密度の最適化**：本質的なパターンを抽象化して伝える
2. **作業記憶の温存**：限られた「思考能力」を保護し、実際の課題に集中
3. **プロジェクト固有の知識伝達**：ディレクトリ構造、命名規則などの最小限情報を効率的に伝達

## Rulesを逐次追加する場合の悪循環

![ルール追加の悪循環図](https://storage.googleapis.com/zenn-user-upload/4c627e7a5b82-20250324.png)

### フェーズ1: 初期の改善と誤った希望

- 基本的なルールで明確な改善
- 「ルールを追加すれば改善する」という誤った信念強化
- より多くのルールへの期待

### フェーズ2: 期待と現実のギャップ

- ルール追加でも期待した改善が見られない
- 「ルールが不十分」または「不明確」と誤診断
- さらに詳細なルールや例外ルールの追加

### フェーズ3: 逆効果のエスカレーション

- コンテキストウィンドウ超過によるパフォーマンス低下
- 中間ルールの無視と同じミスの繰り返し
- 「さらなるルール」による修正の悪循環

### コンテキスト崩壊

- パラドキシカルな性能低下：基本タスクも遂行不能
- 一貫性のない適用：最初と最後のルールは遵守されるが中間ルールは無視
- 自己矛盾する実装：同じファイル内で矛盾するコーディングパターンが混在
- 思考能力の完全な低下：循環論法や思考の繰り返し

## 効果的な戦略：LLMの制約を踏まえたアプローチ

### 1. タスク設計の最適化

- **セッションごとにタスクを完結させる**：独立した作業単位として処理
- **タスクを細かく切る**：小さな独立したタスクに分割
- **計画を明確にする**：明確な計画と期待成果を設定

Devinの開発チームもこの点を認識し、ルールに記載しています。コンテキストウィンドウの問題から、DevinでもClineもCursorも基本的には同じアプローチが必要です。

### 2. 効率的なRulesの設計

- **最小限の必要情報に集中**：本質的な情報のみを含める
- **抽象度と具体性のバランス**：適切な粒度の情報提供
- **手続きとナレッジの区別**：「何を作るか」の情報を優先

Devinでは、「一般的なバグとその関連ソリューション、コード準拠のプラクティス、デプロイメント ワークフロー、テスト ワークフロー、独自のツールの操作方法」など具体的なものを推奨しています。Cursorもファイルパターンマッチングなどを駆使して効率よくルールを制御するシステムがあります。

### 3. 現実的な期待値設定

- **LLMの限界を認識**：完璧な結果を期待せず、検証の重要性を理解
- **ツールとしての適切な使い方**：「万能の開発者」ではなく「制約のある強力なツール」として位置づけ

## まとめ

LLMコーディングエージェントのRulesは「良いプラクティス集」ではなく、「コンテキスト圧縮のための効率的情報伝達ツール」として捉え直す必要があります。最も効果的なアプローチは：

1. 「セッションごとにタスクを行う」
2. 「タスクを細かく切る」
3. 「計画を明確にする」
4. 「最小限の必要情報に集中した」Rulesを作成する

この技術はまだ黎明期ですが、LLMの根本的な制約を理解した上で現実的な期待値を設定し、適切な戦略を採用することで、その潜在能力を最大限に引き出すことができます。

## 参考文献

- [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)
- [コンテキストウインドウについて（By DeepResearch）](https://note.com/delta_ipsilon/n/nbcbe266da163)
- [大規模言語モデルにおける長文コンテキスト外入力への対処に関する研究動向](https://note.com/delta_ipsilon/n/n3e0ccf32ac77)
- [When to Use Devin - Devin Docs](https://docs.devin.ai/essential-guidelines/when-to-use-devin)
- [Cursor – Rules for AI](https://docs.cursor.com/context/rules-for-ai)
