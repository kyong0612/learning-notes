# Introducing AutoRAG: fully managed Retrieval-Augmented Generation on Cloudflare

ref: <https://blog.cloudflare.com/introducing-autorag-on-cloudflare/>

## 要約

### 概要

Cloudflareは**AutoRAG**をオープンベータ版として発表しました。これは完全に管理されたRetrievalAugmented Generation（RAG）パイプラインで、開発者がコンテキスト対応AIをアプリケーションに統合する方法を簡素化するように設計されています。RAGは、独自のデータから情報を取得し、それを大規模言語モデル（LLM）に提供することで、AIレスポンスの精度を向上させる方法です。

![AutoRAGの概要図](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2SZ1fpLEMXLfjidRspvQ3p/35aaef41cf7231cf349019d54143c00e/Feature_Image.png)

従来のRAGパイプラインの構築は複雑で、複数のツールやサービス（データストレージ、ベクトルデータベース、埋め込みモデル、LLM、カスタムインデックス作成など）を組み合わせる必要がありました。AutoRAGはこの複雑さを解消し、わずか数クリックでデータの取り込みから高品質な回答の生成まで、完全に管理されたRAGパイプラインを提供します。

### RAGを使用する理由

LLM（MetaのLlama 3.3など）は強力ですが、トレーニングされた内容のみを知っています。新しい、専有の、またはドメイン固有の情報についての質問に対して正確な回答を生成することが難しい場合があります。システムプロンプトで関連情報を提供することはできますが、入力サイズが肥大化し、コンテキストウィンドウによって制限されます。モデルの微調整は高価で、最新の状態を維持するために継続的な再トレーニングが必要です。

![RAGの仕組み](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5zrM30iI2E1ZlmTQvAsx0D/fcef1f00b048a147fc3bc459895cc19c/1.png)

RAGはこれを解決するために、クエリ時にデータソースから関連情報を取得し、ユーザーの入力クエリと組み合わせ、両方をLLMに供給して、データに基づいた応答を生成します。これにより、AIサポートボット、内部知識アシスタント、ドキュメントのセマンティック検索など、真実の源が常に進化するユースケースに適しています。

### AutoRAGの仕組み

AutoRAGはCloudflareの開発者プラットフォームのビルディングブロックを使用して、RAGパイプラインを設定します。開発者がWorkers AI、Vectorize、AI Gatewayを使用してRAGシステムを作成するコードを書く代わりに、AutoRAGインスタンスを作成してR2ストレージバケットなどのデータソースを指定するだけです。

AutoRAGは2つのプロセスによって動作しています：**インデックス作成**と**クエリ**です。

#### インデックス作成プロセス

データソースを接続すると、AutoRAGは自動的にそれを取り込み、変換し、ベクトルとして保存して、クエリ時のセマンティック検索に最適化します：

![インデックス作成プロセス](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5UK62iIO747BOe7JgazkBP/19a65b75cc4ad6b7fba31bff301cc133/Indexing.png)

1. **データソースからのファイル取り込み：** AutoRAGはデータソースから直接読み取ります。現在、CloudflareのR2との統合をサポートしており、PDFや画像、テキスト、HTML、CSVなどのドキュメントを処理用に保存できます。
2. **Markdownへの変換：** AutoRAGはWorkers AIのMarkdown変換を使用して、すべてのファイルを構造化されたMarkdownに変換します。これにより、多様なファイルタイプ間の一貫性を確保します。画像の場合、Workers AIを使用してオブジェクト検出を実行し、視覚から言語への変換を行い、画像をMarkdownテキストに変換します。
3. **チャンキング：** 抽出されたテキストは、検索の精度を向上させるために小さな部分に分割されます。
4. **埋め込み：** 各チャンクはWorkers AIの埋め込みモデルを使用して、コンテンツをベクトルに変換します。
5. **ベクトル保存：** 結果のベクトルは、ソースの場所やファイル名などのメタデータとともに、アカウントに作成されたCloudflareのVectorizeデータベースに保存されます。

#### クエリプロセス

エンドユーザーがリクエストを行うと、AutoRAGは以下を実行します：

![クエリプロセス](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7ueRtSqcc6BcQL27SyFMzi/30712fdf3a50115f9560f6c3e82f76db/3.png)

1. **AutoRAG APIからクエリを受信：** クエリワークフローは、AutoRAGのAI検索または検索エンドポイントにリクエストを送信すると開始されます。
2. **クエリの書き換え（オプション）：** AutoRAGは、Workers AIのLLMの1つを使用して入力クエリを書き換えるオプションを提供し、元のクエリをより効果的な検索クエリに変換することで検索品質を向上させます。
3. **クエリの埋め込み：** 書き換えられた（または元の）クエリは、ベクトル化されたデータと比較して最も関連性の高い一致を見つけるために、データの埋め込みに使用されたのと同じ埋め込みモデルを介してベクトルに変換されます。
4. **Vectorizeでのベクトル検索：** クエリベクトルは、AutoRAGに関連するVectorizeデータベースに保存されているベクトルと照合して検索されます。
5. **メタデータ + コンテンツの取得：** Vectorizeは最も関連性の高いチャンクとそのメタデータを返します。また、元のコンテンツはR2バケットから取得されます。これらはテキスト生成モデルに渡されます。
6. **応答生成：** Workers AIのテキスト生成モデルを使用して、取得したコンテンツと元のユーザークエリを使用して応答を生成します。

最終的な結果は、プライベートデータに基づいたAI駆動の回答です - 正確で最新の情報です。

### 5分以内でRAGを実装するチュートリアル

ほとんどの場合、AutoRAGの使用開始は既存のR2バケットを指定するだけで済みます。しかし、コンテンツがまだバケットにない場合や、ウェブページ上にある場合、またはフロントエンドUIによって動的にレンダリングされる必要がある場合は、**Browser Rendering API**を使用して独自のウェブサイトをクロールし、RAGを強化する情報を収集できます。

#### ステップ1：ウェブページを取得してR2にアップロードするWorkerを作成

CloudflareのWorkerを作成して、Puppeteerを使用してURLを訪問し、レンダリングして、完全なHTMLをR2バケットに保存します。コード例には、Worker作成、依存関係のインストール、R2バケット作成、設定追加、そしてソースコードの実装が含まれています。

#### ステップ2：AutoRAGの作成とインデックス作成の監視

AutoRAGインスタンスを作成するには、Cloudflareダッシュボードに移動し、以下のステップに従います：

1. R2バケットを選択
2. 埋め込みモデルを選択
3. LLMを選択
4. AI Gatewayを選択または作成
5. AutoRAGに名前を付ける
6. Service APIトークンを選択または作成

![AutoRAGの設定画面](https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5qgy5VRqvKjBhdmSZ4riEE/e7dc59a4c615838704d9ec323bfdabfa/4.png)

作成後、AutoRAGは自動的にVectorizeデータベースを作成し、データのインデックス作成を開始します。インデックス作成の進行状況はAutoRAGの概要ページで確認できます。

#### ステップ3：テストとアプリケーションへの追加

インデックス作成が完了したら、AutoRAGインスタンスのPlaygroundタブを開いて質問を試すことができます。結果に満足したら、AutoRAGをアプリケーションに直接統合できます。Workerを使用してアプリケーションを構築している場合は、AIバインディングを使用してAutoRAGを直接呼び出すことができます。

### 利用開始方法と制限事項

オープンベータ期間中、AutoRAGの有効化は**無料**です。インデックス作成、検索、オーグメンテーションのための計算操作には、この段階では追加コストはかかりません。

AutoRAGはCloudflareの開発者プラットフォーム上に完全に構築されており、RAGパイプラインを自分で構築する場合に使用するのと同じツールを使用しています。AutoRAGインスタンスを作成すると、それは自分のアカウント内のCloudflareサービス上でプロビジョニングされ実行されるため、パフォーマンス、コスト、動作の完全な可視性を得ることができます。

使用されるサービスには以下が含まれます：

- **R2**：ソースデータを保存します。
- **Vectorize**：ベクトル埋め込みを保存し、セマンティック検索を強化します。
- **Workers AI**：画像をMarkdownに変換し、埋め込みを生成し、クエリを書き換え、応答を生成します。
- **AI Gateway**：モデルの使用状況を追跡および管理します。

ベータ期間中のリソース管理を支援するために、各アカウントは**10個のAutoRAG**インスタンスに制限されており、AutoRAGあたり最大**10万ファイル**までとなっています。

### 今後のロードマップ

CloudflareはAutoRAGをさらに強力で柔軟にするために、2025年を通じて以下の機能を開発中です：

- **より多くのデータソース統合**：R2を超えて、ウェブサイトURLの直接解析（ブラウザレンダリングによる）やCloudflare D1などの構造化データソースのサポートを拡張します。
- **よりスマートで高品質な応答**：再ランク付け、再帰的チャンキング、その他の処理技術を組み込んで、生成される回答の品質と関連性を向上させます。

これらの機能は段階的にリリースされ、次の段階を形作るためのフィードバックを求めています。

### まとめ

CloudflareダッシュボードでAI > AutoRAGに移動し、Create AutoRAGを選択することで、今日からAutoRAGを始めることができます。AI駆動の検索体験、内部知識アシスタント、またはLLMの実験を構築している場合でも、AutoRAGはCloudflareのグローバルネットワーク上でRAGを始めるための迅速で柔軟な方法を提供します。詳細については、開発者ドキュメントを参照し、ブラウザレンダリングAPIも試してみてください。

質問やフィードバックがある場合は、Cloudflare開発者Discordに参加してください。
