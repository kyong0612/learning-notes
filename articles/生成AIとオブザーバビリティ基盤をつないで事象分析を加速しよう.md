---
title: "生成AIとオブザーバビリティ基盤をつないで事象分析を加速しよう"
source: "https://zenn.dev/ubie_dev/articles/1e983361cb053b"
author:
  - "umiyosh"
published: 2025-12-23
created: 2025-12-27
description: |
  Honeycomb MCPと生成AIエージェントを連動させ、自然言語で事象分析を行う実験を行った。3つの生成AIツール（Claude Code + Opus 4.5、DevGenius + Sonnet 4.5、Codex + GPT-5.2）で同じプロンプトによる調査を実施し、Claude Codeが最も深い分析に成功。生成AI×オブザーバビリティは原因分析の自動化ではなく、状況把握の標準化と組織で再利用できる入口として価値があることを示した。Phase 1（状況把握の自動化）、Phase 2（確定に寄せる）、Phase 3（AIOps）の3段階で育てる戦略を提案。
tags:
  - "SRE"
  - "生成AI"
  - "o11y"
  - "インシデントレスポンス"
  - "honeycomb"
  - "AIOps"
  - "オブザーバビリティ"
---

# 生成AIとオブザーバビリティ基盤をつないで事象分析を加速しよう

## はじめに

本記事は、UbieのSREとして入社した著者（umiyosh）が、生成AIエージェントとオブザーバビリティ基盤（Honeycomb）を連動させ、自然言語で事象分析を行う実験を行った結果をまとめたものです。

転職後のオンボーディングにおいて、社内の生成AIエージェント「Dev Genius」を活用することで、従来の「ドキュメントを読みまくり」「人に聞きまくり」「実験or業務しまくる」という方法よりも効率的にシステム理解を進められた経験から、この実験を着想しました。

## TL;DR

生成AI Slackボットとo11y MCPを連動させ、事象分析を自然言語で行う世界観を実現。Slackでメンションするだけで調査を開始でき、生成AIがHoneycombのデータセットを参照してクエリを実行し、結果を要約して根拠URLを返すという「調査の入口」を作成しました。

## Honeycombについて

### Honeycombの特徴

Honeycombは、分散トレースを中心に「探索的に」システムを理解・デバッグするのに向いたオブザーバビリティ基盤です。

**主要な概念：**

- **トレース**: 1つのユーザー操作（リクエスト）が、複数のサービスをまたいで処理される「流れ」
- **スパン**: その流れの中の1つの処理単位（例：HTTPリクエスト、DBクエリ、外部API呼び出し）
- **属性**: 各スパンに付く「タグ（文脈）」（例：`service.name`、`http.route`、`http.status_code`、`duration_ms`）
- **バブルアップ**: Honeycombの固有機能。ヒートマップなどの散布図から異常な集合と正常な集合を比較し、属性に明確な差分があるかをわかりやすく表現したUI
- **データセット**: 送信されたイベントを保存・分析するための論理的な区分（サービス単位で分けることが多い）

**Honeycombの強み：**

1. **ワイドイベント**: スパンに属性をたくさん載せられるため、あとから「どのアプリバージョンからエラーが生じた？」「特定のデバイスのユーザのみの問題か？」「特定GKEノードのzone由来の障害か？」など、スパンを細かく切り分けながら探索できる
2. **コスト設計**: イベント従量枠の課金体系のため、スパンを大量に取り付けてもコスト圧迫しない

### オブザーバビリティの思想

o11ycon Tokyo 2025のキーノート（Liz Fong-Jones, Honeycomb Field CTO）では、「複雑なシステムを理解するには観測が必要だが、何もかも情報収集することは予算的に破綻する」という現実から出発し、実装の戦術として "reduce, reuse, recycle" とサンプリング／データクリーンアップを扱っています。

重要な視点は、「オブザーバビリティは理念ではなくサービスの内部状態を説明できるという目的を見失わず運用コストとセットの設計問題として取り扱う」という点です。開発者が好奇心の赴くままに妥当なコストでサービスの内部状態を探索できることが重要です。

## Honeycomb MCP

Honeycomb MCPを使うと、生成AIがHoneycombのデータセットを参照してクエリを実行し、結果を要約したり、根拠URLを返したりできます。

**実現できること：**

- **自然言語 →（生成AIがクエリを組み立て）→ Honeycombで集計 → 結果を文章で返す**、という「調査の入口」を作成
- 複数のデータセットをまたいで同じようなクエリを実行し探索を繰り返す場合、自然言語で「入口」ができるだけで認知負荷がかなり下がる
- 調査結果の根拠となるクエリ結果のページに紐づいているので、そのまま関連するトレースデータを参照したり、バブルアップで特徴量を検査したり、さらにクエリで探索することもできる

## 実験：本番環境事象を"同じ短文プロンプト"で調査させた

### 実験設定

3つの生成AIツールで同じ実験条件でテストしました：

1. **Claude Code + Opus 4.5**
2. **Codex + GPT-5.2**
3. **DevGenius（社内生成AI基盤Slack bot）+ Sonnet 4.5**

**実験シナリオ：**

直近のイベント量に顕著な違いのあるサービスを発見。2025/12/1 12:20以降にprdでイベント量（COUNT）が急増した時点の「何が変わったか」を調査させました。

原因は事前に特定済みで、特定のアプリケーションで実装された計装による増強・増加でした。これを生成AIエージェントおよびMCPが特定できるかを測るシナリオです。

**使用したプロンプト：**

```text
2025/12/1 12:20以降にprdでイベント量（COUNT）が急増した時点の"何が変わったか"を調べて。
```

### 調査用システムプロンプト

各ツールには以下のようなシステムプロンプトを与えています：

**前提：**

- 既定環境: `prd`
- 重要属性（例）: `service.name`, `http.route`, `duration_ms`, `error`, `trace.trace_id`, `span.kind`, `app.version`

**基本ルール（ハルシネーション対策）：**

1. **時刻は必ずツールで変換**（手計算禁止）
   - `parse_time("YYYY-MM-DD HH:MM:SS JST") -> UTC`
   - モデルによってはハルシネーションによりカットオフの日付で検索する癖があるので、内製のMCPを使って強制的に日付を現在日付にするような作業を指示
2. まず `span.kind` を確認し、server spanが無ければ「下流呼び出しの分析」として扱う
3. 結論は断定しない（同一 trace_id の突合が取れない限り「仮説」止まり）
4. **根拠URL必須**（少なくとも1つ）

**標準手順：**

- 異常時間 vs 正常時間の比較 → 代表トレース2〜3本 → 次のクエリ（最大2本）

**出力フォーマット：**

- 観測事実 / 根拠URL / 仮説（最大3） / 欠落リスク / 次のクエリ（最大2）

### 実験結果サマリー

| ルート | 結果 | 主要所見 | 所要 |
| --- | --- | --- | --- |
| Claude Code 2.0.73 + Opus 4.5 | ✅成功 | 属性の特徴分析で `library.name=Prisma` 大量出現→計装増に結論に到達 | 4:44 |
| DevGenius + Sonnet 4.5 | △途中まで | 差分定量化・結果例まで。結論は未到達 | 4:15 |
| Codex cli 0.77.0 + gpt-5.2-codex | △途中まで | internal増など把握。結論は未到達 | 6:30 |

### Claude Code + Opus 4.5（深掘り〜確定まで強い）

このルートは、`app.version` の切替を差分軸として掴み、旧/新での差分比較とBubbleUp（属性分析）を回して、「新リリースで特定の計装が有効化され、internal spanが爆発的に増えた」という結論にたどり着きました。

**得られた結論：**

```text
技術的な解説

release-XXXXXのデプロイ（rev-xxxxx）で、OpenTelemetry Prisma計装が有効化された。
これにより各DBクエリに対して複数のinternalスパン（connection, query, serialize等）が
自動生成されるようになり、トレースの粒度が大幅に向上した一方、イベント量が約11倍に増加。
これは障害ではなく、意図的な計装追加による観測データ増加と考えられる。

観測上の制約

- 2025/12/1当時のトレースIDは保持期間外で直接確認不可
- サンプリングによる観測欠落の可能性あり

次のアクション（推奨）

1. Prisma計装を追加したPR/コミット（rev-xxxxx）の内容を確認
2. イベント量増加によるHoneycombコスト影響を評価
3. 必要に応じてスパンサンプリング率の調整を検討
```

結果として今回の「イベント量急増」は障害というより、観測仕様（計装）の変更によるテレメトリ増加として整理できました。

### DevGenius（Slack bot）+ Sonnet 4.5（入口として強い）

Slack botの最大の価値は、処理速度よりも「間口の広さ」にあります。

**特徴：**

- 観測UIやコーディングツールを開かずに、Slackでメンションするだけで調査を開始できる
- エンジニア／非エンジニアを問わず使える入口として価値が高い
- 差分の定量化・`span.kind` の分布変化・主要操作の変化・影響度（レイテンシ）など、状況把握とEvidence URL提示までは十分に到達できた
- 一方で、抽象プロンプトのままだと「どの差分軸で確定すべきか（例：リリース切替）」まで踏み込みにくく、確定は人間（または深掘り役）にバトンするのが自然

### Codex + gpt-5.2-codex（状況把握はできるが確定は弱い）

**特徴：**

- 差分の「察知」（internal増、特定計装由来のスパンの増加など）はできた
- `app.version` を確定軸として旧/新比較し、結論付けする最後の一手が弱く、仮説止まりになりやすい
- 継続クエリの提案はできていたため、プロンプト側で「旧/新比較→BubbleUpまで必須」と手順を強制すると改善余地がある

## 全体の示唆

### 1. モデル選択も重要だが、より支配的なのは"入力データ（テレメトリ設計）"

差分軸（例：`app.version`）や、反証可能な属性が揃っていると、生成AIはうまく仮説検証ループを回せます。逆に根拠が無い領域を当てにいくと、もっともらしい説明が出やすい。

### 2. Slack botは間口の広さという点で公開するUIとしては便利

誰でも同じUI（Slack）で調査を開始でき、Evidence URLを残せることが価値。確定が必要なら深掘り役に渡す設計が現実的です。

### 3. いずれの方法でも現在のプロンプトでは時間がかかりすぎている

結果が返るまで4分というのはあまりにも長すぎる。今回の実験はデータセット名などの指定は特にしておらず広範囲なデータセットが対象になり、かつ調査手順のシステムプロンプトも冗長なためそれが理由で調査に時間がかかったと思われる。

## 今後の課題点

生成AIエージェントの実行の途中経過情報を見ると、トレースの欠落や、見るべき情報を誤ることがあり、以下のような課題点があると認識しました：

1. **実行時間の短縮**: 作業指示プロンプトやデータセットのデスクリプションの整備など、生成AIが問題に気づきやすく、手順の試行錯誤を減らせるようなシステムプロンプトあるいはskillsの拡充
2. **実行基盤の根拠不足**: Kubernetesイベントやリソース、スケール状況などの計装の拡充
3. **Monitoring/Metricsとの統合**: Grafana等のMCP連携でメトリクスからボトムアップでその動作を説明できる状況を作ると、より解像度が上がった障害分析結果が得られる
4. **ログとの相関**: trace_id等でログを参照できると確証が増える
5. **サンプリング/保持**: テールベースサンプラーを導入し、重要イベントを取りこぼしにくい戦略と、必要な期間の保持設計を行う

## まとめ

ここまでの実験で見えたのは、生成AI×Observabilityは「原因分析を魔法のように自動化する」ものではない一方、状況把握を標準化し、組織で再利用できる入口にはなり得る、ということでした。

SRE視点では「障害調査を速くする」が目的ですが、Platform Engineering視点ではそれに加えて、調査の作法（手順・根拠・言い回し）をプロダクトとして提供することが価値になります。Slackでメンションするだけ、という間口の広さはその一例です。

### Phase 1（今）：状況把握の自動化（入口の整備）

- Slackで「いま何が起きてる？」を雑に聞ける
- 生成AIが、影響の大きい変化点や偏り（例：span.kind、操作、レイテンシ）を要約し、根拠URLまで返す
- 必要なら人間（または深掘り役のツール）が、そのURLから探索を継続できる

この段階だけでも、意思決定（エスカレーション、優先度付け、次の一手）が速くなります。

### Phase 2（次）：確定に寄せる（観測設計と統合）

原因特定（反証可能性）を上げるには、モデルよりも入力（テレメトリ設計）が重要です。

- 計装カバレッジや属性をさらに充実させ比較ループ（旧/新・BubbleUp）が回るようにする
- Monitoring/Metrics（例：Grafana）やログを同じ導線で参照できるようにする
- 実行基盤のイベント（Kubernetesイベント/リソース/スケール）も必要な場面がある

ここはPlatform側の仕事として「入口」「ガードレール」「データ設計」「回答の評価手法確立」を揃えていく領域です。

### Phase 3（将来）：AIOps（半自動の調査支援）

いきなり自動復旧ではなく、まずは人間と伴走するような半自動の調査支援が実用的です。

- 状況把握 → 仮説 → 追加クエリ → 根拠URL収集、までを半自動で回す
- 人間は意思決定（対応方針、復旧、周知）に集中する

そのためには、モデルの進化だけでなく、インシデント対応の運用の型が必要になると考えられます。

## 最後に

オブザーバビリティ・エンジニアリングにはこう書いてあります：

> 「オブザーバビリティツールでは、チーム内の最高のデバッガーは、通常、もっとも好奇心の強いエンジニアです。」（『Observability Engineering』）

属人的な"ヒーロー"に頼るのではなく、好奇心を起点に誰もが探索できる状態を作る。このような世界観が実現できれば、開発者の認知負荷を下げ、調査や共有の摩擦が減り、チームがより速く価値をデリバリーできる状態に近づけるはずです。そのようなプラットフォームとして提供できればと思います。
