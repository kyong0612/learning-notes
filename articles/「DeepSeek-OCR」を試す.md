---
title: "「DeepSeek-OCR」を試す"
source: "https://zenn.dev/kun432/scraps/b86cbb66cea4e7"
author:
  - kun432
published: 2024-11-05
created: 2025-10-23
description: |
  DeepSeek-OCRモデルの実験レポート。3BパラメータのMITライセンスOCRモデルで、画像圧縮による効率的な文書認識と複数の解像度モードによる柔軟な精度調整が特徴。神戸市の観光統計PDFを用いた日本語OCRの実証実験を実施。
tags:
  - DeepSeek
  - OCR
  - VLM
  - 機械学習
  - 日本語OCR
  - PDF処理
  - Transformers
---

## 概要

DeepSeek-OCRは、DeepSeek AIがリリースした3BパラメータのOCRモデル。「コンテキスト光学圧縮」という独自のアプローチで、テキストを画像に変換して圧縮し、少ないビジョントークンでLLMに渡して解読する仕組みを採用。MITライセンスで公開されており、A100-40Gで1日200K+ページをスケール可能に最適化されている。

## モデルの特徴

### アーキテクチャ

**DeepEncoder（約380M）**

- **前段**: SAMベースのウィンドウ注意で高解像度処理を効率化
- **中間**: 16倍のトークン圧縮（2層Conv）
- **後段**: CLIPラージのグローバル注意で知識活用
- 例: 1024×1024画像 → 4096パッチ → 16×圧縮 → **256ビジョントークン**

**DeepSeek-3B-MoEデコーダ（有効570M）**

- 圧縮トークンからテキストを復元する解凍係
- ルーティングで6/64の専門家＋2共有を起動し、推論を軽量化

### 解像度モード

用途に応じて5つのモードから選択可能：

| モード | 解像度 | 平均トークン数 | 適用場面 |
|--------|--------|---------------|----------|
| **Tiny** | 512×512 | 64 | スライド等の軽め文書 |
| **Small** | 640×640 | 100 | 本・レポート（~1000語以下） |
| **Base** | 1024×1024 | 256 | 一般的なPDF、表や数式 |
| **Large** | 1280×1280 | 400 | 高品質が必要な文書 |
| **Gundam** | n×640 + 1024 | n×100 + 256 | 新聞・超高密度文書 |

### 圧縮性能

**Foxベンチマーク（英語文書）での検証結果:**

| テキスト規模 | 64トークン精度 | 圧縮倍率 | 100トークン精度 | 圧縮倍率 |
|-------------|---------------|---------|----------------|---------|
| 600-700語 | 96.5% | 10.5× | 98.5% | 6.7× |
| 800-900語 | 83.8% | 13.2× | 96.8% | 8.5× |
| 1000-1100語 | 79.3% | 16.5× | 91.5% | 10.6× |
| 1200-1300語 | 59.1% | 19.7× | 87.1% | 12.6× |

**結論**: 10倍圧縮で約97%の精度を維持、20倍圧縮でも約60%の精度を確保。

### 主な機能

- 通常のテキストOCR
- レイアウト付き出力（座標＋ラベル）
- 表のHTML構造化
- 化学式（SMILES）の復元
- 幾何図形の要素抽出
- キャプション・検出・グラウンディングなどの汎用ビジョンタスク

## 実験内容

### 環境構成

**使用環境**: Google Colaboratory L4 GPU

**主要パッケージ**:

```
transformers==4.46.3
tokenizers==0.20.3
flash-attn==2.7.3
addict
```

**VRAM消費**: モデルロード時点で約15GB

### テストデータ

神戸市の「令和5年度 神戸市観光動向調査結果について」のPDFを使用。

- PDFを画像に変換（pdf2image使用）
- 21ページから1ページ目と4ページ目を抽出してテスト

### 実験結果

#### 1ページ目（表を含む文書）

**使用モード**: Gundam（base_size=1024, image_size=640）

**処理時間**: 約50秒

**結果**:

- 有効画像トークン: 780
- 出力テキストトークン: 1104
- 圧縮率: 1.42

**精度**:

- 日本語テキストの読み取り: ✅ 正確
- 表の構造認識: △ 一部崩れあり（HTML tableタグで出力）
- レイアウト保持: ✅ 概ね良好

#### 4ページ目（グラフ画像埋め込み文書）

**特徴的な動作**:

- 埋め込みグラフ画像を自動抽出し、別ファイルとして保存
- Markdownにはimagesディレクトリへの相対パスで画像を参照
- バウンディングボックス付きの視覚化画像も出力

**出力ファイル構成**:

```
output/
├── images/
│   ├── 0.jpg  # 抽出されたグラフ1
│   └── 1.jpg  # 抽出されたグラフ2
├── result.mmd        # Markdown形式の結果
└── result_with_boxes.jpg  # バウンディングボックス付き可視化
```

#### Tinyモードでの比較

**結果**: Gundamモードと比較してテーブル構造の崩れがやや目立つ。
**処理速度**: 低解像度モードでも処理時間はあまり変わらず。

## 考察とまとめ

### 他のOCRモデルとの比較

**dots.ocr**との比較:

- 精度: DeepSeek-OCRはdots.ocrと同等レベル（論文ベンチマークより）
- 使い勝手: dots.ocrは軽量・高速・GUI付きで現時点では優位
- 特徴: DeepSeek-OCRの解像度モード選択は独自の強み

### DeepSeek-OCRの強み

1. **トークン効率**: 少ないトークン数で高精度を実現
2. **柔軟性**: ユースケースに応じた解像度モード選択
3. **圧縮能力**: 10倍圧縮で97%精度という優れた圧縮性能
4. **多機能性**: OCR以外にも表構造化、画像抽出など多様な機能

### 選択基準についての示唆

現在、多くのVLMベースOCRモデルが高精度を達成しているため、選択基準として以下が重要になる：

1. **解像度モードの柔軟性**（DeepSeek-OCRの強み）
2. **使い勝手の良さ**（GUI、インストールの容易さ）
3. **処理速度**
4. **特定ドメインでの精度**

### 応用可能性

論文で言及されている「光学メモリ」の概念:

- 会話履歴を画像化して段階的に圧縮
- 直近は高解像度、古い情報は低解像度で「自然な忘却曲線」を模倣
- コンテキスト長をほぼ無限に近づける可能性

これは、LLMのコンテキスト管理における革新的なアプローチとして注目される。

## 参考リンク

- **モデル**: [deepseek-ai/DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
- **論文**: [GitHub - DeepSeek-OCR論文PDF](https://github.com/deepseek-ai/DeepSeek-OCR/tree/main/DeepSeek_OCR_paper.pdf)
- **元X投稿**: <https://x.com/reach_vb/status/1980170192392270227>
- **テストデータ**: [神戸市観光統計](https://www.city.kobe.lg.jp/a64051/shise/toke/sightseeing.html)
