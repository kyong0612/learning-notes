---
title: "Research Engineer / Scientist, Alignment Science"
source: "https://job-boards.greenhouse.io/anthropic/jobs/4631822008"
author:
  - "Anthropic"
published:
created: 2024-08-27
description: |
  Anthropic社のアライメントサイエンスチームにおけるリサーチエンジニア/サイエンティストの募集要項。強力なAIシステムの振る舞いを理解し、誘導するための機械学習実験の構築と実行を担当し、AIを人間にとって有益で、正直で、無害なものにすることを目指します。
tags:
  - "clippings"
  - "AI"
  - "AI-Safety"
  - "JobDescription"
  - "Anthropic"
  - "ResearchEngineer"
---
[求人一覧に戻る](https://job-boards.greenhouse.io/anthropic)

## Anthropicについて

Anthropicの使命は、信頼性があり、解釈可能で、操作可能なAIシステムを構築することです。私たちは、AIがユーザーと社会全体にとって安全で有益なものになることを望んでいます。私たちのチームは、有益なAIシステムを構築するために協力し合う、献身的な研究者、エンジニア、政策専門家、ビジネスリーダーからなる急成長中のグループです。

## 職務内容について

あなたは、強力なAIシステムの振る舞いを理解し、誘導するための、洗練された徹底的な機械学習実験を構築・実行したいと考えています。AIを有益で、正直で、無害なものにすることに関心があり、人間レベルの能力という文脈でこれがどのように困難になりうるかに興味を持っています。あなたは自分自身を科学者でありエンジニアでもあると表現できるでしょう。アライメントサイエンスのリサーチエンジニアとして、あなたはAIの安全性に関する探索的な実験研究に貢献します。特に、将来の強力なシステム（私たちの[責任あるスケーリングポリシー](https://www.anthropic.com/news/anthropics-responsible-scaling-policy)でASL-3またはASL-4に指定されるようなシステム）からのリスクに焦点を当て、解釈可能性、ファインチューニング、フロンティアレッドチームなどの他のチームと協力することがよくあります。

[私たちのブログ](https://alignment.anthropic.com/)では、アライメントサイエンスチームが現在探求している、あるいは過去に探求したトピックの概要を紹介しています。現在の主な焦点は以下の通りです...

- **スケーラブルな監督:** 高度な能力を持つモデルが、様々な領域で人間レベルの知能を超えても、有益で正直であり続けるための技術を開発します。
- **AI制御:** 高度なAIシステムが、未知または敵対的なシナリオにおいても安全かつ無害であり続けることを保証する手法を構築します。
- **[アライメントのストレステスト](https://www.lesswrong.com/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic)****:** [アライメント不全のモデル生物](https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1)を作成し、アライメントの失敗がどのように発生するかについての経験的な理解を深めます。
- **自動化されたアライメント研究:** アライメント研究を加速・改善できるシステムを構築し、アライメントします。
- **アライメント評価**: 展開前のアライメントと福祉評価（[Claude 4システムカード](https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf)参照）、アライメント不全リスクの安全ケース、および第三者評価機関との連携を通じて、モデルの最も重大で懸念される新たな特性を理解し、文書化します。
- [**セーフガード研究**](https://job-boards.greenhouse.io/anthropic/jobs/4459012008): 敵対的攻撃に対する堅牢な防御、モデルの安全性のための包括的な評価フレームワーク、および展開前に潜在的なリスクを検出・緩和するための自動化システムを開発します。
- **モデルの福祉:** 潜在的なモデルの福祉、道徳的地位、および関連する問題を調査し、対処します。詳細は、[プログラム発表](https://www.anthropic.com/research/exploring-model-welfare)および[Claude 4システムカード](https://www-cdn.anthropic.com/07b2a3f9902ee19fe39a36ca638e5ae987bc64dd.pdf)の福祉評価をご覧ください。

*注: この職務では、すべての面接をPythonで行い、ベイエリア在住の候補者を優先します。*

## 代表的なプロジェクト

- 安全技術を覆すように言語モデルを訓練し、我々の介入を覆すのにどれだけ効果的かを確認することで、安全技術の堅牢性をテストします。
- [AIディベート](https://arxiv.org/abs/1805.00899)のような技術をテストするために、マルチエージェント強化学習実験を実行します。
- 新しいLLM生成ジェイルブレイクの効果を効率的に評価するためのツールを構築します。
- 安全性に関連する文脈でモデルの推論能力をテストするための評価質問を効率的に生成するスクリプトとプロンプトを作成します。
- 研究論文、ブログ投稿、講演のためのアイデア、図、文章を提供します。
- [責任あるスケーリングポリシー](https://www.anthropic.com/news/anthropics-responsible-scaling-policy)の設計と実装など、Anthropicにおける主要なAI安全性の取り組みに貢献する実験を実行します。

## 求める人物像

- ソフトウェア、機械学習、またはリサーチエンジニアリングの豊富な経験がある方
- 経験的なAI研究プロジェクトに貢献した経験がある方
- 技術的なAI安全性研究にある程度の知識がある方
- 大規模な単独作業よりも、動きの速い共同プロジェクトを好む方
- 職務内容の範囲外であっても、積極的に仕事を引き受ける方
- AIの影響に関心がある方

## 必須ではない要件

- 職務遂行に必要なスキルの100%
- 正式な資格や学歴

このポジションの想定給与範囲は以下の通りです:

年俸:

$315,000 - $340,000USD

## ロジスティクス

**学歴要件:** 関連分野の学士号または同等の経験が必要です。**  
  
**ロケーションベースのハイブリッドポリシー:** 現在、すべてのスタッフは少なくとも25%の時間をオフィスで過ごすことを期待されています。ただし、職務によってはオフィスでの時間が増える場合があります。

**ビザスポンサーシップ:** ビザのスポンサーになります！ただし、すべての職務とすべての候補者に対してビザのスポンサーシップが成功するわけではありません。しかし、オファーを出した場合は、ビザ取得のためにあらゆる合理的な努力をし、移民弁護士を雇って支援します。

すべての資格を満たしていると思わなくても、応募することをお勧めします。すべての有力な候補者が、記載されているすべての資格を満たしているわけではありません。研究によると、過小評価されているグループに属すると自認する人々は、インポスター症候群を経験し、自身の候補としての強さを疑う傾向があるため、早々に自分を除外せず、この仕事に興味があれば応募を提出することを強くお勧めします。私たちが構築しているようなAIシステムは、非常に大きな社会的・倫理的影響を持つと考えています。そのため、多様な視点を含むことがさらに重要であると考えており、チームにはさまざまな視点を取り入れるよう努めています。

## 私たちの違い

私たちは、最も影響力のあるAI研究はビッグサイエンスになると信じています。Anthropicでは、単一のまとまったチームとして、ほんのいくつかの大規模な研究活動に取り組んでいます。そして、より小規模で特定のパズルに取り組むのではなく、操作可能で信頼できるAIという長期的な目標を前進させるという影響力を重視しています。私たちはAI研究を経験科学と見なしており、それは従来のコンピュータサイエンスの取り組みと同様に、物理学や生物学とも共通点があります。私たちは非常に協力的なグループであり、常に最も影響力のある仕事に取り組んでいることを確認するために、頻繁に研究討論会を開催しています。そのため、コミュニケーションスキルを非常に重視しています。

私たちの研究の方向性を理解する最も簡単な方法は、最近の研究を読むことです。この研究は、GPT-3、回路ベースの解釈可能性、マルチモーダルニューロン、スケーリング則、AIと計算、AIの安全性における具体的な問題、人間の好みからの学習など、私たちのチームがAnthropic以前に取り組んでいた多くの方向性を継続しています。

## 私たちと一緒に働きませんか

Anthropicはサンフランシスコに本社を置く公益法人です。競争力のある報酬と福利厚生、オプションの株式寄付マッチング、寛大な休暇と育児休暇、柔軟な勤務時間、そして同僚と協力するための素敵なオフィススペースを提供しています。**候補者のAI利用に関するガイダンス:** 応募プロセスにおけるAI利用に関する[私たちの方針](https://www.anthropic.com/candidate-ai-guidance)について学びましょう。
