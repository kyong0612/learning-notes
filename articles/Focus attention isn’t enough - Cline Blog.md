---
title: "フォーカス：注意だけでは不十分 - Cline Blog"
source: "https://cline.bot/blog/focus-attention-isnt-enough"
author:
  - "[[Kevin Bond]]"
published:
created: 2025-08-20
description: "コンテキストウィンドウが大きくなっても、コーディングエージェントの脱線は止まりません。Clineの新しいフォーカスチェーンは、すべてのステップを目標に固定し、最も長いタスクでさえも、意図した通りに完了させます。"
tags:
  - "clippings"
---
![Focus: attention isn’t enough](https://cline.bot/_next/image?url=https%3A%2F%2Fcline.ghost.io%2Fcontent%2Fimages%2F2025%2F08%2FChatGPT-Image-Aug-15--2025--01_47_05-AM.png&w=2048&q=75)

## フォーカス：注意だけでは不十分

コンテキストウィンドウが大きくなっても、コーディングエージェントの脱線は止まりません。Clineの新しいフォーカスチェーンは、すべてのステップを目標に固定し、最も長いタスクでさえも、意図した通りに完了させます。

![Kevin Bond](https://cline.bot/_next/image?url=https%3A%2F%2Fcline.ghost.io%2Fcontent%2Fimages%2F2025%2F08%2F1739429258414.jpeg&w=96&q=75)

• [@canvrno](https://twitter.com/@canvrno)

2025年8月15日

**注意** - *名詞*

*At·ten·tion ə-ˈten(t)-shən*  
何かに心を適用する行為または状態

**フォーカス** - *名詞*

*fo·cus fō-kəs*  
活動、魅力、または注意の中心  
集中の点  
**向けられた注意：強調**

AIコーディングアシスタントはプログラミングを変革しましたが、ユーザーと共通の欠点を共有しています - **彼らは忘れる**のです。タスクが進行し、プロンプトが長くなるにつれて、これらのエージェントは徐々に以前の詳細を見失っていきます。フロンティアモデルのコンテキストウィンドウが拡大しても、この問題が解決するのを待つのは魅力的ですが、残念ながら、単にコンテキストサイズを増やすだけでは解決しませんでした。実際、大規模言語モデルのコンテキストウィンドウが埋まり始めると、その出力の品質はしばしば[低下します](https://onnyunhui.medium.com/evaluating-long-context-lengths-in-llms-challenges-and-benchmarks-ef77a220d34d?ref=cline.ghost.io)。この「**中間での迷子**」現象は研究者によって記録されています。モデルは入力の最初または最後の情報に最もよく焦点を当てる傾向があり、重要な詳細が[中間に埋もれている](https://ar5iv.labs.arxiv.org/html/2307.03172?ref=cline.ghost.io)と**著しく性能が低下**します。言い換えれば、LLMは私たちと同じように情報過多に陥りやすいのです。

## より大きなウィンドウ、同じ記憶の問題

長時間の複数ステップのタスク中、LLMエージェントはしばしば目標のドリフトを経験します。これは物理的なコンテキストウィンドウの制約に根差した現象です。モデルがトークンを生成するにつれて、以前のステップがアクティブなアテンションウィンドウの外に出てしまうことがあります。例えばGPTファミリーのモデルは、「中間での迷子」効果を示します。これは、コンテキストの最初または最後にある情報が、中間に埋もれた詳細よりもはるかに良く記憶されるというU字型のパフォーマンス曲線です。明示的なアンカーメカニズムがなければ、エージェントは自身の以前の理論的根拠を「見る」ことができず、行動を再実行したり、以前の決定と矛盾したり、タスクから逸脱したりするリスクが高まります。

LLMのコンテキストウィンドウを拡張する努力（現在では100万トークン以上）は素晴らしいものですが、より長いコンテキストだけが万能薬ではありません。評価によれば、多くのモデルのパフォーマンスは特定の閾値を超えると飽和し、[しばしば低下する](https://arxiv.org/abs/2503.20589?ref=cline.ghost.io)ことが示されています。これは新しい問題ではありません。[Greg Kamradtが観察した](https://www.youtube.com/watch?v=KwRRuiCCdmc&ref=cline.ghost.io)ように、GPT-4の精度は、完全な128Kウィンドウのうち64Kトークン以上のコンテキストを与えられたときに著しく低下しました。今日の増加した制限をもってしても、コンテキスト管理戦略は依然として重要です。研究者は一般的に2つの補完的なアプローチを追求しています。(i) 技術的により長いコンテキストを扱えるモデルを構築すること、(ii) 検索または要約を使用して最も関連性の高いスニペットのみを供給することです([arxiv.org](http://arxiv.org/?ref=cline.ghost.io))。

モデルはますます大量の入力を消化できるようになっていますが、出力が最もシャープになるコンテキストウィンドウにはスイートスポットが依然として存在します。IBMのAIチームが（AIの年月で言えば）ずっと前に[述べた](https://research.ibm.com/blog/larger-context-window?ref=cline.ghost.io)ように、「人間と同様に、LLMは情報過多に陥りやすい... 詳細を投げすぎると、重要な要点を見逃す可能性がある」のです。今日、より大きなトークンウィンドウが目前に迫っていても、よく構造化されたコンテキストが重要です。

私たちは苦いが必要不可欠な真実を学びました：スケールだけでは不十分であり、一般的な手法は、正しい情報を正しい形式で提供されたときに最も良いパフォーマンスを発揮します。Clineにとって、これはRAGに頼る反射的な行動に抵抗することを意味します。[検索は受動的であり、エージェンシーは能動的です](https://pashpashpash.substack.com/p/why-i-no-longer-recommend-rag-for?ref=cline.ghost.io)。リポジトリを接続されていないベクトルインデックス化されたチャンクに分割し、コサイン類似性に頼って正しいものを浮かび上がらせることは、推論を希薄化させ、モデルの注意を散漫にするリスクがあります。有能なエージェントは、シニアエンジニアのようにコードベースを探索すべきです。フォルダをナビゲートし、インポートをたどり、ファイルを順番に読み、問題空間の首尾一貫した内部マップを構築するのです。だからこそ、コードベース全体を無差別に投入したり、脆弱なRAGパイプラインに依存したりする代わりに、私たちはモデルに各ユーザーターンで明確でスコープの定まった「やることリスト」を提供します。それはタスクを意識し、物語に基づいたコンテキストであり、整合性が取れ、スコープが定められ、目の前のタスクに関連しています。必要なものすべてであり、不要なものは何もありません。

コンテキストウィンドウ内のすべてのトークンが等価であるわけではありません。タスクを直接進めるトークン（主要な要件、重要なコードパス、エージェントが行動しなければならない決定など）は**高価値トークン**と見なすことができます。低価値トークンはノイズです。冗長なコード、本筋から外れたコメント、または推論を改善することなくスペースを消費する繰り返しのスニペットなどです。大規模なコードベースでは、特に広範な検索パイプラインに頼っている場合、低価値トークンが高価値トークンを押し出しやすいです。その結果、コストが高く、実行が遅く、しばしばパフォーマンスが悪い、肥大化したプロンプトになります。**私たちは高価値トークンを*強調する*ことを目指しています。計画のすべてのステップが意図的で、関連性があり、モデルが効果的に使用できる場所に配置されるようにします。エージェントを最も重要なことに固定することで、すべてのトークンをより良く活用し、モデルの注意を集中させます。**

## 目標を維持するためのコンテキストフォワードアプローチ

私たちはこの問題に正面から取り組むための新機能、**フォーカスチェーン**を展開しています。これは単なるやることリストやUIの飾りではありません。これは、AIエージェントの注意を目の前のタスクに固定し続けるために特別に構築された、単一タスクのオーケストレーションに対する*コンテキストフォワード*なアプローチです。本質的に、フォーカスチェーンはエージェントにタスクのステップバイステップの計画を生成させ、作業を進める中でその**コンテキストを永続的に引き継ぎ**ます。各ステップで、エージェントは計画を参照し、更新することで、何をしていて、なぜそれを行っているのかを見失わないようにします。

これが実際にどのように機能するかです。Clineにリクエストを出すと、最初に行うことは、完了する必要があるすべてのステップの番号付きリストを作成することです（これがフォーカスの「チェーン」です）。この計画はエージェントの作業コンテキストに保持されます。その後、すべての段階で、エージェントはフォーカスチェーンを確認し、進捗をマークし、必要に応じて残りのステップを修正します。重要なのは、同じモデルが時間をかけてリストを更新するタスクを担うことです。そうすることで、計画自体がプロンプトの一部となり、モデルに過去の行動と今後の行動を思い出させます。エージェントは、進化するやることリストがコンテキストと共に移動するため、本質的に「自分が何に取り組んでいるかを覚えている」のです。この元の設計への継続的な接地は、モデルがコースを外れたり、脇道に逸れたりするのを防ぎます。それはまるで、AIプロジェクトマネージャーがエージェントの耳元でささやいているようなものです。「*ターゲットから外れるな - これが我々がやっていることだ。*」

このように集中し続けることは、特に以前は脱線しがちだった複雑で長期間にわたるタスクにおいて、測定可能なほど良い結果につながります。思考の連鎖を維持することで、フォーカスチェーンは長時間のLLMセッションを悩ませることがある疑似的な記憶喪失を軽減します。エージェントは、以前のステップを繰り返したり、自己矛盾したりする可能性がはるかに低くなります。なぜなら、それは単に消えゆく潜在的な記憶に純粋に頼っているのではなく、明示的な計画が常に視野にあるからです。

他のコーディングエージェントも同様の機能をリリースしていますが、私たちのものは、意味のある違いを生み出すと信じているコンテキストフォワードアプローチを採用しています。この初期リリースは強力な基盤であり、現在価値を提供すると同時に、将来のさらに大きな能力への道を切り開きます。

## チェーンにリンクを追加する

フォーカスチェーンの影響を実証するために、私たちは「ディーププランニング」と呼ばれる新しいワークフローもリリースしています。これはフォーカスチェーンの能力を示すために設計されています。このワークフローでは、AIエージェントはまず、あなたのコードベースを深く探索し、要求された機能や修正のための包括的な実装計画を作成するタスクを担います。これは事実上の計画フェーズです。エージェントは関連ファイルを読み、コンテキストを収集し、その情報を使用して詳細な攻撃計画を作成します。計画が準備され（そして検証され）たら、ワークフローは第2のタスク、つまり実行フェーズを開始し、そこでClineが実際に変更を実装します。ここでフォーカスチェーンが輝きます。第1フェーズで作成された計画は、常に存在するガイドとして第2フェーズに引き継がれます。実装に取り組むエージェントは、計画フェーズから*必要なすべての詳細*を持っており、潜在的に長いコーディングセッション全体を通じてユーザーのリクエストにレーザーフォーカスを維持するためにフォーカスチェーンを活用します。たとえタスクが数百万トークンの生成を消費することになったとしても（数時間相当の作業を考えてください）、エージェントは持続し、フォーカスチェーンは依頼されたことをやり遂げさせます。

この2段階のワークフローは、フォーカスチェーンを使用して効率と信頼性を向上させる方法の一例にすぎません。複雑な仕事を計画段階と実行段階に分割し、チェーンを介してコンテキストの連続性を維持することで、エージェントを成功に導きます。それは明確なロードマップを持ってコーディングタスクに取り組み、コードベースの大きさやセッションの長さに関わらず、軌道から外れません。私たちのコミュニティがフォーカスチェーンの他の多くの創造的な用途を発見すると信じています。永続的で構造化されたコンテキストから恩恵を受ける可能性のある複雑なタスクがあるときはいつでも、フォーカスチェーンがAIをタスクに集中させ、目標を達成させる鍵となるかもしれません。

## このコンテキストを締めくくる

AIの能力が進歩するにつれて、これらのモデルが*どれだけ*処理できるかだけでなく、与えられたものを*どれだけうまく*活用するかに取り組むことが重要です。より大きなコンテキストウィンドウは助けになりますが、それだけでLLMの記憶の限界を完全になくすことはできません。フォーカスチェーンは、この課題に対する私たちの答えです。AIエージェントの短期記憶を豊かにし、忘れるという自然な傾向から保護する方法です。コンテキストを前進させ、タスクをステップバイステップで調整することで、最も長く最も複雑なコーディングタスクであっても、一貫性、正確性、そして集中を目指しています。

初期の結果はエキサイティングです。以前は途中で脱線していた長期間のタスクが、最後まで一貫性を保つようになり、エージェントは初期の設計により整合性のとれたコードを生成します。私たちは、皆さんが自身のプロジェクトやワークフローでフォーカスチェーンを試してくださることを熱望しています。この機能は、AIコーディングアシスタントの信頼性の新しいレベルを表しており、私たちはその可能性を探求し始めたばかりです。フォーカスチェーンが私たちのモデルを軌道に乗せ続けることで、私たちはどこから始めたかを忘れることなく、可能なことの限界を押し広げることができます。
