---
title: "画像でテキストをトークン圧縮するDeepSeek-OCRがいろいろすごい"
source: "https://nowokay.hatenablog.com/entry/2025/10/22/200049"
author:
  - "きしだ なおき (id:nowokay)"
published: 2025-10-22
created: 2025-10-24
description: "DeepSeek-OCRは、テキストを画像化することでトークンサイズを圧縮する革新的なOCRモデル。3BパラメータのMoEモデルに0.4Bの画像エンコーダーを搭載し、従来のOCRとは異なるアプローチで高精度なテキスト認識を実現。有価証券報告書の複雑な表や免許証など、さまざまな文書を高精度で読み取ることができる。"
tags:
  - "AI"
  - "LLM"
  - "OCR"
  - "DeepSeek"
  - "画像認識"
  - "トークン圧縮"
---

## DeepSeek-OCRとは

DeepSeek-OCRは、中国のDeepSeekが開発した革新的なOCRモデルです。従来のOCRとは異なり、「テキストを画像にしたほうがトークンサイズを小さくできる」というアプローチを採用しています。テキストを画像にしてトークン化したものをテキストトークンに戻すという処理を行った結果、OCR機能が実現されました。

### モデルの構成

- **3Bパラメータ**のMoE（Mixture of Experts）モデル
- **アクティブパラメータは0.6B**
- **0.4Bの画像エンコーダー**を搭載
- 画像言語モデルとして機能

### 技術的背景

論文では、Qwen3-VLとInternVLのアーキテクチャとその欠点が指摘されており、DeepSeek-OCRはこれらの課題を解決するアプローチを採用しています。

## 導入と使い方

### インストール時の注意点

- GitHubリポジトリ: <https://github.com/deepseek-ai/DeepSeek-OCR>
- Hugging Faceモデル: <https://huggingface.co/deepseek-ai/DeepSeek-OCR>
- **重要**: 最新のTransformers 4.57.1では動作しない
- **推奨**: requirement.txtに記載の**Transformers 4.46.3**を使用すること

## OCRの実力検証

### 1. 有価証券報告書の表認識

**結果: 完璧**

任天堂の有価証券報告書の表を画像キャプチャして読み込ませたところ、以下の点で完璧な認識を実現：

- 小数点とカンマの違いを正確に識別
- 複雑な表構造を正確に再現
- 数値の精度が高い

### 2. 運転免許証の認識

**結果: 非常に良好**

警察庁サイトの運転免許証見本を読み込ませた結果：

- 大型、中型などの縦書きテキストも認識
- 写真部分も適切に切り取られる
- 全体的に高精度な認識

## 他の画像言語モデルとの比較

### Qwen3-VL 8Bとの比較

**Qwen3-VLの特徴:**

- 1週間前にリリースされた最新モデル
- 8Bと4Bのバージョンがある
- チャット機能を持つ汎用的な画像言語モデル
- 動画も読める

**認識精度:**

- 同じ有価証券報告書の表で列数が違う
- 項目名が不足し内容と食い違いがある
- 認識ミスが散見される
- 8Bとしては頑張っているが、DeepSeek-OCRには及ばない

**使い分け:**

- DeepSeek-OCRはOCR専門でチャット機能なし
- Qwen3-VLは汎用的な画像言語モデルとして多くのユースケースに対応

### InternVL 3.5 8Bとの比較

**結果: 他と比較すると劣る**

- Qwen3とGPT-ossに画像エンコーダーを載せたモデル
- 8月時点では優秀だったが、現在の水準では見劣りする
- 表の認識精度が低い

## 位置検出機能

DeepSeek-OCRには、テキストやオブジェクトの位置を検出する機能も搭載されています。

### OCRの基本プロンプト

```
<image>\n<|grounding|>Convert the document to markdown.
```

### 位置検出のプロンプト

```
<image>\nLocate <|ref|>the gocart<|/ref|> in the image.
```

**結果:**

- オブジェクト（ゴーカート）の位置を正確に検出
- 座標情報を返す（全体を1000とした相対位置）
- 文字の位置も検出可能

**出力例:**

```
<|ref|>the gocart<|/ref|><|det|>[[504, 480, 712, 645]]<|/det|>
```

日本語テキストの位置検出も機能：

```
<image>\nLocate <|ref|>ホキ美術館<|/ref|> in the image.
```

## 制限事項と弱点

### ランダム文字列の認識

記事の追記によると、**ランダム文字列は認識できない**という弱点が指摘されています。

**理由:**

- DeepSeek-OCRはLLM側でテキストを再現する際に文脈による補完を行う
- つじつまが合った読み取りになりやすい
- 逆に言えば、ハルシネーションで全く違う文字を出す可能性がある

この特性から、ガチな商用利用では専用OCR AIの方が制御しやすい可能性があります。

### その他の弱点

著者は続編記事「DeepSeek-OCRの弱点をつく」で、さらなる弱点を検証しています。

## 日本語OCR: YomiTokuとの比較

記事の追記2で、日本語専門のAI-OCR「YomiToku」が紹介されています。

### YomiTokuの特徴

- **開発**: MLism株式会社
- **リポジトリ**: <https://github.com/kotaro-kinoshita/yomitoku>
- **モデルサイズ**: 約650MB（DeepSeek-OCRの1/10）
- **推奨解像度**: 短辺1280以上

### 認識精度

**数値の読み取り**: 完璧

**文字認識**:

- 「人」が「A」になる誤認識がたまに発生
- 解像度が低い場合（867x1047）に発生
- 高解像度画像では改善される可能性

**カンマとスペース**:

- 元画像通りの忠実な読み取り
- DeepSeek-OCRのような文脈補完はない

### ライセンス

**CC BY-NC-SA 4.0**

- 非商用の個人利用・研究用途: 自由
- 商用利用: ライセンス要問合せ

## AI-OCRの現状と展望

### 市場の動き

1. **AI Inside**: 「AI-OCRは完成した」と発表、データ化精度99.999%を達成
   - ただしプロプライエタリ

2. **Qwen3-VL**: オープンソースで汎用的な画像言語モデル
   - OCR能力も備えるが、専門モデルには及ばず

3. **DeepSeek-OCR**: オープンソースで高精度なOCR専門モデル
   - 商用モデル並みの精度を実現

### 著者の感想

「商用モデルのようにはいかんか」と思っていたところに、DeepSeek-OCRの精度の高さに驚いた、という経緯が語られています。

## 実用化への考察

### DeepSeek-OCRの強み

- **高精度**: 複雑な表や文書を正確に認識
- **コンパクト**: 3Bパラメータで高性能
- **多機能**: OCRに加えて位置検出も可能
- **オープンソース**: 無料で利用可能

### 使い分けの推奨

1. **DeepSeek-OCR**:
   - OCR専門タスク
   - 高精度が求められる場合
   - 文脈理解が有効な場合

2. **Qwen3-VL**:
   - チャット機能が必要な場合
   - 動画処理が必要な場合
   - 汎用的な画像理解タスク

3. **YomiToku**:
   - 日本語文書専門
   - 忠実な読み取りが必要な場合
   - 軽量モデルが必要な場合
   - ガチな商用利用

## まとめ

DeepSeek-OCRは、トークン圧縮という独自のアプローチから生まれた革新的なOCRモデルです。従来の画像言語モデルと比較して、OCRタスクにおいて顕著に高い精度を実現しています。

ただし、ランダム文字列の認識やハルシネーションのリスクなど、固有の制約も存在します。用途に応じて、汎用モデルや専門OCRと使い分けることが重要です。

オープンソースで高精度なOCRモデルの登場により、AI-OCR技術がより身近になったと言えるでしょう。
